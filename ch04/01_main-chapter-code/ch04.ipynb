{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f4321d-d32a-4a90-bfc7-e923f316b2f8",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "<br>汉化的库: <a href=\"https://github.com/GoatCsu/CN-LLMs-from-scratch.git\">https://github.com/GoatCsu/CN-LLMs-from-scratch.git</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"../image/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9295b2-182b-490b-8325-83a67c4a001d",
   "metadata": {},
   "source": [
    "# 第四章: 从零开始构建 GPT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9eac223-a125-40f7-bacc-bd0d890450c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.8\n",
      "torch version: 2.10.0\n",
      "tiktoken version: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "import matplotlib\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "print(\"matplotlib version:\", version(\"matplotlib\"))\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))\n",
    "#加载并确认版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da97ed-e02f-4d7f-b68e-a0eba3716e02",
   "metadata": {},
   "source": [
    "- 在这一章我们要用类GPT LLM架构\n",
    "- 下一章就是训练LLM了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f11e0-4434-4979-9dee-e1207df0eb01",
   "metadata": {},
   "source": [
    "<img src=\"../image/01.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe99ab-0bcf-4778-a6b5-6db81fb826ef",
   "metadata": {},
   "source": [
    "## 4.1 LLM架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72d1ff-d82d-4e33-a88e-3c1a8831797b",
   "metadata": {},
   "source": [
    "- 第 1 章讨论了 GPT 和 Llama 等模型，这些模型基于原始 Transformer 架构的解码器部分，按顺序生成单词。\n",
    "- 因此，这些大语言模型（LLM）通常被称为“类解码器”的 LLM。\n",
    "- 与传统的深度学习模型相比，LLM 的规模更大，这主要是由于其参数数量庞大，而非代码量的增加。\n",
    "- 我们将看到，在 LLM 的架构中，许多元素是重复的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5213e9-bd1c-437e-aee8-f5e8fb717251",
   "metadata": {},
   "source": [
    "<img src=\"../image/02.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43f5e2-fb51-434a-b9be-abeef6b98d99",
   "metadata": {},
   "source": [
    "- 在前几章中，为了便于说明，我们使用了较小的嵌入维度对标记输入和输出进行处理，以确保内容能够显示在单页内。\n",
    "- 本章将讨论与小型 GPT-2 模型类似的嵌入和模型规模。\n",
    "- 我们将具体实现最小的 GPT-2 模型架构（1.24 亿参数）。该架构来源于 Radford 等人的报告 [《Language Models are Unsupervised Multitask Learners》](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)（需要注意的是，初始报告中参数数量被列为 1.17 亿，但这一错误在模型权重库中已被更正）。\n",
    "- 第 6 章将展示如何将预训练权重加载到我们的实现中，这些权重可兼容 3.45 亿、7.62 亿和 15.42 亿参数规模的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21baa14d-24b8-4820-8191-a2808f7fbabc",
   "metadata": {},
   "source": [
    "- 123million参数的GPT-2配置如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ed66875-1f24-445d-add6-006aae3c5707",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}\n",
    "#初始化定义需要的各种超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12fcd28-d210-4c57-8be6-06cfcd5d73a4",
   "metadata": {},
   "source": [
    "- 我们使用简短的变量名，以避免代行过长。\n",
    "- `\"vocab_size\"` 表示词汇表大小，共 50,257 个单词，由第 2 章介绍的 BPE 分词器支持。\n",
    "- `\"context_length\"` 表示模型的最大输入标记数，依赖于第 2 章的位置信息嵌入。\n",
    "- `\"emb_dim\"` 是标记输入的嵌入维度，将每个标记转换为 768 维向量。\n",
    "- `\"n_heads\"` 是多头注意力机制中的注意力头数量，详见第 3 章。\n",
    "- `\"n_layers\"` 是模型中 Transformer 块的数量，后续章节会详细实现。\n",
    "- `\"drop_rate\"` 是 dropout 机制的强度，设置为 0.1，表示训练时丢弃 10% 的隐藏单元以防止过拟合（第 3 章讨论）。\n",
    "- `\"qkv_bias\"` 决定多头注意力机制中的 `Linear` 层是否包含偏置向量。现代 LLM 通常禁用此选项，但在第 5 章加载 OpenAI 的 GPT-2 预训练权重时，会重新启用以保持兼容性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adce779-857b-4418-9501-12a7f3818d88",
   "metadata": {},
   "source": [
    "<img src=\"../image/03.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "619c2eed-f8ea-4ff5-92c3-feda0f29b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        # 词嵌入层，将输入索引转换为词向量，词表大小由字典大小和特征维度决定。\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        # 位置信息嵌入层，基于文本长度和特征维度生成位置信息。\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        # Dropout 层，用于随机丢弃一部分嵌入信息以减少过拟合。\n",
    "\n",
    "        # 使用多个 Transformer 块（占位符）\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        # Transformer 模块的堆叠，模型核心部分。\n",
    "\n",
    "        # 使用归一化层（占位符）\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        # 最终归一化层，用于调整特征分布。\n",
    "\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "        # 输出层，将特征映射到词表分布，最终预测输出单词。\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        # 获取批次大小和序列长度。\n",
    "\n",
    "        tok_embeds = self.tok_emb(in_idx) \n",
    "        # 根据输入索引生成词嵌入。\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        # 生成对应的位置信息嵌入。\n",
    "\n",
    "        x = tok_embeds + pos_embeds\n",
    "        # 将词嵌入和位置信息嵌入相加。\n",
    "        x = self.drop_emb(x)\n",
    "        # 应用 Dropout 随机丢弃部分信息。\n",
    "        x = self.trf_blocks(x)\n",
    "        # 通过多个 Transformer 块处理特征。\n",
    "        x = self.final_norm(x)\n",
    "        # 应用最终的归一化层。\n",
    "        logits = self.out_head(x)\n",
    "        # 将隐藏状态映射到词表分布，生成预测结果。\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    # Transformer 块的占位类。\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # 占位，实际模型应实现注意力机制和前馈网络。\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 此块不执行任何操作，仅返回输入。\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    # 归一化层的占位类。\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # 参数用于模拟 LayerNorm 的接口。\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 此层不执行任何操作，仅返回输入。\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665e8ab-20ca-4100-b9b9-50d9bdee33be",
   "metadata": {},
   "source": [
    "<img src=\"../image/04.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "794b6b6c-d36f-411e-a7db-8ac566a87fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "#召唤gpt大神\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "#编码输入文本\n",
    "batch = torch.stack(batch, dim=0)\n",
    "#按照横向来叠加两个向量\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "009238cd-0160-4834-979c-309710986bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以确保结果可复现\n",
    "# 这样每次运行代码时,模型的初始化权重都是相同的\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 使用之前定义的 GPT_CONFIG_124M 配置创建一个占位 GPT 模型实例\n",
    "# DummyGPTModel 是一个简化版本,用于演示模型的基本结构\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# 将输入批次(batch)传入模型进行前向传播\n",
    "# batch 的形状是 [2, 4],表示 2 个样本,每个样本有 4 个 token\n",
    "# logits 是模型的原始输出,形状为 [batch_size, seq_len, vocab_size]\n",
    "# 即 [2, 4, 50257],其中 50257 是 GPT-2 的词汇表大小\n",
    "logits = model(batch)\n",
    "\n",
    "# 打印输出张量的形状,用于验证模型输出的维度是否正确\n",
    "print(\"Output shape:\", logits.shape)\n",
    "\n",
    "# 打印完整的 logits 张量\n",
    "# 每个位置的 logits 是一个长度为 50257 的向量\n",
    "# 表示该位置预测词汇表中每个 token 的未归一化概率(分数)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fad0fe-895d-4493-9e48-962e2d46c66f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note**\n",
    "\n",
    "- 系统为Windows或者Linux, 运行结果如下所示:\n",
    "    \n",
    "```\n",
    "Output shape: torch.Size([2, 4, 50257])\n",
    "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
    "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
    "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
    "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
    "\n",
    "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
    "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
    "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
    "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
    "       grad_fn=<UnsafeViewBackward0>)\n",
    "```\n",
    "\n",
    "- Since these are just random numbers, this is not a reason for concern, and you can proceed with the remainder of the chapter without issues\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8332a00-98da-4eb4-b882-922776a89917",
   "metadata": {},
   "source": [
    "## 4.2 归一化操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cfb81-d59b-4d95-afe3-e43cf095f292",
   "metadata": {},
   "source": [
    "- **层归一化（LayerNorm）**，也称为层标准化（[Ba et al. 2016](https://arxiv.org/abs/1607.06450)），将神经网络层的激活值中心化为均值为 0，并将其方差归一化为 1。\n",
    "- 这种方法能够稳定训练过程，并加速权重的高效收敛。\n",
    "- 在 Transformer 块中，层归一化会在多头注意力模块的前后应用（我们将在后续实现），并在最终输出层之前再次应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ac47a-69cc-4597-beeb-65bed3b5910f",
   "metadata": {},
   "source": [
    "<img src=\"../image/05.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79e1b463-dc3f-44ac-9cdb-9d5b6f64eb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子以确保结果可复现\n",
    "# 每次运行时会生成相同的随机数序列\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 创建一个批次示例数据:\n",
    "# - 形状为 (2, 5): 2 个训练样本,每个样本有 5 个特征(维度)\n",
    "# - torch.randn 生成服从标准正态分布(均值0,方差1)的随机张量\n",
    "# 示例:创建一个形状为 (2, 5) 的张量\n",
    "# 第一个样本: [0.5, -1.2, 0.8, -0.3, 1.1]\n",
    "# 第二个样本: [-0.7, 0.9, -0.4, 1.5, -0.2]\n",
    "batch_example = torch.randn(2, 5)\n",
    "# 实际输出可能类似:\n",
    "# tensor([[ 0.2961,  0.5166, -0.2483, -0.0887,  0.1025],\n",
    "#         [-1.1006,  1.5067,  0.3216, -0.1336,  0.3353]])\n",
    "\n",
    "# 构建一个简单的神经网络层序列:\n",
    "# nn.Sequential 会按顺序执行其中的模块\n",
    "# 1. nn.Linear(5, 6): 全连接层(线性层),输入维度5,输出维度6\n",
    "#    - 将每个样本从 5 维映射到 6 维\n",
    "#    - 内部执行 y = xW^T + b (W是权重矩阵,b是偏置向量)\n",
    "# 2. nn.ReLU(): 激活函数,执行 ReLU(x) = max(0, x)\n",
    "#    - 将负值变为0,保留正值不变\n",
    "#    - 为网络引入非线性,使其能学习复杂模式\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "\n",
    "# 将批次数据传入网络层进行前向传播\n",
    "# 输入形状: (2, 5) -> 输出形状: (2, 6)\n",
    "# 即: 2个样本,每个样本从5维特征变换为6维特征\n",
    "out = layer(batch_example)\n",
    "\n",
    "# 打印输出结果,查看经过线性变换和ReLU激活后的张量\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fccc29e-71fc-4c16-898c-6137c6ea5d2e",
   "metadata": {},
   "source": [
    "- 计算上述信息的均值与方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9888f79e-8e69-44aa-8a19-cd34292adbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052eda3e-b395-48c4-acd4-eb8083bab958",
   "metadata": {},
   "source": [
    "- 归一化会单独对两个输入（行）进行处理；\n",
    "- 设置 `dim=-1` 的意思是让计算沿着最后一个维度进行（在这里是特征维度），而不是按行处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570db83a-205c-4f6f-b219-1f6195dde1a7",
   "metadata": {},
   "source": [
    "<img src=\"../image/06.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ecbc7-eb14-4fa1-b5d0-7e1ff9694f99",
   "metadata": {},
   "source": [
    "- 通过减去均值并除以方差的平方根（即标准差），可以让输入在列（特征）维度上的均值变为 0，方差变为 1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a1d1bb9-3341-4c9a-bc2a-d2489bf89cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 执行归一化操作(标准化)\n",
    "# 公式: (x - μ) / σ,其中 μ 是均值,σ 是标准差\n",
    "# - out: 原始输出张量,形状 (2, 6)\n",
    "# - mean: 每行的均值,形状 (2, 1)\n",
    "# - var: 每行的方差,形状 (2, 1)\n",
    "# - torch.sqrt(var): 计算标准差(方差的平方根)\n",
    "# 归一化后,每行数据的分布会变为均值=0、标准差=1 的标准正态分布\n",
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "\n",
    "# 打印归一化后的输出\n",
    "# 此时每行的数值已经被标准化,便于后续训练和梯度传播\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "\n",
    "# 验证归一化效果:重新计算归一化后数据的均值\n",
    "# dim=-1: 沿最后一个维度(特征维度)计算\n",
    "# keepdim=True: 保持维度,结果形状仍为 (2, 1)\n",
    "# 理论上归一化后的均值应该接近 0\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "\n",
    "# 验证归一化效果:重新计算归一化后数据的方差\n",
    "# dim=-1: 沿最后一个维度(特征维度)计算\n",
    "# keepdim=True: 保持维度,结果形状仍为 (2, 1)\n",
    "# 理论上归一化后的方差应该接近 1\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "\n",
    "# 打印验证结果\n",
    "# 如果归一化正确,均值应该非常接近 0,方差应该非常接近 1\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62b90c-7156-4979-9a79-ce1fb92969c1",
   "metadata": {},
   "source": [
    "- 每个输入的均值都会被调整为 0，方差被归一化为 1。\n",
    "- 为了结果容易阅读，我们可以禁用 PyTorch 的科学计数法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e06c34b-c68a-4b36-afbe-b30eda4eca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fb958-d4ed-43cc-858d-00052bb6b31a",
   "metadata": {},
   "source": [
    "- 上面我们对每个输入的特征进行了归一化。\n",
    "- 现在，基于相同的思路，我们可以实现一个 `LayerNorm` 类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3333a305-aa3d-460a-bcce-b80662d464d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    Layer Normalization (层归一化) 模块\n",
    "    \n",
    "    作用:\n",
    "    1. 对每个样本的特征维度进行归一化,使其均值为0、方差为1\n",
    "    2. 通过可学习的缩放和平移参数,让模型自适应调整归一化后的分布\n",
    "    3. 稳定训练过程,加速收敛,避免梯度消失/爆炸问题\n",
    "    \n",
    "    与 Batch Normalization 的区别:\n",
    "    - BatchNorm: 对同一特征在不同样本间归一化 (跨batch维度)\n",
    "    - LayerNorm: 对同一样本的不同特征归一化 (跨特征维度)\n",
    "    - LayerNorm 更适合序列模型(如Transformer),因为不依赖batch大小\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, emb_dim):\n",
    "        \"\"\"\n",
    "        初始化 LayerNorm 层\n",
    "        \n",
    "        参数:\n",
    "            emb_dim (int): 嵌入维度大小,即每个token的特征向量长度\n",
    "                          例如 GPT-2 中为 768 或 1024\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # eps (epsilon): 数值稳定性常数\n",
    "        # 在计算标准差时加到方差上,防止方差为0时除以0导致NaN错误\n",
    "        # 1e-5 是一个足够小的值,不会显著影响归一化结果\n",
    "        self.eps = 1e-5\n",
    "        \n",
    "        # scale (gamma/γ): 可学习的缩放参数\n",
    "        # - 形状: (emb_dim,) 对每个特征维度有独立的缩放系数\n",
    "        # - 初始化为全1: 初始时不改变归一化后的值\n",
    "        # - nn.Parameter: 标记为可训练参数,会在反向传播中更新\n",
    "        # - 作用: 让模型学习每个特征维度应该放大或缩小多少\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        \n",
    "        # shift (beta/β): 可学习的平移参数\n",
    "        # - 形状: (emb_dim,) 对每个特征维度有独立的偏移量\n",
    "        # - 初始化为全0: 初始时不改变归一化后的值\n",
    "        # - nn.Parameter: 标记为可训练参数,会在反向传播中更新\n",
    "        # - 作用: 让模型学习每个特征维度应该向上或向下平移多少\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播:对输入进行层归一化\n",
    "        \n",
    "        参数:\n",
    "            x (Tensor): 输入张量,形状通常为 (batch_size, seq_len, emb_dim)\n",
    "                       或 (batch_size, emb_dim)\n",
    "        \n",
    "        返回:\n",
    "            Tensor: 归一化并经过缩放平移后的张量,形状与输入相同\n",
    "        \n",
    "        计算步骤:\n",
    "            1. 计算每个样本在特征维度上的均值\n",
    "            2. 计算每个样本在特征维度上的方差\n",
    "            3. 标准化: (x - mean) / sqrt(var + eps)\n",
    "            4. 缩放和平移: scale * norm_x + shift\n",
    "        \"\"\"\n",
    "        \n",
    "        # 步骤1: 计算均值\n",
    "        # dim=-1: 沿最后一个维度(特征维度)计算均值\n",
    "        #         对于形状 (batch, seq_len, emb_dim),会对每个 (batch, seq_len) 位置\n",
    "        #         的 emb_dim 个特征值求平均\n",
    "        # keepdim=True: 保持维度,结果形状为 (batch, seq_len, 1)\n",
    "        #               便于后续广播运算\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        \n",
    "        # 步骤2: 计算方差\n",
    "        # dim=-1: 沿最后一个维度(特征维度)计算方差\n",
    "        # keepdim=True: 保持维度,结果形状为 (batch, seq_len, 1)\n",
    "        # unbiased=False: 使用有偏估计 (除以n而非n-1)\n",
    "        #                 原因: GPT-2原始实现使用有偏方差,为了加载预训练权重需保持一致\n",
    "        #                 对于大的emb_dim,有偏/无偏差异可忽略\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        \n",
    "        # 步骤3: 标准化 (归一化)\n",
    "        # 公式: norm_x = (x - μ) / σ\n",
    "        # - (x - mean): 中心化,使均值变为0\n",
    "        # - torch.sqrt(var + self.eps): 计算标准差,加eps防止除0\n",
    "        # - 整体效果: 将数据转换为均值=0、标准差=1的标准正态分布\n",
    "        # 这样可以:\n",
    "        #   a) 消除不同特征维度的量纲差异\n",
    "        #   b) 使梯度更稳定,加速训练收敛\n",
    "        #   c) 缓解梯度消失/爆炸问题\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        \n",
    "        # 步骤4: 缩放和平移 (Affine Transformation)\n",
    "        # 公式: y = γ * norm_x + β\n",
    "        # - self.scale (γ): 逐元素相乘,调整每个特征的方差/幅度\n",
    "        # - self.shift (β): 逐元素相加,调整每个特征的均值/中心\n",
    "        # \n",
    "        # 为什么需要这一步?\n",
    "        # - 标准化后所有特征都变成均值0方差1,可能丢失了原始数据的有用信息\n",
    "        # - 通过可学习的γ和β,模型可以恢复或调整到最适合任务的分布\n",
    "        # - 如果模型发现某个特征不需要归一化,可以学习到 γ≈σ, β≈μ 来\"撤销\"归一化\n",
    "        # \n",
    "        # 广播机制:\n",
    "        # - norm_x 形状: (batch, seq_len, emb_dim)\n",
    "        # - scale/shift 形状: (emb_dim,)\n",
    "        # - PyTorch会自动广播,对每个batch和seq_len位置应用相同的scale/shift\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c3908-7544-4808-b8cb-5d0a55bcca72",
   "metadata": {},
   "source": [
    "## 缩放与平移\n",
    "\n",
    "- 除了通过减去均值并除以方差来执行归一化操作外，我们还引入了两个可训练参数：`scale`（缩放参数）和 `shift`（平移参数）。\n",
    "- 初始时，`scale` 值为 1，`shift` 值为 0，不会对结果产生影响；但在训练过程中，LLM 会自动调整这两个参数，以提升模型在任务中的表现。\n",
    "- 这种设计使模型能够学习到最适合其数据的缩放和平移方式。\n",
    "- 此外，在计算方差的平方根时，我们会添加一个较小的值（`eps`），以避免方差为 0 时出现除以 0 的错误。\n",
    "\n",
    "## 偏差方差\n",
    "\n",
    "- 在方差计算中，设置 `unbiased=False` 使用公式 $\\frac{\\sum_i (x_i - \\bar{x})^2}{n}$，其中 $n$ 是样本大小（即特征或列的数量）。该公式未使用贝塞尔校正（分母为 `n` 而非 `n-1`），因此提供的是方差的偏差估计。\n",
    "- 对于嵌入维度 $n$ 较大的 LLM 来说，使用 `n` 和 `n-1` 的差异可以忽略不计。\n",
    "- 然而，由于 GPT-2 在归一化层的训练中使用了偏差方差，为了与预训练权重兼容，我们也采用了这种设置。\n",
    "\n",
    "## 实践 LayerNorm\n",
    "\n",
    "- 现在让我们通过实际代码尝试 `LayerNorm` 的应用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23b1000a-e613-4b43-bd90-e54deed8d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 LayerNorm 实例\n",
    "# - emb_dim=5: 指定嵌入维度为5,即每个token的特征向量有5个元素\n",
    "# - 这会初始化两个可学习参数:\n",
    "#   * self.scale (γ): 形状为 (5,), 初始值全为1\n",
    "#   * self.shift (β): 形状为 (5,), 初始值全为0\n",
    "ln = LayerNorm(emb_dim=5)\n",
    "\n",
    "# 对 batch_example 应用层归一化\n",
    "# 假设 batch_example 的形状为 (batch_size, seq_len, emb_dim)\n",
    "# 例如: (2, 3, 5) 表示 2个样本, 每个样本3个token, 每个token 5维特征\n",
    "# \n",
    "# 归一化过程 (对最后一维 emb_dim 进行):\n",
    "# 1. 计算每个token的5个特征的均值和方差\n",
    "# 2. 用 (x - mean) / sqrt(var + eps) 标准化\n",
    "# 3. 用可学习的 scale 和 shift 进行仿射变换\n",
    "# \n",
    "# 输出 out_ln 的形状与输入相同: (batch_size, seq_len, emb_dim)\n",
    "# 但每个token的特征已被归一化,使其在训练中更稳定\n",
    "out_ln = ln(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94c12de2-1cab-46e0-a099-e2e470353bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136cfc4-7c89-492e-b120-758c272bca8c",
   "metadata": {},
   "source": [
    "<img src=\"../image/07.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11190e7d-8c29-4115-824a-e03702f9dd54",
   "metadata": {},
   "source": [
    "## 4.3 GELU作为激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0585dfb-f21e-40e5-973f-2f63ad5cb169",
   "metadata": {},
   "source": [
    "- 在本节中，我们将实现一个小型神经网络子模块，该模块是 LLM 中 Transformer 块的核心组成部分。\n",
    "- 首先，我们从激活函数开始。\n",
    "- 在深度学习中，ReLU（线性整流单元）激活函数因其简单性和在各种神经网络架构中的高效性而被广泛使用。\n",
    "- 在 LLM 中，除了传统的 ReLU，还使用了其他类型的激活函数。其中两个典型的例子是 GELU（高斯误差线性单元）和 SwiGLU（Swish 门控线性单元）。\n",
    "- GELU 和 SwiGLU 是更复杂的平滑激活函数，分别结合了高斯函数和 sigmoid 门控线性单元，提供了比 ReLU 这种简单分段线性函数更好的性能，尤其适用于深度学习模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d482ce7-e493-4bfc-a820-3ea99f564ebc",
   "metadata": {},
   "source": [
    "- **GELU**（[Hendrycks 和 Gimpel, 2016](https://arxiv.org/abs/1606.08415)）可以通过多种方式实现；其精确定义为 $\\text{GELU}(x) = x \\cdot \\Phi(x)$，其中 $\\Phi(x)$ 是标准高斯分布的累积分布函数。\n",
    "- 在实际应用中，通常会使用一种计算成本更低的近似形式：  \n",
    "  $\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)$  \n",
    "  （原始 GPT-2 模型也是使用该近似公式进行训练的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f84694b7-95f3-4323-b6d6-0a73df278e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \"\"\"\n",
    "    GELU (Gaussian Error Linear Unit) 激活函数的实现\n",
    "    \n",
    "    GELU 是一种平滑的非线性激活函数,相比 ReLU 有以下特点:\n",
    "    1. 在负值区域有非零梯度(除了约 -0.75 处),避免\"神经元死亡\"\n",
    "    2. 平滑可导,训练更稳定\n",
    "    3. 在 Transformer 模型(如 GPT)中表现优于 ReLU\n",
    "    \n",
    "    数学公式(近似版本):\n",
    "    GELU(x) ≈ 0.5 * x * (1 + tanh(√(2/π) * (x + 0.044715 * x³)))\n",
    "    \n",
    "    这个近似公式比精确的高斯累积分布函数计算更快,是 GPT-2 训练时使用的版本\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数\n",
    "        \n",
    "        参数:\n",
    "            x: 输入张量,形状任意 (batch_size, seq_len, emb_dim) 等\n",
    "        \n",
    "        返回:\n",
    "            经过 GELU 激活后的张量,形状与输入相同\n",
    "        \n",
    "        实现细节:\n",
    "        1. 0.5 * x: 基础缩放\n",
    "        2. x + 0.044715 * x³: 三次多项式修正项,使函数更平滑\n",
    "        3. √(2/π) ≈ 0.7978: 归一化常数\n",
    "        4. tanh(...): 将结果压缩到 (-1, 1) 范围\n",
    "        5. (1 + tanh(...)): 将范围调整到 (0, 2)\n",
    "        6. 最终乘以 0.5 * x: 得到类似 ReLU 但更平滑的效果\n",
    "        \"\"\"\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            # 这一步把激活函数变得平滑了很多,相比 ReLU 的硬截断\n",
    "            # √(2/π) 是归一化常数,确保激活函数的数值范围合理\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            # x + 0.044715*x³ 是三次多项式近似,0.044715 是经验系数\n",
    "            # 这个三次项让负值区域也有梯度,避免梯度消失\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc5487d2-2576-4118-80a7-56c4caac2e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入 matplotlib 绘图库,用于可视化激活函数的形状\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 实例化两个激活函数对象:\n",
    "# - gelu: 我们自定义的 GELU 激活函数(上面定义的类)\n",
    "# - relu: PyTorch 内置的 ReLU 激活函数\n",
    "# 这样可以方便地对比两种激活函数的行为差异\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# 生成测试数据:\n",
    "# torch.linspace(-3, 3, 100) 在 [-3, 3] 区间内均匀生成 100 个点\n",
    "# 这个范围足够展示激活函数在负值、零点、正值区域的不同表现\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "\n",
    "# 将测试数据分别通过两个激活函数,得到输出值:\n",
    "# - y_gelu: GELU 激活函数的输出,是平滑曲线\n",
    "# - y_relu: ReLU 激活函数的输出,是分段线性(负值为0,正值保持不变)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "# 创建一个 8x3 英寸的画布,用于并排显示两个子图\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "# 使用 enumerate 遍历两个激活函数的输出和标签:\n",
    "# - zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]) 将输出和标签配对\n",
    "# - enumerate(..., 1) 从 1 开始编号(方便 subplot 索引)\n",
    "# - i: 子图编号(1 或 2)\n",
    "# - y: 当前激活函数的输出值\n",
    "# - label: 当前激活函数的名称(\"GELU\" 或 \"ReLU\")\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    # 创建 1 行 2 列的子图布局,当前绘制第 i 个子图\n",
    "    # 1: 总共 1 行\n",
    "    # 2: 总共 2 列\n",
    "    # i: 当前子图位置(1=左图, 2=右图)\n",
    "    plt.subplot(1, 2, i)\n",
    "    \n",
    "    # 绘制激活函数曲线:\n",
    "    # x 轴: 输入值(从 -3 到 3)\n",
    "    # y 轴: 激活函数的输出值\n",
    "    plt.plot(x, y)\n",
    "    \n",
    "    # 设置子图标题,显示激活函数名称\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    \n",
    "    # 设置 x 轴标签,表示输入值\n",
    "    plt.xlabel(\"x\")\n",
    "    \n",
    "    # 设置 y 轴标签,表示激活函数的输出值\n",
    "    # 例如: \"GELU(x)\" 或 \"ReLU(x)\"\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    \n",
    "    # 显示网格线,方便观察函数值的变化趋势\n",
    "    # 可以清楚看到 ReLU 在 x=0 处的折点,以及 GELU 的平滑过渡\n",
    "    plt.grid(True)\n",
    "\n",
    "# 自动调整子图之间的间距,避免标题/标签重叠\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图形窗口\n",
    "# 通过对比可以看到:\n",
    "# - ReLU: 在 x<0 时输出为 0(硬截断),在 x>0 时输出等于输入(斜率为1)\n",
    "# - GELU: 平滑曲线,在 x<0 时也有非零梯度(除了约 -0.75 处),更适合深度学习\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd01662-14cb-43fd-bffd-2d702813de2d",
   "metadata": {},
   "source": [
    "- 正如我们所见，ReLU 是一种分段线性函数：对于正值直接输出输入值；对于负值则输出零。\n",
    "- GELU 是一种平滑的非线性函数，它近似 ReLU，但在负值时具有非零梯度（除了大约在 -0.75 处）。\n",
    "\n",
    "- 接下来，我们将实现一个小型神经网络模块 `FeedForward`，该模块将用于 LLM 的 Transformer 块中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9275c879-b148-4579-a107-86827ca14d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeedForward 前馈神经网络模块\n",
    "# 这是 Transformer 块中的核心组件之一,用于对每个 token 的嵌入向量进行非线性变换\n",
    "# 典型结构: 线性层 → 激活函数 → 线性层 (也称为 Position-wise Feed-Forward Network)\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\"\n",
    "        初始化前馈网络\n",
    "        \n",
    "        参数:\n",
    "            cfg: 配置字典,包含模型超参数\n",
    "                 cfg[\"emb_dim\"]: 嵌入维度(例如 GPT-124M 中为 768)\n",
    "        \n",
    "        网络结构:\n",
    "            输入维度 → 4倍扩展维度 → 激活函数 → 压缩回原始维度\n",
    "            例如: 768 → 3072 → GELU → 768\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 使用 nn.Sequential 将多个层按顺序组合成一个模块\n",
    "        # 前向传播时会自动按顺序执行这些层\n",
    "        self.layers = nn.Sequential(\n",
    "            # 第一个线性层: 将嵌入维度扩展到 4 倍\n",
    "            # 输入: [batch_size, num_tokens, emb_dim]\n",
    "            # 输出: [batch_size, num_tokens, 4 * emb_dim]\n",
    "            # 例如: [2, 3, 768] → [2, 3, 3072]\n",
    "            # 扩展到 4 倍是 Transformer 的标准做法,增加模型的表达能力\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            \n",
    "            # GELU 激活函数: 引入非线性变换\n",
    "            # 保持形状不变: [batch_size, num_tokens, 4 * emb_dim]\n",
    "            # GELU 比 ReLU 更平滑,在负值区域也有梯度,有助于训练\n",
    "            GELU(),\n",
    "            \n",
    "            # 第二个线性层: 将维度压缩回原始嵌入维度\n",
    "            # 输入: [batch_size, num_tokens, 4 * emb_dim]\n",
    "            # 输出: [batch_size, num_tokens, emb_dim]\n",
    "            # 例如: [2, 3, 3072] → [2, 3, 768]\n",
    "            # 这样输出维度与输入维度相同,方便后续的残差连接\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "    \n",
    "    # 前向传播函数: 定义数据如何流经网络\n",
    "    # 运行一次 forward 会依次执行: 线性变换 → GELU 激活 → 线性变换\n",
    "    # 即: 扩展维度 → 非线性激活 → 压缩维度\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        参数:\n",
    "            x: 输入张量,形状为 [batch_size, num_tokens, emb_dim]\n",
    "               例如: [2, 3, 768] 表示 2 个样本,每个样本 3 个 token,每个 token 768 维\n",
    "        \n",
    "        返回:\n",
    "            输出张量,形状与输入相同 [batch_size, num_tokens, emb_dim]\n",
    "            例如: [2, 3, 768]\n",
    "        \n",
    "        处理流程:\n",
    "            1. x → Linear(768→3072): 扩展特征维度\n",
    "            2. → GELU(): 非线性激活\n",
    "            3. → Linear(3072→768): 压缩回原始维度\n",
    "        \"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c4976e2-0261-418e-b042-c5be98c2ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcaacfa-3cfc-4c9e-b668-b71a2753145a",
   "metadata": {},
   "source": [
    "<img src=\"../image/09.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "928e7f7c-d0b1-499f-8d07-4cadb428a6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# input shape: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768) \n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8756c5-6b04-443b-93d0-e555a316c377",
   "metadata": {},
   "source": [
    "<img src=\"../image/10.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da2a50-04f4-4388-af23-ad32e405a972",
   "metadata": {},
   "source": [
    "<img src=\"../image/11.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffcb905-53c7-4886-87d2-4464c5fecf89",
   "metadata": {},
   "source": [
    "## 4.4 类似于ResNet的shortcut传递"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae416c-821e-4bfa-a741-8af4ba5db00e",
   "metadata": {},
   "source": [
    "- 接下来，我们来讨论**快捷连接**（shortcut connections）的概念，也称为**跳跃连接**（skip connections）或**残差连接**（residual connections）。\n",
    "- 残差连接最初是在深度网络中提出的，主要应用于计算机视觉中的残差网络（ResNet），以缓解梯度消失问题。\n",
    "- 残差连接通过为梯度提供一条更短的替代路径，使其能够更顺畅地通过网络流动。\n",
    "- 具体实现是将某一层的输出与后续某一层的输出相加，通常会跳过中间的一层或多层。\n",
    "- 以下是一个小型网络的示例来说明这一概念：\n",
    "\n",
    "![残差连接示例](../image/12.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cfd241-a32e-4601-8790-784b82f2f23e",
   "metadata": {},
   "source": [
    "- 代码形式长成这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05473938-799c-49fd-86d4-8ed65f94fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    示例深度神经网络,用于演示残差连接(shortcut/skip/residual connection)的作用\n",
    "    \n",
    "    这个网络包含5层线性变换,每层后接GELU激活函数。\n",
    "    可以选择是否使用残差连接来缓解梯度消失问题。\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        \"\"\"\n",
    "        初始化网络\n",
    "        \n",
    "        Args:\n",
    "            layer_sizes: 列表,定义每层的输入输出维度,长度为6(5层网络需要6个维度值)\n",
    "                        例如 [3, 3, 3, 3, 3, 1] 表示输入3维,中间层都是3维,输出1维\n",
    "            use_shortcut: 布尔值,是否使用残差连接\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        \n",
    "        # 定义多层网络,包含 5 层线性层和激活函数 GELU\n",
    "        # 每个 nn.Sequential 包含一个线性变换和一个激活函数\n",
    "        self.layers = nn.ModuleList([\n",
    "            # 第1层: layer_sizes[0] -> layer_sizes[1]\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            # 第2层: layer_sizes[1] -> layer_sizes[2]\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            # 第3层: layer_sizes[2] -> layer_sizes[3]\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            # 第4层: layer_sizes[3] -> layer_sizes[4]\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            # 第5层: layer_sizes[4] -> layer_sizes[5]\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "        # 这是一个五层的神经网络块,其中每层包含一个线性变换和一个激活函数 GELU,\n",
    "        # 类似 ResNet 的结构,支持添加残差连接。\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        Args:\n",
    "            x: 输入张量,形状为 [batch_size, input_dim]\n",
    "            \n",
    "        Returns:\n",
    "            输出张量,形状为 [batch_size, output_dim]\n",
    "        \"\"\"\n",
    "        # 遍历每一层\n",
    "        for layer in self.layers:\n",
    "            # 计算当前层的输出\n",
    "            # layer(x) 会依次执行 Linear 和 GELU\n",
    "            layer_output = layer(x)\n",
    "            \n",
    "            # 检查是否可以应用残差连接\n",
    "            # 残差连接的条件:\n",
    "            # 1. use_shortcut 为 True (用户启用了残差连接)\n",
    "            # 2. x.shape == layer_output.shape (输入输出维度必须相同才能相加)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                # 残差连接: 将输入 x 与当前层输出相加\n",
    "                # 这样梯度可以直接通过加法操作流回前面的层,缓解梯度消失\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                # 不使用残差连接,或者维度不匹配时,直接使用当前层的输出\n",
    "                x = layer_output\n",
    "        \n",
    "        # 返回最终结果(经过所有层处理后的输出)\n",
    "        return x\n",
    "\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    \"\"\"\n",
    "    打印模型每层权重的梯度均值,用于观察梯度消失/爆炸现象\n",
    "    \n",
    "    Args:\n",
    "        model: 要分析的神经网络模型\n",
    "        x: 输入样本\n",
    "    \"\"\"\n",
    "    # 前向传播:计算模型输出\n",
    "    output = model(x)\n",
    "    \n",
    "    # 定义一个简单的目标值(用于计算损失)\n",
    "    target = torch.tensor([[0.]])\n",
    "    \n",
    "    # 计算损失,使用均方误差损失函数 (MSE Loss)\n",
    "    # MSE = mean((output - target)^2)\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # 反向传播,计算所有参数的梯度\n",
    "    # 这会填充每个参数的 .grad 属性\n",
    "    loss.backward()\n",
    "\n",
    "    # 遍历模型的所有参数,打印权重参数的梯度均值\n",
    "    for name, param in model.named_parameters():\n",
    "        # 只关注权重参数(weight),不关注偏置(bias)\n",
    "        if 'weight' in name:\n",
    "            # 计算梯度的绝对值的平均值\n",
    "            # 如果这个值很小(接近0),说明该层存在梯度消失问题\n",
    "            # 如果这个值很大,说明该层可能存在梯度爆炸问题\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bf277-b3db-4bb1-84ce-7a20caff1011",
   "metadata": {},
   "source": [
    "- 在没有残差链接的时候,梯度是这样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c75f43cc-6923-4018-b980-26023086572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "# 定义一个深层神经网络的结构\n",
    "# layer_sizes 列表定义了每一层的神经元数量:\n",
    "# - 输入层: 3个神经元\n",
    "# - 4个隐藏层: 每层3个神经元\n",
    "# - 输出层: 1个神经元\n",
    "# 总共5层(不包括输入层),这是一个相对较深的网络,容易出现梯度消失问题\n",
    "layer_sizes = [3, 3, 3, 3, 3, 1]  \n",
    "\n",
    "# 创建一个样本输入张量\n",
    "# shape: [1, 3] 表示 batch_size=1, 输入特征维度=3\n",
    "# 值 [1., 0., -1.] 是一个简单的测试输入,包含正数、零和负数\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "# 设置随机种子,确保实验的可重复性\n",
    "# 这样每次运行代码时,网络的初始权重都是相同的\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 创建一个 **不使用残差连接** 的深层神经网络\n",
    "# use_shortcut=False 表示禁用残差连接(shortcut connections)\n",
    "# 这个模型将展示传统深层网络的梯度消失问题\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")\n",
    "\n",
    "# 打印每一层权重的梯度均值\n",
    "# 目的: 观察在没有残差连接的情况下,梯度如何在反向传播过程中逐层衰减\n",
    "# 预期结果: 越靠近输入层(layer.0),梯度越小,说明存在梯度消失现象\n",
    "# 这会导致前面的层难以学习,训练效果差\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fd5d4-7345-4663-97f5-38f19dfde621",
   "metadata": {},
   "source": [
    "- **有** 残差的链接,梯度是这样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11b7c0c2-f9dd-4dd5-b096-a05c48c5f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)\n",
    "#引入了残差链接,发现梯度消失的缺点明显改善了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff783a-46f0-49c5-a7a9-26a525764b6e",
   "metadata": {},
   "source": [
    "- 正如我们从上述输出中看到的，残差连接有效地防止了梯度在早期层（靠近 `layer.0`）中消失。\n",
    "- 接下来，在实现 Transformer 块时，我们将使用这一残差连接的概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae578ca-e564-42cf-8635-a2267047cdff",
   "metadata": {},
   "source": [
    "## 4.5 在 Transformer 块中连接attention层与线性层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3daac6f-6545-4258-8f2d-f45a7394f429",
   "metadata": {},
   "source": [
    "- 在本节中，我们将把前面介绍的概念整合成一个所谓的 Transformer 块。\n",
    "- Transformer 块将上一章中的因果多头注意力模块与线性层以及我们之前实现的前馈神经网络相结合。\n",
    "- 此外，Transformer 块还包含 Dropout 和残差连接的机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e1e8176-e5e3-4152-b1aa-0bbd7891dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import MultiHeadAttention\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer 块 - GPT 架构的核心组件\n",
    "    \n",
    "    这个模块实现了标准的 Transformer 块结构,包含:\n",
    "    1. 多头自注意力机制 (Multi-Head Self-Attention)\n",
    "    2. 前馈神经网络 (Feed-Forward Network)\n",
    "    3. 层归一化 (Layer Normalization)\n",
    "    4. 残差连接 (Residual Connections)\n",
    "    5. Dropout 正则化\n",
    "    \n",
    "    结构流程:\n",
    "        输入 -> LayerNorm -> MultiHeadAttention -> Dropout -> 残差连接\n",
    "             -> LayerNorm -> FeedForward -> Dropout -> 残差连接 -> 输出\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\"\n",
    "        初始化 Transformer 块\n",
    "        \n",
    "        参数:\n",
    "            cfg: 配置字典,包含以下关键参数:\n",
    "                - emb_dim: 嵌入维度 (例如 768)\n",
    "                - context_length: 上下文长度 (例如 1024)\n",
    "                - n_heads: 注意力头数量 (例如 12)\n",
    "                - drop_rate: Dropout 比例 (例如 0.1)\n",
    "                - qkv_bias: 是否在 Q/K/V 投影中使用偏置\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 多头注意力模块 - 让模型能够关注输入序列中不同位置的信息\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],               # 输入特征维度 (例如 768)\n",
    "            d_out=cfg[\"emb_dim\"],              # 输出特征维度 (保持与输入相同)\n",
    "            context_length=cfg[\"context_length\"],  # 上下文长度 (最大序列长度)\n",
    "            num_heads=cfg[\"n_heads\"],          # 注意力头的数量 (例如 12 个头)\n",
    "            dropout=cfg[\"drop_rate\"],          # 注意力权重的 Dropout 比例\n",
    "            qkv_bias=cfg[\"qkv_bias\"]           # 查询、键和值投影矩阵是否使用偏置\n",
    "        )\n",
    "        \n",
    "        # 前馈神经网络模块 - 对每个位置独立应用的两层全连接网络\n",
    "        # 通常会先扩展维度(例如 768 -> 3072),再压缩回原维度(3072 -> 768)\n",
    "        self.ff = FeedForward(cfg)\n",
    "        \n",
    "        # 第一个层归一化 - 在注意力层之前应用\n",
    "        # 作用: 稳定训练,加速收敛,缓解梯度消失/爆炸问题\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 第二个层归一化 - 在前馈网络之前应用\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 残差连接的 Dropout - 用于正则化,防止过拟合\n",
    "        # 注意: 这个 Dropout 会应用在残差连接的路径上\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        参数:\n",
    "            x: 输入张量,形状为 [batch_size, num_tokens, emb_dim]\n",
    "               例如 [2, 4, 768] 表示 2 个样本,每个样本 4 个 token,每个 token 768 维\n",
    "        \n",
    "        返回:\n",
    "            输出张量,形状与输入相同 [batch_size, num_tokens, emb_dim]\n",
    "        \n",
    "        实现细节:\n",
    "            采用 Pre-LN (Pre-Layer Normalization) 结构:\n",
    "            - 先归一化,再应用子层 (注意力或前馈网络)\n",
    "            - 这种结构比 Post-LN 更稳定,训练更容易\n",
    "        \"\"\"\n",
    "        # ========== 第一个子层: 多头自注意力 + 残差连接 ==========\n",
    "        \n",
    "        # 保存输入作为残差连接的快捷路径\n",
    "        # 这样可以让梯度直接流向前面的层,缓解梯度消失问题\n",
    "        shortcut = x\n",
    "        \n",
    "        # 步骤 1: 层归一化 - 标准化特征分布\n",
    "        # 对最后一个维度 (emb_dim) 进行归一化,使均值为 0,方差为 1\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # 步骤 2: 多头自注意力 - 让每个 token 关注序列中的其他 token\n",
    "        # 输入形状: [batch_size, num_tokens, emb_dim]\n",
    "        # 输出形状: [batch_size, num_tokens, emb_dim] (形状保持不变)\n",
    "        x = self.att(x)\n",
    "        \n",
    "        # 步骤 3: Dropout - 随机丢弃一些神经元,防止过拟合\n",
    "        x = self.drop_shortcut(x)\n",
    "        \n",
    "        # 步骤 4: 残差连接 - 将原始输入加回来\n",
    "        # 这是关键操作: x_out = x_processed + x_original\n",
    "        # 好处: 1) 梯度可以直接流向前面的层  2) 保留原始信息\n",
    "        x = x + shortcut\n",
    "        \n",
    "        # ========== 第二个子层: 前馈神经网络 + 残差连接 ==========\n",
    "        \n",
    "        # 再次保存当前状态作为残差连接的快捷路径\n",
    "        shortcut = x\n",
    "        \n",
    "        # 步骤 5: 层归一化 - 再次标准化特征分布\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        # 步骤 6: 前馈神经网络 - 对每个位置独立应用非线性变换\n",
    "        # 通常结构: Linear(768->3072) -> GELU -> Linear(3072->768)\n",
    "        # 作用: 增加模型的表达能力,引入非线性\n",
    "        x = self.ff(x)\n",
    "        \n",
    "        # 步骤 7: Dropout - 再次应用 Dropout 正则化\n",
    "        x = self.drop_shortcut(x)\n",
    "        \n",
    "        # 步骤 8: 残差连接 - 再次将输入加回来\n",
    "        x = x + shortcut\n",
    "        \n",
    "        # 返回最终输出,形状与输入完全相同\n",
    "        # 这个输出可以看作是\"增强版\"的上下文向量\n",
    "        # 它融合了自注意力机制捕获的全局信息和前馈网络提取的局部特征\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b64d16-94a6-4d13-8c85-9494c50478a9",
   "metadata": {},
   "source": [
    "<img src=\"../image/13.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2d375-87bd-4153-9040-63a1e6a2b7cb",
   "metadata": {},
   "source": [
    "- 假设我们有 2 个输入样本，每个样本包含 6 个标记，每个标记是一个 768 维的嵌入向量；然后，这个 Transformer 块会先应用自注意力机制，再通过线性层处理，生成一个相同尺寸的输出。\n",
    "- 你可以将输出视为我们在上一章讨论的上下文向量的增强版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fb45a63-b1f3-4b08-b525-dafbc8228405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "# ========== 测试 TransformerBlock 的输入输出形状 ==========\n",
    "\n",
    "# 设置随机种子,确保结果可复现\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 创建一个模拟的输入张量\n",
    "# 形状解释:\n",
    "#   - 2: batch_size,表示批次中有 2 个样本\n",
    "#   - 4: num_tokens,表示每个样本有 4 个标记(token)\n",
    "#   - 768: emb_dim,表示每个标记的嵌入维度是 768\n",
    "# 这个张量模拟了经过 token embedding 和 position embedding 后的输入\n",
    "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
    "\n",
    "# 实例化一个 TransformerBlock\n",
    "# 使用 GPT_CONFIG_124M 配置(124M 参数的 GPT-2 模型配置)\n",
    "# 这个 block 包含:\n",
    "#   1. 多头自注意力层(MultiHeadAttention)\n",
    "#   2. 前馈神经网络(FeedForward)\n",
    "#   3. 两个层归一化(LayerNorm)\n",
    "#   4. 两个残差连接\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "\n",
    "# 将输入传递给 TransformerBlock,得到输出\n",
    "# 内部流程:\n",
    "#   x -> LayerNorm -> MultiHeadAttention -> Dropout -> 残差连接\n",
    "#   -> LayerNorm -> FeedForward -> Dropout -> 残差连接 -> output\n",
    "output = block(x)\n",
    "\n",
    "# 打印输入和输出的形状\n",
    "# 关键观察: 输入和输出的形状完全相同!\n",
    "# 这是 Transformer 架构的重要特性 - 形状保持不变\n",
    "print(\"Input shape:\", x.shape)      # 预期输出: torch.Size([2, 4, 768])\n",
    "print(\"Output shape:\", output.shape) # 预期输出: torch.Size([2, 4, 768])\n",
    "\n",
    "# 这个测试验证了:\n",
    "# 1. TransformerBlock 可以正确处理批量输入\n",
    "# 2. 输出形状与输入形状一致,可以堆叠多个 block\n",
    "# 3. 每个 token 的表示从 768 维输入变成 768 维输出(维度不变,但内容已被增强)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e4ee4-cf23-4583-b1fd-317abb4fcd13",
   "metadata": {},
   "source": [
    "<img src=\"../image/14.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46618527-15ac-4c32-ad85-6cfea83e006e",
   "metadata": {},
   "source": [
    "## 4.6 编码GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7d03d-9ff3-4ca3-ad67-01b67c2f5457",
   "metadata": {},
   "source": [
    "- 终于要结束了：现在让我们将 Transformer 块插入到本章开头编写的架构中，这样就可以得到一个可用的 GPT 架构。\n",
    "- 请注意，Transformer 块会重复多次；对于最小的 124M GPT-2 模型来说，我们会重复 12 次。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7b362d-f8c5-48d2-8ebd-722480ac5073",
   "metadata": {},
   "source": [
    "<img src=\"../image/15.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e4b5d-ed89-4fdf-9a52-67deee0593bc",
   "metadata": {},
   "source": [
    "- 对应的代码实现，其中 `cfg[\"n_layers\"] = 12`："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4e972-a13b-4733-9cf4-f54c882870cf",
   "metadata": {},
   "source": [
    "- (译者)一点语法小知识\n",
    "在 Python 中，* 是 解包操作符，用于将一个可迭代对象（如列表、元组）中的元素逐一解包成单独的参数。\n",
    "在 PyTorch 中，nn.Sequential 接受一组模块作为输入，而不是一个列表或其他容器。\n",
    "这里使用 * 将生成的 TransformerBlock 列表解包为独立的参数传递给 nn.Sequential。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c61de39c-d03c-4a32-8b57-f49ac3834857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):  # GPT 模型的完整实现\n",
    "    \"\"\"\n",
    "    GPT (Generative Pre-trained Transformer) 模型\n",
    "    \n",
    "    这是一个完整的 GPT 架构实现,包含:\n",
    "    1. Token 嵌入层 (tok_emb): 将词汇表中的 token ID 转换为向量表示\n",
    "    2. 位置嵌入层 (pos_emb): 为每个 token 添加位置信息\n",
    "    3. Dropout 层 (drop_emb): 防止过拟合\n",
    "    4. Transformer 块堆叠 (trf_blocks): 核心的自注意力和前馈网络层\n",
    "    5. 最终归一化层 (final_norm): 稳定输出\n",
    "    6. 输出投影层 (out_head): 将嵌入向量映射回词汇表大小\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\"\n",
    "        初始化 GPT 模型\n",
    "        \n",
    "        参数:\n",
    "            cfg: 配置字典,包含以下关键参数:\n",
    "                - vocab_size: 词汇表大小 (例如 50257)\n",
    "                - emb_dim: 嵌入维度 (例如 768)\n",
    "                - context_length: 最大序列长度 (例如 1024)\n",
    "                - drop_rate: Dropout 比率 (例如 0.1)\n",
    "                - n_layers: Transformer 块的数量 (例如 12)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Token 嵌入层: 将 token ID (整数) 映射为 emb_dim 维的向量\n",
    "        # 例如: vocab_size=50257, emb_dim=768\n",
    "        # 输入形状: [batch_size, seq_len] (整数索引)\n",
    "        # 输出形状: [batch_size, seq_len, emb_dim]\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 2. 位置嵌入层: 为序列中的每个位置学习一个固定的向量表示\n",
    "        # context_length 是模型能处理的最大序列长度\n",
    "        # 位置 0, 1, 2, ... 各有一个可学习的 emb_dim 维向量\n",
    "        # 输入: 位置索引 [0, 1, 2, ..., seq_len-1]\n",
    "        # 输出形状: [seq_len, emb_dim]\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 3. Dropout 层: 在训练时随机将一部分神经元输出置零,防止过拟合\n",
    "        # drop_rate 控制丢弃的比例 (例如 0.1 表示丢弃 10%)\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # 4. Transformer 块堆叠: 这是 GPT 的核心部分\n",
    "        # 使用列表推导式创建 n_layers 个 TransformerBlock\n",
    "        # * 操作符将列表解包为独立参数传递给 nn.Sequential\n",
    "        # 例如: n_layers=12 时,会创建 12 个 TransformerBlock 依次执行\n",
    "        # 每个 block 包含: 多头注意力 + 前馈网络 + 残差连接 + LayerNorm\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # 注意: 下面这段重复定义的代码会覆盖上面的 self.trf_blocks\n",
    "        # 这里只创建了 3 个 TransformerBlock,可能是用于调试或演示\n",
    "        # 在实际使用中应该删除这段代码,使用上面的动态创建版本\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            TransformerBlock(cfg),  # 第 1 个 Transformer 块\n",
    "            TransformerBlock(cfg),  # 第 2 个 Transformer 块\n",
    "            TransformerBlock(cfg)   # 第 3 个 Transformer 块\n",
    "        )\n",
    "        \n",
    "        # 5. 最终的 Layer Normalization: 在输出前对特征进行归一化\n",
    "        # 作用: 稳定训练,加速收敛,减少梯度消失/爆炸问题\n",
    "        # 对最后一个维度 (emb_dim) 进行归一化\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        \n",
    "        # 6. 输出投影层: 将 emb_dim 维的向量映射回 vocab_size 维\n",
    "        # 这样可以为词汇表中的每个 token 计算一个分数 (logit)\n",
    "        # bias=False: 不使用偏置项 (GPT-2 的标准做法)\n",
    "        # 输入形状: [batch_size, seq_len, emb_dim]\n",
    "        # 输出形状: [batch_size, seq_len, vocab_size]\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        \"\"\"\n",
    "        前向传播函数: 将输入的 token 索引转换为输出 logits\n",
    "        \n",
    "        参数:\n",
    "            in_idx: 输入的 token 索引张量\n",
    "                   形状: [batch_size, seq_len]\n",
    "                   例如: [[15496, 11, 314, 1101], [262, 1218, 286, 257]]\n",
    "        \n",
    "        返回:\n",
    "            logits: 每个位置对词汇表中每个 token 的未归一化分数\n",
    "                   形状: [batch_size, seq_len, vocab_size]\n",
    "                   可以通过 softmax 转换为概率分布\n",
    "        \n",
    "        处理流程:\n",
    "            输入 token IDs → Token 嵌入 → 加上位置嵌入 → Dropout \n",
    "            → Transformer 块堆叠 → LayerNorm → 输出投影 → Logits\n",
    "        \"\"\"\n",
    "        # 获取批次大小和序列长度\n",
    "        # 例如: in_idx.shape = [2, 4] 表示 2 个样本,每个样本 4 个 token\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        \n",
    "        # 步骤 1: 将 token ID 转换为嵌入向量\n",
    "        # 输入: [batch_size, seq_len] 的整数索引\n",
    "        # 输出: [batch_size, seq_len, emb_dim] 的浮点数向量\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        # 步骤 2: 生成位置嵌入\n",
    "        # torch.arange(seq_len) 创建 [0, 1, 2, ..., seq_len-1]\n",
    "        # device=in_idx.device 确保位置索引与输入在同一设备 (CPU/GPU)\n",
    "        # 输出: [seq_len, emb_dim] 的位置向量\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        \n",
    "        # 步骤 3: 将 token 嵌入和位置嵌入相加\n",
    "        # pos_embeds 会自动广播到 [batch_size, seq_len, emb_dim]\n",
    "        # 这样每个 token 的表示就同时包含了\"内容信息\"和\"位置信息\"\n",
    "        # 形状: [batch_size, seq_len, emb_dim]\n",
    "        x = tok_embeds + pos_embeds\n",
    "        \n",
    "        # 步骤 4: 应用 Dropout 正则化\n",
    "        # 在训练时随机丢弃一些神经元,防止过拟合\n",
    "        # 在推理时不起作用 (model.eval() 模式下)\n",
    "        x = self.drop_emb(x)\n",
    "        \n",
    "        # 步骤 5: 通过所有 Transformer 块进行处理\n",
    "        # 每个块都会应用自注意力机制和前馈网络\n",
    "        # 输入和输出形状保持不变: [batch_size, seq_len, emb_dim]\n",
    "        x = self.trf_blocks(x)\n",
    "        \n",
    "        # 步骤 6: 最终的 Layer Normalization\n",
    "        # 对输出进行归一化,稳定数值范围\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        # 步骤 7: 通过输出层投影到词汇表空间\n",
    "        # 将 emb_dim 维的向量映射为 vocab_size 维的 logits\n",
    "        # logits[i, j, k] 表示第 i 个样本的第 j 个位置预测第 k 个 token 的分数\n",
    "        # 形状: [batch_size, seq_len, vocab_size]\n",
    "        logits = self.out_head(x)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750270f-c45d-4410-8767-a6adbd05d5c3",
   "metadata": {},
   "source": [
    "- 用了124M模型的原始参数,我们接下啦要初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef94fd9c-4e9d-470d-8f8e-dd23d1bb1f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1288, -0.0010, -0.8699,  ..., -0.0127, -0.3599,  0.0275],\n",
      "         [ 0.5068, -0.2318,  0.2832,  ..., -0.5274,  0.0906, -0.7593],\n",
      "         [ 1.0905, -0.6728, -0.8097,  ...,  0.7395,  0.4309, -0.2174],\n",
      "         [-0.9789, -0.2985,  0.1336,  ..., -0.4023,  0.0093,  0.1462]],\n",
      "\n",
      "        [[-0.1734, -0.3146, -0.5338,  ..., -0.0521, -0.0971,  0.1293],\n",
      "         [ 0.8129,  0.1875, -0.1978,  ...,  0.8638,  0.0565, -0.9834],\n",
      "         [ 0.7845, -0.3407,  0.1625,  ..., -0.2429,  0.1776, -0.4528],\n",
      "         [ 0.0278,  0.4425, -0.2536,  ...,  0.5252,  0.4567,  0.2523]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)\n",
    "#经典操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d616e7a-568b-4921-af29-bd3f4683cd2e",
   "metadata": {},
   "source": [
    "- 我们将在下一章训练这个模型。\n",
    "- 但关于其规模需要补充一点：我们之前提到它是一个拥有 1.24 亿参数的模型；我们可以通过以下方式再次确认这个数字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84fb8be4-9d3b-402b-b3da-86b663aac33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 99,239,424\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数数量\n",
    "# model.parameters() 返回模型中所有可训练参数的迭代器\n",
    "# p.numel() 返回每个参数张量中元素的总数（number of elements）\n",
    "# 例如：一个形状为 [768, 50257] 的权重矩阵有 768 * 50257 = 38,597,376 个参数\n",
    "# sum() 将所有层的参数数量累加起来，得到模型的总参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# 打印总参数数量\n",
    "# :, 格式化符号会在数字中添加千位分隔符，使大数字更易读\n",
    "# 例如：163009536 会显示为 163,009,536\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d13dd-dd01-4ba6-a2ad-31ca8a9fd660",
   "metadata": {},
   "source": [
    "- 正如我们上面看到的，这个模型实际上有 1.63 亿参数，而不是 1.24 亿；这是为什么呢？\n",
    "- 在原始 GPT-2 论文中，研究人员采用了**权重共享**（weight tying）技术，即将标记嵌入层（`tok_emb`）作为输出层复用，具体表现为设置 `self.out_head.weight = self.tok_emb.weight`。\n",
    "- 标记嵌入层将 50,257 维的独热编码输入标记映射到 768 维的嵌入表示。\n",
    "- 输出层则将 768 维的嵌入表示映射回 50,257 维的表示，从而可以将其还原为单词（关于这一点，我们将在下一节详细讨论）。\n",
    "- 因此，嵌入层和输出层的权重参数数量相同，从它们权重矩阵的形状可以看出这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3b43233-e9b8-4f5a-b72b-a263ec686982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)\n",
    "#输出格式让我们更好地理解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02259f6-6f79-4c89-a866-4ebeae1c3289",
   "metadata": {},
   "source": [
    "- 在原始 GPT-2 论文中，研究人员将标记嵌入矩阵复用为输出矩阵。\n",
    "- 相应地，如果我们减去输出层的参数数量，就会得到一个拥有 1.24 亿参数的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95a22e02-50d3-48b3-a4e0-d9863343c164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 60,642,048\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")\n",
    "#Parameter- sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b03f80-b94c-46e7-9d42-d0df399ff3db",
   "metadata": {},
   "source": [
    "- 在实际应用中，因为不使用权重共享更容易训练模型，所以这里没有进行权重共享。\n",
    "- 不过，在第 5 章加载预训练权重时，我们将重新讨论并应用权重共享的概念。\n",
    "- 最后，我们可以通过以下方式计算模型的内存需求，这可能是一个有用的参考点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5131a752-fab8-4d70-a600-e29870b33528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 378.57 MB\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总内存占用（以字节为单位）\n",
    "# 假设模型使用 float32 数据类型存储参数，每个参数占用 4 字节\n",
    "# float32 是深度学习中最常用的数据类型：\n",
    "#   - float16（半精度）：2 字节/参数\n",
    "#   - float32（单精度）：4 字节/参数\n",
    "#   - float64（双精度）：8 字节/参数\n",
    "# 因此，总字节数 = 参数总数 × 每个参数的字节数\n",
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# 将字节转换为兆字节（MB），便于理解模型大小\n",
    "# 转换公式：1 MB = 1024 KB = 1024 × 1024 字节 = 1,048,576 字节\n",
    "# 例如：如果 total_params = 163,009,536，则：\n",
    "#   total_size_bytes = 163,009,536 × 4 = 652,038,144 字节\n",
    "#   total_size_mb = 652,038,144 / 1,048,576 ≈ 621.83 MB\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "# 打印模型的总大小（以 MB 为单位）\n",
    "# :.2f 格式化符号表示保留两位小数\n",
    "# 这个大小仅包含模型参数本身，不包括：\n",
    "#   - 训练时的梯度（需要额外相同大小的内存）\n",
    "#   - 优化器状态（如 Adam 需要额外 2 倍参数大小的内存）\n",
    "#   - 激活值（前向传播时的中间结果）\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a3be4-c20a-4657-b4e0-77c97510b47c",
   "metadata": {},
   "source": [
    "- **练习**：你可以尝试以下其他配置，这些配置参考自 [GPT-2 论文](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dOad5HoAAAAJ&citation_for_view=dOad5HoAAAAJ:YsMSGLbcyi4C)。\n",
    "\n",
    "    - **GPT2-small**（我们已经实现的 124M 配置）：\n",
    "        - `\"emb_dim\" = 768`\n",
    "        - `\"n_layers\" = 12`\n",
    "        - `\"n_heads\" = 12`\n",
    "\n",
    "    - **GPT2-medium**：\n",
    "        - `\"emb_dim\" = 1024`\n",
    "        - `\"n_layers\" = 24`\n",
    "        - `\"n_heads\" = 16`\n",
    "\n",
    "    - **GPT2-large**：\n",
    "        - `\"emb_dim\" = 1280`\n",
    "        - `\"n_layers\" = 36`\n",
    "        - `\"n_heads\" = 20`\n",
    "\n",
    "    - **GPT2-XL**：\n",
    "        - `\"emb_dim\" = 1600`\n",
    "        - `\"n_layers\" = 48`\n",
    "        - `\"n_heads\" = 25`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d9bc0-95ab-45d4-9378-417628d86e35",
   "metadata": {},
   "source": [
    "## 4.7 文本生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48da5deb-6ee0-4b9b-8dd2-abed7ed65172",
   "metadata": {},
   "source": [
    "- GPT架构的LLM一次只能生成一个单词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caade12a-fe97-480f-939c-87d24044edff",
   "metadata": {},
   "source": [
    "<img src=\"../image/16.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7061524-a3bd-4803-ade6-2e3b7b79ac13",
   "metadata": {},
   "source": [
    "- 以下的 `generate_text_simple` 函数实现了贪心解码（greedy decoding），这是一种简单且快速的文本生成方法。\n",
    "- 在贪心解码中，模型在每一步选择具有最高概率的词（或标记）作为下一个输出（由于最高的 logit 值对应最高的概率，实际上我们不需要显式地计算 softmax 函数）。\n",
    "- 在下一章，我们将实现一个更为复杂的 `generate_text` 函数。\n",
    "- 下图展示了给定输入上下文时，GPT 模型是如何生成下一个词标记的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0f32c-c18c-445e-b294-a879de2aa187",
   "metadata": {},
   "source": [
    "<img src=\"../image/17.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9b428a9-8764-4b36-80cd-7d4e00595ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # 预测单词的模块\n",
    "    # idx 是当前上下文中的（batch, n_tokens）索引数组\n",
    "    for _ in range(max_new_tokens):\n",
    "        # 每次生成一个单词后，重新将其加入序列中\n",
    "        # 如果当前上下文长度超过模型支持的最大上下文长度，则截取\n",
    "        # 例如，如果LLM只支持5个token，而上下文长度为10\n",
    "        # 那么只使用最后5个token作为上下文\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        # 如果idx的长度超过模型支持的上下文长度size，只保留最后size个token\n",
    "        # 避免溢出\n",
    "        # 获取预测结果\n",
    "        with torch.no_grad():  # 在推理阶段，不需要计算梯度，因为没有反向传播\n",
    "            # 这样可以减少存储开销\n",
    "            logits = model(idx_cond)\n",
    "            # 模型输出结果\n",
    "        # 只关注最后一个时间步的输出\n",
    "        # (batch, n_tokens, vocab_size) 变为 (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]\n",
    "        # 关注最后一个时间步\n",
    "        # 使用softmax函数计算概率\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "        # 归一化\n",
    "        # 获取具有最高概率值的词汇索引\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "        # 获取概率最高的词汇索引\n",
    "        # 将采样的索引添加到序列中\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515f2c1-3cc7-421c-8d58-cc2f563b7030",
   "metadata": {},
   "source": [
    "- 上面的 `generate_text_simple` 实现了一个迭代过程，其中它一次生成一个token。\n",
    "\n",
    "<img src=\"../image/18.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f682eac4-f9bd-438b-9dec-6b1cc7bc05ce",
   "metadata": {},
   "source": [
    "- 举个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d7e3e94-df0f-4c0f-a6a1-423f500ac1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 定义起始上下文文本（模型生成的起点）\n",
    "start_context = \"Hello, I am\"\n",
    "\n",
    "# 步骤1: 将文本编码为token ID序列\n",
    "# tokenizer.encode() 会将输入字符串转换为整数列表\n",
    "# 例如: \"Hello, I am\" -> [15496, 11, 314, 716]\n",
    "# 每个整数对应词汇表中的一个token\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "# 输出示例: encoded: [15496, 11, 314, 716]\n",
    "\n",
    "# 步骤2: 将Python列表转换为PyTorch张量，并添加批次维度\n",
    "# torch.tensor(encoded) 将列表转为1维张量，形状为 (n_tokens,)\n",
    "# unsqueeze(0) 在第0维添加批次维度，形状变为 (1, n_tokens)\n",
    "# 这是因为模型期望输入格式为 (batch_size, sequence_length)\n",
    "# 即使只处理一个样本，也需要批次维度\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "# 输出示例: encoded_tensor.shape: torch.Size([1, 4])\n",
    "# 表示批次大小为1，序列长度为4个token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a72a9b60-de66-44cf-b2f9-1e638934ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 37418,  5604, 14311,  6900, 24252,  7098]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "# 步骤3: 将模型设置为评估模式\n",
    "# model.eval() 会禁用 dropout 和 batch normalization 的训练行为\n",
    "# 在推理/生成阶段,我们不需要随机丢弃神经元(dropout),需要模型的确定性输出\n",
    "# 这确保每次运行生成的结果是一致的(给定相同的输入和模型参数)\n",
    "model.eval()\n",
    "\n",
    "# 步骤4: 调用文本生成函数\n",
    "# 使用我们之前定义的 generate_text_simple 函数来生成新的token\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    # 参数说明: model 是我们要使用的 GPT 模型实例\n",
    "    # 左边是函数定义中的参数名,右边是我们传入的实际对象\n",
    "    \n",
    "    idx=encoded_tensor,\n",
    "    # idx 是输入的上下文token序列,形状为 (1, 4)\n",
    "    # 这是模型生成的起点,模型会基于这个上下文继续生成\n",
    "    \n",
    "    max_new_tokens=6,\n",
    "    # 指定要生成的新token数量\n",
    "    # 模型会迭代6次,每次生成1个token\n",
    "    # 最终输出长度 = 初始上下文长度(4) + 新生成的token数(6) = 10\n",
    "    \n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "    # 指定模型的上下文窗口大小(本例中为256)\n",
    "    # 这是模型在生成每个新token时能\"看到\"的最大历史token数\n",
    "    # 如果生成的序列超过这个长度,只会使用最近的 context_length 个token\n",
    ")\n",
    "\n",
    "# 步骤5: 打印生成结果\n",
    "print(\"Output:\", out)\n",
    "# 输出完整的token ID张量,形状为 (1, 10)\n",
    "# 包含原始的4个输入token + 新生成的6个token\n",
    "\n",
    "print(\"Output length:\", len(out[0]))\n",
    "# 打印第一个(也是唯一一个)批次样本的序列长度\n",
    "# out[0] 移除批次维度后得到形状为 (10,) 的张量\n",
    "# len() 返回序列中token的总数,应该是 10\n",
    "# 注意: 这里的长度是token ID的数量,不是字符或单词的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d131c00-1787-44ba-bec3-7c145497b2c3",
   "metadata": {},
   "source": [
    "- 去除批次维度并将其转换回文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "053d99f6-5710-4446-8d52-117fb34ea9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I amrievingourneyAmongersioninasrazil\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a894003-51f6-4ccc-996f-3b9c7d5a1d70",
   "metadata": {},
   "source": [
    "- 请注意，目前模型尚未经过训练，因此上述输出文本是随机的。\n",
    "- 我们将在下一章中训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35278b6-9e5c-480f-83e5-011a1173648f",
   "metadata": {},
   "source": [
    "## 总结与收获\n",
    "\n",
    "- 请查看 [./gpt.py](./gpt.py) 脚本，这是一个独立的脚本，包含了我们在此 Jupyter Notebook 中实现的 GPT 模型。\n",
    "- 练习题的解答可以在 [./exercise-solutions.ipynb](./exercise-solutions.ipynb) 中找到。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
