{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45398736-7e89-4263-89c8-92153baff553",
      "metadata": {},
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "<br>汉化的库: <a href=\"https://github.com/GoatCsu/CN-LLMs-from-scratch.git\">https://github.com/GoatCsu/CN-LLMs-from-scratch.git</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"../image/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
      "metadata": {
        "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
      },
      "source": [
        "# 第五章: 在无标签数据集上预训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "92b989e9-da36-4159-b212-799184764dd9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "matplotlib version: 3.10.8\n",
            "numpy version: 1.26.4\n",
            "tiktoken version: 0.12.0\n",
            "torch version: 2.10.0\n",
            "tensorflow version: 2.20.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\", \n",
        "        \"numpy\", \n",
        "        \"tiktoken\", \n",
        "        \"torch\",\n",
        "        \"tensorflow\" # For OpenAI's pretrained weights\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")\n",
        "#同样导入库并检查版本"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
      "metadata": {},
      "source": [
        "- 在本章中，我们将实现循环训练和基本模型评价的代码，用于预训练大语言模型。\n",
        "- 在本章的最后，我们还将从 OpenAI 加载公开可用的预训练权重到我们的模型中。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
      "metadata": {},
      "source": [
        "<img src=\"../image/chapter-overview.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d214765-7a73-42d5-95e9-302154b29db9",
      "metadata": {},
      "source": [
        "- 本章节涉及的主题如下所示"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
      "metadata": {},
      "source": [
        "<img src=\"../image/mental-model--0.webp\" width=400px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
      "metadata": {
        "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
      },
      "source": [
        "## 5.1 评估文本生成大模型"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
      "metadata": {},
      "source": [
        "- 本节开始时，我们简要回顾了如何使用上一章的代码初始化 GPT 模型。\n",
        "- 然后，我们讨论了大语言模型的基本评估指标。\n",
        "- 最后，在本节中，我们将这些评估指标应用于训练和验证数据集。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
      "metadata": {
        "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
      },
      "source": [
        "### 5.1.1 用GPT来生成文本"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
      "metadata": {},
      "source": [
        "- 我们首先与前几章一样初始化GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "86000d74-624a-48f0-86da-f41926cb9e04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86000d74-624a-48f0-86da-f41926cb9e04",
        "outputId": "ad482cfd-5a62-4f0d-e1e0-008d6457f512"
      },
      "outputs": [],
      "source": [
        "# 导入 PyTorch 库,用于构建和训练神经网络\n",
        "import torch\n",
        "# 从前面章节的代码中导入 GPTModel 类(在 previous_chapters 模块中定义)\n",
        "from previous_chapters import GPTModel\n",
        "\n",
        "# 定义 GPT-2 124M(1.24亿参数)模型的配置字典\n",
        "# 这个配置决定了模型的架构和规模\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # 词汇表大小:GPT-2 使用的 BPE 词汇表包含 50257 个 token\n",
        "    \"context_length\": 256, # 上下文长度(最大序列长度):为了节省计算资源缩短为 256(原始 GPT-2 为 1024)\n",
        "    \"emb_dim\": 768,        # 嵌入维度:每个 token 的向量表示维度,也是模型的隐藏层维度\n",
        "    \"n_heads\": 12,         # 注意力头数量:多头注意力机制中的头数(emb_dim 必须能被 n_heads 整除)\n",
        "    \"n_layers\": 12,        # Transformer 层数:模型堆叠的 Transformer 块数量\n",
        "    \"drop_rate\": 0.1,      # Dropout 比率:训练时随机丢弃神经元的比例,用于防止过拟合(现代 LLM 通常不用)\n",
        "    \"qkv_bias\": False      # Query-Key-Value 偏置:是否在注意力机制的 QKV 线性层中使用偏置项(现代 LLM 通常设为 False)\n",
        "}\n",
        "\n",
        "# 设置 PyTorch 的随机种子为 123,确保模型初始化的权重可复现\n",
        "# 这样每次运行代码时,模型的初始参数都是相同的,便于调试和对比实验\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 使用上面定义的配置字典实例化 GPT 模型\n",
        "# GPTModel 会根据配置创建包含嵌入层、多个 Transformer 块和输出层的完整模型\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 将模型设置为评估模式(evaluation mode)\n",
        "# 这会禁用 Dropout 和 BatchNorm 等训练时特有的行为,确保推理时的确定性输出\n",
        "model.eval();  # 注意:分号是为了在 Jupyter 中抑制输出\n",
        "# 总结:导入模型类,设定模型架构参数,设定随机种子确保可复现,并初始化为评估模式"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
      "metadata": {},
      "source": [
        "- 我们在上述代码中使用了 0.1 的 dropout 率，但如今训练大语言模型时通常不使用 dropout。\n",
        "- 现代的大语言模型不在 `nn.Linear` 层的查询、键和值矩阵中使用偏置向量（与早期的 GPT 模型不同），而是通过设置 `\"qkv_bias\": False` 实现。\n",
        "- 我们将上下文长度（`context_length`）减少到仅 256 个 token，以减少训练模型时的计算资源需求，而原始的 1.24 亿参数的 GPT-2 模型使用了 1024 个token。\n",
        "  - 这是为了让更多读者可以在他们的笔记本电脑上运行并跟随代码示例。\n",
        "  - 然而，您可以自由将 `context_length` 增加到 1024 个 token（这不需要更改任何代码）。\n",
        "  - 我们稍后也将从预训练权重中加载一个具有 1024 `context_length` 的模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
      "metadata": {},
      "source": [
        "- 接下来，我们使用上一章中的 `generate_text_simple` 函数生成文本。\n",
        "- 此外，我们定义了两个便利函数，`text_to_token_ids` 和 `token_ids_to_text`，用于在 token ID 和文本表示之间进行转换，这两个函数将在本章中多次使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
      "metadata": {},
      "source": [
        "<img src=\"../image/gpt-process.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ],
      "source": [
        "import tiktoken  # 导入 tiktoken 作为 GPT-2 的分词器(BPE tokenizer)实现\n",
        "from previous_chapters import generate_text_simple  # 导入上一章实现的简易文本生成函数\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    \"\"\"\n",
        "    将字符串文本转换为模型可接受的 token ID 张量。\n",
        "    Args:\n",
        "        text (str): 输入文本，例如 \"hello world\"\n",
        "        tokenizer: 分词器对象(tiktoken)，用于编码字符串为 token ids\n",
        "    Returns:\n",
        "        Tensor: 形状为 [1, seq_len] 的 Long Tensor，作为模型的输入（包含 batch 维度）\n",
        "    \"\"\"\n",
        "    # allowed_special={'<|endoftext|>'} 允许编码时捕获 GPT 特殊终止符（更完整地模拟 GPT-2 的处理方式）\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    # 转为 tensor，并增加 batch 维度（模型输入形状需为 [B, T]）\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # unsqueeze(0) 在最前面加一维\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    \"\"\"\n",
        "    将 token ID 张量还原为对应的字符串文本。\n",
        "    Args:\n",
        "        token_ids (Tensor): [1, seq_len] 或 [seq_len] 形状的 token id 张量\n",
        "        tokenizer: 分词器对象(tiktoken)，用于将 token ids 解码为字符串\n",
        "    Returns:\n",
        "        str: 解码后的自然语言文本\n",
        "    \"\"\"\n",
        "    # squeeze(0) 移除 batch 维度 [1, T] -> [T]，得到一维 token id 列表\n",
        "    flat = token_ids.squeeze(0)\n",
        "    # 解码为字符串文本\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "# 示例起始上下文\n",
        "start_context = \"Every effort moves you\"\n",
        "\n",
        "# 实例化 GPT-2 的分词器 (BPE)；\"gpt2\" 标识选择与官方模型一致的词表和规则\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")  # tiktoken 官方 推荐 API\n",
        "\n",
        "# 用 generate_text_simple 生成新的 token id 序列\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),  # 初始 token id 张量(含 batch 维度)\n",
        "    max_new_tokens=10,                                # 限定最多自动生成 10 个新 token\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]     # 指定模型当前支持的最大上下文序列长度\n",
        ")\n",
        "\n",
        "# 将模型输出的 token id 张量反解码为人类可读的文本并输出\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
      "metadata": {},
      "source": [
        "- 如上所示，由于模型尚未训练，它生成的文本并不理想。\n",
        "- 我们如何衡量或设定“好文本”的标准，并将其转化为数值，以便在训练过程中进行跟踪？\n",
        "- 下一小节介绍了计算生成输出的损失指标的度量标准，我们可以用它来衡量训练进度。\n",
        "- 后续关于微调大语言模型的章节还将介绍其他衡量模型质量的方法。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
      "metadata": {
        "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
      },
      "source": [
        "### 5.1.2 计算文本生成的损失：交叉熵(cross- entropy)和困惑度(perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
      "metadata": {},
      "source": [
        "- 假设我们有一个 `inputs` 张量，其中包含 2 个训练示例（行）的 token ID。\n",
        "- 与 `inputs` 对应，`targets` 包含我们希望模型生成的目标 token ID。\n",
        "- 请注意，`targets` 是将 `inputs` 向右移动 1 个位置后的结果，正如我们在第二章实现数据加载器时所解释的那样。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
        "outputId": "8d6fa0ff-7b37-4634-c3f0-2c050cbe81f0"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "#用向量的形式展现输入的文本\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]\n",
        "#用向量的形式展现要输出的东西"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
      "metadata": {},
      "source": [
        "- 将 `inputs` 输入给模型后，我们将得到 2 个输入示例的 logits 向量，每个输入示例包含 3 个token。\n",
        "- 每个 token 都是一个 50,257 维的向量，对应于词汇表的大小。\n",
        "- 通过应用 softmax 函数，我们可以将 logits 张量转换为一个相同维度的张量，其中包含概率得分。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "# 在计算 logits 时，我们不需要进行梯度反向传播，因此使用 torch.no_grad() 来加速计算，并节省内存\n",
        "with torch.no_grad():\n",
        "    # 将输入输入进模型，获得每个 token 的输出 logits\n",
        "    # logits 的维度为 (batch_size, num_tokens, vocab_size)\n",
        "    # 其中 batch_size = 输入的样本数，num_tokens = 每条输入的 token 数量，vocab_size = 词表大小(50257)\n",
        "    logits = model(inputs)\n",
        "\n",
        "# 对 logits 的最后一维（词表维度）应用 softmax，得到属于词表中每个 token 的预测概率\n",
        "# 结果 probas 的形状同 logits: (batch_size, num_tokens, vocab_size)\n",
        "probas = torch.softmax(logits, dim=-1)  # 每个 token 在词表中每个词的概率分布\n",
        "\n",
        "# 输出概率张量的形状，以便确认维度理解：应为 (批次数, token 数量, 词表大小)\n",
        "print(probas.shape)  # 输出: (batch_size, num_tokens, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
      "metadata": {},
      "source": [
        "- 下图展示了我们如何将概率得分转换为文本，示例使用了一个非常小的词汇表，这一内容已在上一章的结尾讨论过。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
      "metadata": {},
      "source": [
        "<img src=\"../image/proba-to-text.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8480efd-d419-4954-9ecc-2876055334bd",
      "metadata": {},
      "source": [
        "- 如上一章所讨论的，我们可以应用 `argmax` 函数将概率得分转换为预测的 token ID。\n",
        "- 上面的 softmax 函数为每个 token 生成了一个 50,257 维的向量；`argmax` 函数返回该向量中概率得分最高的位置，即给定 token 的预测 token ID。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
      "metadata": {},
      "source": [
        "- 由于我们有 2 个输入批次，每个批次包含 3 个 token，因此我们得到 2 行 3 列的预测 token ID："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
        "outputId": "ed17da47-c3e7-4775-fd00-4ec5bcda3db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ],
      "source": [
        "# 使用 torch.argmax 在最后一个维度（即词表维度）上选取概率最大的位置，该位置对应于概率最高的 token 的词表索引（token ID）。\n",
        "# keepdim=True 保持输出张量在该维度上的形状，以便后续处理时形状一致。\n",
        "# 这一步相当于“贪心解码”：对每个输入文本的每个 token 位置，选择概率最高的 token，作为模型当前时刻的输出。\n",
        "# 例如，对于批量输入为 (batch_size, num_tokens, vocab_size) 的 probas，\n",
        "# 最终输出的 token_ids 是形状为 (batch_size, num_tokens, 1) 的张量。\n",
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "\n",
        "# 打印出每个输入（batch）中每个 token 的预测 token ID（即词表索引）。\n",
        "# 这些 token_ids 可以用于解码为对应的文本内容。\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee4072c-21ed-4df7-8721-dd2535362573",
      "metadata": {},
      "source": [
        "- 如果解码这些 token，我们会发现它们与希望模型预测的 token (目标 token)有很大不同："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  Armed heNetflix\n"
          ]
        }
      ],
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "#给出答案\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
        "#给出事实上的结论"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
      "metadata": {},
      "source": [
        "- 这是因为模型还没有经过训练。\n",
        "- 要训练模型，我们需要知道它与正确预测（目标）之间的差距有多大。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
      "metadata": {},
      "source": [
        "<img src=\"../image/proba-index.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7251bf5-a079-4782-901d-68c9225d3157",
      "metadata": {},
      "source": [
        "- 对应于目标索引的 token 概率如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
        "outputId": "41c946a2-c458-433e-a53d-5e7e89d9dddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
            "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
          ]
        }
      ],
      "source": [
        "# 下面我们希望找出模型针对每个输入文本（batch）在每个 token 位置上，预测目标 token（targets）时给出的概率值\n",
        "# 假设我们有 probas，其形状为 (2, 3, vocab_size)\n",
        "# 其中，2 表示批大小（有2句话），3 表示每个句子3个 token，vocab_size 是词表大小\n",
        "\n",
        "# 首先选择第一个 batch，对应 text 1\n",
        "text_idx = 0  # 当前处理第一个输入文本（batch）\n",
        "# probas[text_idx, [0, 1, 2], targets[text_idx]] 的意思是：\n",
        "# - 取出第一个文本（batch）中的每个位置（token 0, 1, 2），\n",
        "# - 对于每个位置，取出目标 token（targets[text_idx]）对应的概率（targets[text_idx] 形状为(3,)）\n",
        "# 这样能得到该 batch 内每个 token 的目标概率\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "# 等价效果（逐位置取“正确目标 token”的概率）:\n",
        "# target_probas_1 = torch.tensor([\n",
        "#     probas[text_idx, 0, targets[text_idx][0]],\n",
        "#     probas[text_idx, 1, targets[text_idx][1]],\n",
        "#     probas[text_idx, 2, targets[text_idx][2]],\n",
        "# ])\n",
        "print(\"Text 1:\", target_probas_1)  # 输出第一个输入文本每个 token 的“正确 token”概率值\n",
        "\n",
        "# 同理，处理第二个 batch，对应 text 2\n",
        "text_idx = 1  # 当前处理第二个输入文本（batch）\n",
        "# 使用同样方式，取出第二个文本每个 token 的“正确 token”概率值\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)  # 输出第二个输入文本每个 token 的“正确 token”概率值"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
      "metadata": {},
      "source": [
        "- 我们希望最大化这些值，使它们的概率接近 1。\n",
        "- 在数学优化中，最大化概率得分的对数比直接最大化概率得分更为简单；虽然这超出了本书的讨论范围，但我录制了一节更详细的讲座，您可以在这里查看：[L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
        "outputId": "1bf18e79-1246-4eab-efd8-12b328c78678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
          ]
        }
      ],
      "source": [
        "# 我们想要计算模型在两个输入文本（batch）上的每个 token，预测“正确目标 token”时给出的概率的对数值（log-probability）。\n",
        "# 之前已经得到了 target_probas_1 和 target_probas_2，分别表示第1和第2个输入文本中每个 token 的目标概率（target token 的预测概率），shape 都是 (3,)\n",
        "\n",
        "# 首先，将两个 batch 的目标概率拼接起来，得到一个长度为6的一维向量，表示所有 token 的目标概率。\n",
        "all_target_probas = torch.cat((target_probas_1, target_probas_2))  # 拼接两个 batch 的目标概率，得到 shape=(6,)\n",
        "\n",
        "# 接下来，对每个目标概率取对数，得到每个 token 的 log-probability（对数概率）。\n",
        "# torch.log 作用是单元素取自然对数（ln），注意：概率越接近1，log值越接近0；概率越小，log值越负，表示模型信心不足。\n",
        "log_probas = torch.log(all_target_probas)\n",
        "\n",
        "# 打印结果，查看每个 token 的预测对数概率值。\n",
        "print(log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4261441-a511-4633-9c4c-67998af31b84",
      "metadata": {},
      "source": [
        "- 接下来，我们计算平均对数概率："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9b003797-161b-4d98-81dc-e68320e09fec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b003797-161b-4d98-81dc-e68320e09fec",
        "outputId": "a447fe9c-7e27-40ed-f1fb-51210e3f7cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(-10.7940)\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average probability for each token\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)\n",
        "#对数概率平均值"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
      "metadata": {},
      "source": [
        "- 目标是通过优化模型权重，使得平均对数概率尽可能大。\n",
        "- 由于对数的性质，最大的可能值是 0，而我们当前距离 0 还有很大差距。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
      "metadata": {},
      "source": [
        "- 在深度学习中，通常的做法是最小化 \"负\" 的平均对数概率值，而不是最大化平均对数概率值；在我们的例子中，深度学习中我们会最小化 10.7722 使其接近 0，而不是最大化 -10.7722 使其接近 0。\n",
        "- 值 -10.7722 的负数，即 10.7722，在深度学习中也被称为交叉熵损失（cross-entropy loss）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ],
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "#最大化对数等价为最小化负对数\n",
        "print(neg_avg_log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
      "metadata": {},
      "source": [
        "- PyTorch 中的`cross_entropy` 已经能实现这些功能"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
      "metadata": {},
      "source": [
        "<img src=\"../image/cross-entropy.webp\" width=400px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
      "metadata": {},
      "source": [
        "- 在使用`cross_entropy` 之前, 我们可以看一下loggias跟target是怎样的"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
        "outputId": "43fd802a-8136-4b35-df0d-f61a5d4cb561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
        "print(\"Logits shape:\", logits.shape)\n",
        "\n",
        "# Targets have shape (batch_size, num_tokens)\n",
        "print(\"Targets shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
      "metadata": {},
      "source": [
        "- 有了PyTorch 中的 `cross_entropy` 函数，我们希望通过在批次维度上合并这些张量来将其展平："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
        "outputId": "0b2b778b-02fb-43b2-c879-adc59055a7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "#将张量 logits 的 第0维和第1维合并为一个维度，展平成一个二维张量\n",
        "targets_flat = targets.flatten()\n",
        "#将张量 targets 展平为一维张量\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4921a57f-3a79-473e-a863-6d63b495010f",
      "metadata": {},
      "source": [
        "- 请注意，目标是 token ID，这些 ID 也代表我们希望最大化的 logits 张量中的索引位置。\n",
        "- PyTorch 中的 `cross_entropy` 函数会自动处理对这些token索引的 softmax 和对数概率计算，确保它们被最大化。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
        "outputId": "c0be634a-2c65-4ff7-a73f-1bfc2e406ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ],
      "source": [
        "# 使用PyTorch的cross_entropy函数来计算交叉熵损失。\n",
        "# \n",
        "# 参数说明：\n",
        "# - logits_flat: 形状为 (batch_size * num_tokens, vocab_size) 的二维张量，表示模型输出的未归一化分数（logits），\n",
        "#   其中每一行对应一个样本在整个词表上的预测分布。\n",
        "# - targets_flat: 形状为 (batch_size * num_tokens,) 的一维张量，表示每个样本的真实类别（即目标token的索引）。\n",
        "#\n",
        "# 这个函数会自动对logits应用softmax，将其转换为概率分布，然后计算目标token的负对数概率（负对数似然）。\n",
        "# 最终返回所有样本的平均损失值（标量）。\n",
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "# 输出计算得到的平均交叉熵损失。\n",
        "# 该值通常用作神经网络训练时的优化目标，数值越小代表模型性能越好。\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
      "metadata": {},
      "source": [
        "- 与交叉熵损失相关的一个概念是大语言模型的困惑度 (perplexity)。\n",
        "- 困惑度就是交叉熵损失的指数值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "168952a1-b964-4aa7-8e49-966fa26add54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "168952a1-b964-4aa7-8e49-966fa26add54",
        "outputId": "a0a692c1-6412-4068-8aa5-8858548141eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(48725.8203)\n"
          ]
        }
      ],
      "source": [
        "perplexity = torch.exp(loss)\n",
        "#指数化loss作为P值\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
      "metadata": {},
      "source": [
        "- 困惑度通常被认为更易解释，因为它可以理解为模型在每一步对词汇表大小的不确定性（在上面的例子中，这相当于 48,725 个单词或 token）。\n",
        "- 换句话说，困惑度提供了一个衡量模型预测的概率分布与数据集中单词实际分布匹配程度的指标。\n",
        "- 类似于损失值，较低的困惑度表示模型预测与实际分布的差距较小。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
      "metadata": {
        "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
      },
      "source": [
        "### 5.1.3 计算训练集和验证集的损失"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
      "metadata": {},
      "source": [
        "- 我们使用一个相对较小的数据集来训练大语言模型（训练内容只有一个短篇故事）。\n",
        "- 选择小故事的原因包括：\n",
        "  - 无独立显卡的电脑也可以快速完成\n",
        "  - 训练时间较短（以分钟计算，而非数周）\n",
        "  - 我们使用了无版权文本，可以将其包含在这个 GitHub 仓库中，而不会违反任何使用权或显著增加仓库大小。\n",
        "\n",
        "- 例如，Llama 2 7B 模型在 2 万亿 token 上训练时需要 184,320 个 GPU 小时（使用 A100 GPU）。\n",
        "  - 截至本文撰写时，AWS 上 8xA100 云服务器的每小时成本约为 30 美元。\n",
        "  - 因此，通过简单计算，训练这个 LLM 的成本为 184,320 / 8 * 30 美元 = 690,000 美元。\n",
        "\n",
        "- 下面，我们使用了第二章中使用的同一数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os  # 导入操作系统相关功能的模块，用于检查文件是否存在\n",
        "import urllib.request  # 导入用于处理URL操作的模块，用于从网络下载文件\n",
        "\n",
        "# 设置本地数据集文件的路径\n",
        "file_path = \"the-verdict.txt\"\n",
        "\n",
        "# 提供远程数据集的URL地址，若本地没有则从该地址下载\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "# 检查本地是否已经存在目标数据集文件，以避免重复下载\n",
        "if not os.path.exists(file_path):\n",
        "    # 本地文件不存在，从指定URL下载数据\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        # 读取网络应答内容，并以utf-8编码解码为字符串\n",
        "        text_data = response.read().decode('utf-8')\n",
        "    # 将下载获得的数据写入本地文件，便于后续再次使用时无需重新下载\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data)\n",
        "else:\n",
        "    # 如果本地文件已存在，则直接从本地读取内容，加快处理速度\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()\n",
        "\n",
        "# 到这里，无论是下载还是本地读取，我们都得到了完整的数据集内容，存储在text_data变量中"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "379330f1-80f4-4e34-8724-41d892b04cee",
      "metadata": {},
      "source": [
        "- 通过前100个词与后100个词快速检查文本是否加载正常"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6kgJbe4ehI4q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6kgJbe4ehI4q",
        "outputId": "9ff31e88-ee37-47e9-ee64-da6eb552f46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "# First 100 characters\n",
        "print(text_data[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "j2XPde_ThM_e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j2XPde_ThM_e",
        "outputId": "a900c1b9-9a87-4078-968b-a5721deda5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
          ]
        }
      ],
      "source": [
        "# Last 100 characters\n",
        "print(text_data[-99:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
        "outputId": "c2a25334-21ca-486e-8226-0296e5fc6486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "#统计一下文本的长度,编码文本内容并输出文本个数\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
      "metadata": {},
      "source": [
        "- 为了教学,我们选取了这个短文本作为样例"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
      "metadata": {},
      "source": [
        "- 接下来，我们将数据集划分为训练集和验证集，并使用第二章中的data loader为大语言模型（LLM）训练准备数据。\n",
        "- 出于可视化的目的，下图假设 `max_length=6`，但对于训练加载器，我们将 `max_length` 设置为 LLM 支持的上下文长度。\n",
        "- 为了简化，下图仅展示了输入token：\n",
        "    - 由于我们训练 LLM 预测文本中的下一个单词，因此目标 token 与输入 token 相同，只是目标 token 向右移动了一个位置。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
      "metadata": {},
      "source": [
        "<img src=\"../image/batching.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0959c855-f860-4358-8b98-bc654f047578",
      "metadata": {},
      "outputs": [],
      "source": [
        "from previous_chapters import create_dataloader_v1  # 导入之前章节自定义的数据加载器函数 create_dataloader_v1\n",
        "\n",
        "# 训练集和验证集的比例（90% 训练集, 10% 验证集）\n",
        "train_ratio = 0.90  # 通常机器学习任务会将大部分样本用于训练\n",
        "split_idx = int(train_ratio * len(text_data))  # 计算用于分割数据集的索引\n",
        "\n",
        "# 根据上述索引，将整个文本数据拆分为训练集和验证集\n",
        "train_data = text_data[:split_idx]  # 前90%作为训练集\n",
        "val_data = text_data[split_idx:]    # 后10%作为验证集\n",
        "\n",
        "# 设置随机种子，确保实验可复现（同样的数据集和参数下每次运行结果一致）\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 构建训练数据加载器\n",
        "# - train_data: 分割后的训练文本\n",
        "# - batch_size=2: 每个批次2组数据（便于代码测试和调试，小批量可加快实验迭代）\n",
        "# - max_length：单个输入序列的最大长度，设为GPT配置中的context_length\n",
        "# - stride：窗口滑动步幅，此处等同于max_length，即无重叠滑动窗口\n",
        "# - drop_last=True: 如果最后一个批次不足batch_size，则丢弃该批\n",
        "# - shuffle=True：训练集需打乱，避免模型记住文本顺序，利于泛化\n",
        "# - num_workers=0：加载数据时不使用多进程，加速作用在大数据集下更明显\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# 构建验证数据加载器（与训练集不同点如下）\n",
        "# - drop_last=False: 验证时希望用到全部数据，因此不丢弃最后一个不足batch的批次\n",
        "# - shuffle=False: 验证时无需打乱数据，确保评估过程稳定一致\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sanity check – 数据量充足性检查\n",
        "# 目的：确认训练集（train_loader）和验证集（val_loader）里，是否都有足够token填满一个完整的序列（即至少够一个“窗口”）。\n",
        "# 若不足，数据加载器会报错、空批次或训练毫无意义。\n",
        "# 下面分别对训练和验证部分进行检查。\n",
        "\n",
        "# 检查训练集：训练集的token总数（total_tokens * train_ratio）是否大于等于序列长度设定（context_length）\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          # 说明：训练数据不够，无法切分出一个完整序列\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          # 建议1：降低模型的context长度要求\n",
        "          \"increase the `training_ratio`\")                # 建议2：提高训练集所占比例\n",
        "\n",
        "# 检查验证集：验证集的token总数（total_tokens * (1-train_ratio)）是否同样充足\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          # 说明：验证数据同样不够填满一个批次\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          # 建议1：同样考虑降低context长度\n",
        "          \"decrease the `training_ratio`\")                # 建议2：减少训练比例，让验证集有更多token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
      "metadata": {},
      "source": [
        "- 小的批处理数据集很适合用来小试牛刀\n",
        "- 例如, Llama 27B就是用每次1024的批处理数据"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
      "metadata": {},
      "source": [
        "- 另一种确认数据正常导入的方法如下"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "# 逐批次遍历训练数据加载器，打印每个输入（x）和目标（y）张量的形状\n",
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    # x: 输入序列的张量，shape: (batch_size, context_length)\n",
        "    # y: 目标输出（通常是下一个token的标签），shape: (batch_size, context_length)\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "# 逐批次遍历验证数据加载器，检查每一批次数据是否形状一致\n",
        "for x, y in val_loader:\n",
        "    # 我们也打印val_loader中的每个批次输入与目标张量的形状，用于确认数据加载是否正确和与训练集的一致性\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
      "metadata": {},
      "source": [
        "- 还有一个方法来确认是否导入成功"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "eb860488-5453-41d7-9870-23b723f742a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb860488-5453-41d7-9870-23b723f742a0",
        "outputId": "96b9451a-9557-4126-d1c8-51610a1995ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training tokens: 4608\n",
            "Validation tokens: 512\n",
            "All tokens: 5120\n"
          ]
        }
      ],
      "source": [
        "# 统计训练集的 token 总数\n",
        "train_tokens = 0  # 用于累加训练集 token 数\n",
        "for input_batch, target_batch in train_loader:\n",
        "    # input_batch: 训练集输入张量，形状为 (batch_size, context_length)\n",
        "    # .numel() 返回张量中所有元素的数量，即该 batch 包含的所有 token 数\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "# 统计验证集的 token 总数\n",
        "val_tokens = 0  # 用于累加验证集 token 数\n",
        "for input_batch, target_batch in val_loader:\n",
        "    # 同理，累计每个 batch 的 token 数\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "# 打印训练集、验证集和总 token 数\n",
        "print(\"Training tokens:\", train_tokens)    # 输出训练集所有批次的总 token 数\n",
        "print(\"Validation tokens:\", val_tokens)    # 输出验证集所有批次的总 token 数\n",
        "print(\"All tokens:\", train_tokens + val_tokens)  # 输出训练+验证集 token 总和\n",
        "\n",
        "# 说明：\n",
        "# - 在 PyTorch 中，.numel() 方法返回张量所有元素（token）的总数，无论其实际维度如何。\n",
        "# - 这样可以粗略统计 token 数，以判断数据划分和加载是否符合预期。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
      "metadata": {},
      "source": [
        "- 我们用了预分装函数来计算交叉熵\n",
        "- 我们还调用另一个辅助函数，用于计算数据加载器中由用户指定的批次数Loss。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
      "metadata": {
        "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    # 将输入与目标张量移动到指定的计算设备上（如 GPU 或 CPU）\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    # 前向传播：用模型计算输入batch的logits（预测结果，shape: [batch_size, context_length, vocab_size]）\n",
        "    logits = model(input_batch)\n",
        "    # 由于 PyTorch 的 Cross Entropy Loss 期望输入为二维（[N, C]）和一维（[N]）张量，这里需要 flatten\n",
        "    # logits.flatten(0, 1): 将[batch_size, context_length, vocab_size]拉平成[batch_size*context_length, vocab_size]\n",
        "    # target_batch.flatten(): 将目标也拉成一维（[batch_size*context_length]），表示每个位置的真实词id\n",
        "    # 计算批次的交叉熵损失\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    # 返回单个批次的loss张量\n",
        "    return loss\n",
        "# 说明：此函数对一个batch的数据，计算模型输出与真实标签之间的交叉熵损失，常用于训练和评估。\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    \"\"\"\n",
        "    遍历整个dataloader（或部分指定的批次），累加每个batch的loss，最后返回平均损失。\n",
        "    - data_loader: 数据加载器\n",
        "    - model: 当前模型\n",
        "    - device: 计算设备\n",
        "    - num_batches: 可选，若指定，则仅计算前num_batches个batch\n",
        "    \"\"\"\n",
        "    total_loss = 0.  # 用于累加损失和\n",
        "    if len(data_loader) == 0:\n",
        "        # 防止空的数据加载器，直接返回nan\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        # 若未指定num_batches，则遍历整个数据加载器\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # 指定了num_batches，取用户指定和实际可用批次数的较小者，防止超出总批次数\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    # enumerate为每个batch编号和提供数据\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            # 用上面函数分别计算每批次的损失\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()  # 将 loss 张量转为 float 累加\n",
        "        else:\n",
        "            # 如果已经处理了指定批次数，则跳出循环\n",
        "            break\n",
        "    # 返回平均损失（总损失除以批次数）\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
      "metadata": {},
      "source": [
        "- 如果你的电脑有支持 CUDA 的 GPU，大预言模型将无需更改代码即可在 GPU 上进行训练。\n",
        "- 通过 `device` 设置，我们确保数据加载到与大语言模型相同的设备上。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss: 10.987583266364204\n",
            "Validation loss: 10.98110580444336\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 如果支持，则调用 GPU\n",
        "\n",
        "# 注意：\n",
        "# 如果取消注释以下代码块，代码可以在 Apple Silicon 芯片上运行（如果适用），\n",
        "# 在 M3 MacBook Air 上测量速度大约是 Apple CPU 的两倍。\n",
        "# 然而，计算得到的损失值可能会略有不同。\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#\n",
        "# print(f\"Using {device} device.\")\n",
        "\n",
        "model.to(device)  # 对于 nn.Module 类，不需要赋值 model = model.to(device)\n",
        "\n",
        "torch.manual_seed(123)  # 固定随机种子，保证数据加载器打乱数据的结果可复现\n",
        "\n",
        "with torch.no_grad():  # 禁用梯度跟踪以提高效率，因为此时尚未开始训练\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "# 推理阶段不计算梯度\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
      "metadata": {},
      "source": [
        "<img src=\"../image/mental-model-1.webp\" width=400px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
      "metadata": {
        "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
      },
      "source": [
        "## 5.2 训练大语言模型"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
      "metadata": {},
      "source": [
        "- 在本节中，我们最终实现了用于训练大语言模型（LLM）的代码。\n",
        "- 我们想要于一个简单的训练函数（如果您对通过更高级的技术增强此训练函数感兴趣，例如学习率预热(rate warmup)、余弦退火(cosine annealing)和梯度裁剪(gradient clipping)，请参阅[附录D](../../appendix-D/01_main-chapter-code)）。\n",
        "\n",
        "<img src=\"../image/train-steps.webp\" width=300px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "Mtp4gY0ZO-qq",
      "metadata": {
        "id": "Mtp4gY0ZO-qq"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(\n",
        "    model,            # nn.Module 神经网络模型\n",
        "    train_loader,     # 训练集 DataLoader（按 batch 提供数据）\n",
        "    val_loader,       # 验证集 DataLoader\n",
        "    optimizer,        # 优化器（如 AdamW）\n",
        "    device,           # 设备，例如 \"cpu\"、\"cuda\" 或 \"mps\"\n",
        "    num_epochs,       # 训练轮数（遍历整个训练集的次数）\n",
        "    eval_freq,        # 评估间隔（每多少 step 评估一次）\n",
        "    eval_iter,        # 每次评估时采样多少个 batch 计算损失\n",
        "    start_context,    # 用于生成演示文本的初始提示（字符串）\n",
        "    tokenizer         # 分词器（实现编码与解码）\n",
        "):\n",
        "    # 初始化三个列表，用于记录训练损失、验证损失、已见 token 数\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1  # 累计走过的 token 数和全局step编号\n",
        "\n",
        "    # 主训练循环：epoch 表示“轮”（每轮遍历一遍全部训练集）\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()        # 设置为训练模式（例如启用 dropout/batchnorm）\n",
        "        # 遍历当前 epoch 的所有 batch（每个 batch 是小批量的数据）\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()   # 梯度清零，避免上一次累积\n",
        "            # 前向传递 & 损失计算（input_batch: 输入 token，target_batch: 目标 token）\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()         # 误差反向传播：计算参数梯度\n",
        "            optimizer.step()        # 执行一步优化：更新参数\n",
        "\n",
        "            tokens_seen += input_batch.numel()  # 累加本 batch token 数（粗略统计训练了多少 token）\n",
        "            global_step += 1                    # 每处理一个 batch，全局 step 增 1\n",
        "\n",
        "            # 评估监控（每 eval_freq 步评估一次）\n",
        "            if global_step % eval_freq == 0:\n",
        "                # 在评估时调用 evaluate_model，返回训练集/验证集损失\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter\n",
        "                )\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                # 显示当前训练步的信息\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # 每个 epoch 结束后，生成一段示例文本, 直观了解模型效果\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    # 返回所有采样点处的损失\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    # 用于在训练过程中“快照”评估模型的 train/val 损失\n",
        "    model.eval()              # 切到 eval 模式（关闭 dropout/batchnorm）\n",
        "    with torch.no_grad():     # 保证不计算梯度，提高效率，节约显存\n",
        "        # 只取前 eval_iter 个 batch 做评估，加速（完整评估全量数据通常较慢）\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()             # 评估后，切回 train 模式（继续训练）\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    # 生成一段模型预测文本，并打印出来\n",
        "    model.eval()  # 切到 eval 模式，保证一致性\n",
        "    context_size = model.pos_emb.weight.shape[0]  # 上限长度（比如 128）\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)  # 编码起始文本为 token id\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model,\n",
        "            idx=encoded,\n",
        "            max_new_tokens=50,          # 每轮生成 50 个新 token\n",
        "            context_size=context_size   # 上下文窗口长度\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)  # 解码为字符串\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))                  # 简洁打印（去掉换行）\n",
        "    model.train()      # 恢复训练模式以便后续继续训练"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9252ffa4-8162-466e-b347-27cb89b9a5ee",
      "metadata": {},
      "source": [
        "(GPT的解释)\n",
        "- global_step 是训练循环中的重要计数器，主要用于控制学习率调度、记录日志、保存模型检查点和控制终止条件等任务。\n",
        "- 在分批训练中，它提供了一个统一的参考点，有助于管理复杂的训练流程。\n",
        "- epoch 是按完整数据集的迭代单位，而 global_step 是按 batch 单位，粒度更细，用于管理更精确的任务。例如：\n",
        "    1.\t动态学习率调整,某些学习率调度器需要以 batch 为单位进行调整，而不是每个 epoch。例如，WarmUp 会在固定的前 N 步逐渐升高学习率。\n",
        "\t2.\t频繁日志记录,记录训练日志时，通常是每隔 log_interval 步输出一次，而不是每个 epoch。\n",
        "\t3.\t检查点保存,保存模型状态通常是按步数完成，尤其是当训练需要中断和恢复时，global_step 是更精确的 token。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
      "metadata": {},
      "source": [
        "- 我们用上述的定义训练一下这个模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3422000b-7aa2-485b-92df-99372cd22311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3422000b-7aa2-485b-92df-99372cd22311",
        "outputId": "0e046603-908d-4093-8ae5-ef2f632639fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.928\n",
            "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.335\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.622, Val loss 7.051\n",
            "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.600\n",
            "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
            "Ep 3 (Step 000020): Train loss 5.586, Val loss 6.477\n",
            "Ep 3 (Step 000025): Train loss 5.523, Val loss 6.399\n",
            "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
            "Ep 4 (Step 000030): Train loss 5.128, Val loss 6.366\n",
            "Ep 4 (Step 000035): Train loss 4.941, Val loss 6.366\n",
            "Every effort moves you a a to the a. Gisburn, and a. Gisburn. I had the of the of the of the of the of the of the of the of the of the of the of the of the of the. I had a\n",
            "Ep 5 (Step 000040): Train loss 4.340, Val loss 6.246\n",
            "Every effort moves you, with a, in the of the picture--as of the of the of the of the picture of his of the  \"I had been. \"Oh, in the donkey--and it was a little the man of the picture of\n",
            "Ep 6 (Step 000045): Train loss 3.967, Val loss 6.181\n",
            "Ep 6 (Step 000050): Train loss 3.451, Val loss 6.155\n",
            "Every effort moves you know the \"Oh, and.  \"Oh, and in a little: \"There, and in the    \"Oh, and I had been the donkey.            \n",
            "Ep 7 (Step 000055): Train loss 3.466, Val loss 6.195\n",
            "Ep 7 (Step 000060): Train loss 2.666, Val loss 6.134\n",
            "Every effort moves you know the picture.  \"I looked he was a little the last word.           \"I he was his pictures-c.             \n",
            "Ep 8 (Step 000065): Train loss 2.208, Val loss 6.141\n",
            "Ep 8 (Step 000070): Train loss 1.879, Val loss 6.228\n",
            "Every effort moves you know,\" was not that the picture.  \"I had the last word. Gisburn's an!  \"Oh, in the moment--as Jack himself, as he was his own the donkey. \"There were days when I\n",
            "Ep 9 (Step 000075): Train loss 1.499, Val loss 6.230\n",
            "Ep 9 (Step 000080): Train loss 1.174, Val loss 6.250\n",
            "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fact, with a Mrs. Gisburn's open countenance. \"It's his pictures with a \"strongest,\" she was\n",
            "Ep 10 (Step 000085): Train loss 0.901, Val loss 6.328\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"         He placed them at my elbow and as I turned, and down the room, when I\n",
            "训练完成耗时 0.20 分钟。\n"
          ]
        }
      ],
      "source": [
        "# Note:\n",
        "# 本段代码用于训练一个 GPT 模型，并测量整个训练过程的耗时\n",
        "import time   # 导入 time 库用于计时\n",
        "\n",
        "start_time = time.time()  # 记录训练开始的时间，单位为秒\n",
        "\n",
        "torch.manual_seed(123)    # 设置随机种子，保证实验的可复现性\n",
        "\n",
        "# 实例化 GPT 小模型。GPT_CONFIG_124M 是预定义的模型配置（如层数/头数等）\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)          # 将模型加载到指定设备（如 GPU 或 CPU）\n",
        "\n",
        "# 设置优化器：采用 AdamW 优化算法\n",
        "# - lr=0.0004：学习率，表示每次参数更新的步幅大小\n",
        "# - weight_decay=0.1：权重衰减（L2 正则化），有助于防止过拟合\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10  # 计划训练的总轮数（每轮遍历一次全部训练集）\n",
        "\n",
        "# 启动训练流程\n",
        "# - train_loader: 训练数据加载器\n",
        "# - val_loader: 验证数据加载器\n",
        "# - optimizer: 优化器对象\n",
        "# - device: 计算设备\n",
        "# - num_epochs: 总训练轮数\n",
        "# - eval_freq: 每隔多少步评估并记录一次当前最新损失\n",
        "# - eval_iter: 评估时包含的 batch 数量（加速评估）\n",
        "# - start_context: 用于生成样例时的起始文本\n",
        "# - tokenizer: 分词器/编码器\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "# train_losses/val_losses: 记录每个评估点训练和验证损失（loss），通常用于后续画图\n",
        "# tokens_seen: 记录到当前评估点为止模型见过多少个 token（累计训练的进度指标）\n",
        "\n",
        "end_time = time.time()  # 训练结束，记录当前时间\n",
        "execution_time_minutes = (end_time - start_time) / 60  # 计算训练耗时，单位转换为分钟\n",
        "print(f\"训练完成耗时 {execution_time_minutes:.2f} 分钟。\")  # 输出总训练时间"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0WSRu2i0iHJE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "0WSRu2i0iHJE",
        "outputId": "9d36c61b-517d-4f07-a7e8-4563aff78b11"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "# 画 loss 曲线的函数（更详细注释版）\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    # 创建一个新的图像（fig），和主坐标轴（ax1）；设置图像大小为5x3英寸\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # 在主坐标轴上绘制训练损失曲线\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    # 绘制验证集损失曲线，使用不同线型区分\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")  # 横坐标为“轮数（Epochs）”\n",
        "    ax1.set_ylabel(\"Loss\")    # 纵坐标为“损失值”\n",
        "    ax1.legend(loc=\"upper right\")  # 图例放在右上角\n",
        "    # 让主横坐标（Epochs）只显示整数刻度，比如 0, 1, 2, ...，避免非整数的小数刻度\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    # 创建一个共享相同纵坐标(y) 的第二横坐标轴（ax2）\n",
        "    ax2 = ax1.twiny()  # twiny: 在顶部叠加一个新的x轴\n",
        "    # 为了让 ax2 的 x 轴与 tokens_seen 刻度保持一致，这里画一条不可见的直线（alpha=0），\n",
        "    # 这样 ax2 的横坐标会自动适配 tokens_seen 区间\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    ax2.set_xlabel(\"Tokens seen\")  # 顶部横坐标名为“已见 token 数”\n",
        "\n",
        "    # 自动调整图像布局，使元素不重叠\n",
        "    fig.tight_layout()\n",
        "    # 保存图片到文件，文件名为 loss-plot.pdf（可用于论文/汇报插图）\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    # 显示图像\n",
        "    plt.show()\n",
        "\n",
        "# 构建 epochs_tensor，形状与 losses 相匹配，用于横坐标（轮数）对齐平滑绘图\n",
        "# torch.linspace(start, end, steps)：在 start 和 end 之间均匀生成 steps 个点\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "\n",
        "# 调用上面的 plot_losses 函数，画出训练集和验证集loss曲线以及 token 进度\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
        "# 这是一个很常见的画 loss 曲线函数的范例，适合任何深度学习任务"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
      "metadata": {},
      "source": [
        "- 从以上结果可以看出，模型在开始阶段生成的是难以理解的字符串，但是在后期能够生成基本符合语法的句子。\n",
        "- 从训练集和验证集的损失值可以看出，模型开始出现过拟合现象。\n",
        "- 如果检查后期它生成的某些段落，会发现它们与训练集中的内容完全相同(模型只是简单地记住了训练数据,背住答案罢了)。\n",
        "- 之后的部分，我们将讨论一些解码策略，这些策略可以一定程度缓解这种“背答案”的问题。\n",
        "- 请注意，这里的过拟合是由于训练集非常非常小，并且我们对其进行了多次迭代。\n",
        "  - 本次 LLM 训练主要用于教学目的；我们的目标是观察模型是否能够学会生成连贯的文本。\n",
        "  - 为了避免花费数周或数月时间在大量昂贵硬件上训练模型，我们将在后续加载预训练权重。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
      "metadata": {},
      "source": [
        "<img src=\"../image/mental-model-2.webp\" width=350px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de713235-1561-467f-bf63-bf11ade383f0",
      "metadata": {},
      "source": [
        "**如果您对通过更高深的技术增强此训练函数感兴趣，例如学习率预热、余弦退火和梯度裁剪，请参阅[附录D](../../appendix-D/01_main-chapter-code)。**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
      "metadata": {},
      "source": [
        "**更大的数据集跟更深度的训练,可以在以下找到链接 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
      "metadata": {
        "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
      },
      "source": [
        "## 5.3 控制随机性的解码策略"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
      "metadata": {},
      "source": [
        "- 对于像我们训练的这种规模相对较小的GPT模型（LLM），推理阶段的计算成本较低。因此，如果在训练时使用了GPU，推理阶段则无需依赖GPU资源。\n",
        "- 我们可以利用第5章介绍的`generate_text_simple`函数（该函数已在简单训练函数中被调用）来逐步生成新文本，每次生成一个单词（或 token）。\n",
        "- 正如5.1.2节所提到的，下一个生成的 token 是从词汇表中选取概率得分最高的 token 。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 将模型参数从GPU（如果原本在GPU）转移到CPU上，方便后续推理和节省资源\n",
        "model.to(\"cpu\")\n",
        "# 设置模型为推理（evaluation）模式，关闭dropout、batchnorm等随机性，用于生成阶段\n",
        "model.eval()\n",
        "\n",
        "# 加载GPT-2的分词器，本例用tiktoken库，tokenizer用于文本与token id的相互转换\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# 利用 generate_text_simple 函数生成新文本（自动文本补全）\n",
        "# 参数说明：\n",
        "# - model: 训练好的GPT模型\n",
        "# - idx: (张量) 输入文本的token id序列，作为生成起点（prompt）\n",
        "# - max_new_tokens: 生成新token的最大数目（此例生成25个新token）\n",
        "# - context_size: 每次前馈生成所允许的最大上下文长度（与模型结构相关）\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),  # 将输入字符串转为token id列表\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "# 输出：打印模型生成的文本（将token id序列解码为字符串）\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
      "metadata": {},
      "source": [
        "- 即使我们多次调用 `generate_text_simple` 函数，大语言模型（LLM）生成的输出也始终是确定性的，即每次结果相同。\n",
        "- 为了增强生成文本的灵活性，我们引入了两种解码策略来改进 `generate_text_simple`：**温度缩放** 和 **top-k 采样**。\n",
        "- 这些方法能够调节模型生成文本的随机性和多样性，从而满足不同的应用需求。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
      "metadata": {},
      "source": [
        "### 5.3.1 温度缩放"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
      "metadata": {},
      "source": [
        "- 在之前的实现中，我们始终使用 `torch.argmax` 来选择概率最高的 token 作为下一个生成的 token。\n",
        "- 为了增加生成文本的多样性，我们可以改用 `torch.multinomial(probs, num_samples=1)`，从概率分布中随机采样下一个 token。\n",
        "- 在这种方法中，每个索引被选中的概率与其在输入张量中对应的概率值成正比，从而实现基于概率的随机采样。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
      "metadata": {},
      "source": [
        "- 以下是对生成下一个 token 过程的简单回顾，假设我们使用一个非常小的词汇表来说明："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "# 构造一个小型词表，方便举例说明每个token对应的ID\n",
        "vocab = { \n",
        "    \"closer\": 0,    # \"closer\" 对应的 token id 是 0\n",
        "    \"every\": 1,     # \"every\"  对应的 token id 是 1\n",
        "    \"effort\": 2,    # 以下依此类推\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5, \n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "# 反向词表：根据token id查回原始单词，便于查看输出结果\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "# 假设当前输入序列为 \"every effort moves you\"，\n",
        "# 经过 LLM 预测，下一个 token 的所有候选项得到如下 logits（未归一化分数，高者代表模型更偏好）\n",
        "next_token_logits = torch.tensor(\n",
        "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "# token 顺序与 vocab 上述顺序对应。例如4.51代表\"closer\"，6.75代表\"forward\"\n",
        "\n",
        "# 第一步：将 logits 转换为概率分布（概率越大，模型越倾向于选该token）\n",
        "probas = torch.softmax(next_token_logits, dim=0) # 对所有logits做softmax归一化\n",
        "\n",
        "# 第二步：选择概率最大的 token 作为输出（贪心解码/确定性采样）\n",
        "next_token_id = torch.argmax(probas).item()      # 取得概率值最大的token对应的id\n",
        "\n",
        "# 输出下一个 token（通过 token id 查回单词），观察模型会“接”什么词\n",
        "print(inverse_vocab[next_token_id])   # 打印生成的下一个单词"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "dd55dce8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
              "        1.0120e-04, 3.5758e-01, 4.0122e-03])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "# 设置随机种子，使每次采样都可以复现同样的结果（便于调试和教学说明）\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 从概率分布 probas 中“随机”采样一个 token 的 id\n",
        "# torch.multinomial 会根据每个token的概率值进行加权随机选择，其中被选中的token概率越大，越容易被采样到\n",
        "# 参数说明：\n",
        "#   - probas: 各token的归一化概率分布（softmax输出）\n",
        "#   - num_samples=1: 只采样1个token\n",
        "# 返回结果是一个长度为1的张量，.item()取出其中的整数值（就是token的id）\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "\n",
        "# 将采样得到的 token id 转换为原始单词。inverse_vocab用来查表映射\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
      "metadata": {},
      "source": [
        "- 我们不再依赖 `torch.argmax` 来选择最可能的 token ，而是通过 `torch.multinomial(probas, num_samples=1)` 从 softmax 分布中采样来确定下一个 token 。\n",
        "- 为了直观地理解这一过程，我们可以使用原始的 softmax 概率对下一个 token 进行 1,000 次采样，并观察结果分布："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "582 x forward\n",
            "2 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "343 x toward\n"
          ]
        }
      ],
      "source": [
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123) # Manual seed for reproducibility\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
        "    #从概率分布 probas 中按照权重进行一次采样,并生成索引\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "    #然后变成单词\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "#统计采样过程中每个词的出现频率\n",
        "print_sampled_tokens(probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
      "metadata": {},
      "source": [
        "- 我们可以通过一种称为**温度缩放**的技术来调节概率分布和 token 选择的过程。\n",
        "- 温度缩放的核心操作是将 logits 除以一个大于 0 的数值（即温度值），然后再应用 softmax 函数。\n",
        "- 当温度值大于 1 时，softmax 输出的概率分布会更加均匀，从而增加生成文本的多样性。\n",
        "- 当温度值小于 1 时，softmax 输出的概率分布会更加集中（更陡峭或更尖锐），从而倾向于选择概率更高的 token，减少随机性。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e24fe1-3c4e-4ebe-877e-d5d8b703d148",
      "metadata": {},
      "source": [
        "模型的预测概率往往过于自信或低估某些类别的概率，尤其在分类任务中。\n",
        "温度缩放通过引入一个参数  T > 0  来重新调整 logits，改善预测概率的校准性能"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    \"\"\"\n",
        "    对 logits 向量执行温度缩放后的 softmax：\n",
        "    - logits: 原始未归一化的模型输出（通常是每个 token 的分数）\n",
        "    - temperature: 温度系数，调节分布的“平坦”程度\n",
        "      - temperature > 1：分布更平坦，更加多样化，不同token概率差距变小（增加随机性）\n",
        "      - temperature < 1：分布更尖锐，概率大的token更突出（趋向贪婪/确定性采样）\n",
        "      - temperature = 1：标准 softmax（无缩放）\n",
        "    \"\"\"\n",
        "    scaled_logits = logits / temperature  # 将 logits 除以温度参数（核心操作）\n",
        "    return torch.softmax(scaled_logits, dim=0)  # 沿着 token 维度做 softmax，得到概率分布\n",
        "\n",
        "# 设定多个温度系数用于实验不同采样策略的影响\n",
        "# - 1   ：原始分布（无温度缩放，标准 softmax）\n",
        "# - 0.1 ：低温度，使分布极其陡峭，几乎总是选最大概率的token\n",
        "# - 5   ：高温度，使分布比较平坦，提升小概率token被采样到的机会\n",
        "temperatures = [1, 0.1, 5]\n",
        "\n",
        "# 针对每个温度系数，分别对 logits 计算经过温度缩放后的 softmax 概率分布\n",
        "# 最终 scaled_probas 是一个列表，包含不同温度下的概率分布（每个元素 shape 与 logits 相同）\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ---- 绘制不同温度下 softmax 概率分布的条形图 ----\n",
        "\n",
        "# x 轴位置：生成长度为 vocab 大小的等差数列 [0, 1, ..., len(vocab)-1]\n",
        "x = torch.arange(len(vocab))\n",
        "\n",
        "# 每组条形（bar）的宽度设置为 0.15，方便多组并排显示，避免重叠\n",
        "bar_width = 0.15\n",
        "\n",
        "# 创建一个图像和一个坐标轴对象，设置图像大小为 5x3 英寸\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "# 遍历每个温度参数，将不同温度下 softmax 概率分布绘制为并排条形图\n",
        "for i, T in enumerate(temperatures):\n",
        "    # ax.bar 的第一个参数是条形的起始 x 坐标：\n",
        "    # - x + i * bar_width，把每组不同温度的条形错开并排\n",
        "    # - scaled_probas[i] 是此温度下各 token 的概率，作为条形高度\n",
        "    # - label 便于后续图例（legend）区分不同温度\n",
        "    rects = ax.bar(\n",
        "        x + i * bar_width,       # x 位置偏移，错位显示\n",
        "        scaled_probas[i],        # 对应概率分布\n",
        "        bar_width,               # 条形宽度\n",
        "        label=f'Temperature = {T}'  # 图例标签\n",
        "    )\n",
        "\n",
        "# 设置 y 轴标签为“Probability”\n",
        "ax.set_ylabel('Probability')\n",
        "\n",
        "# 设置 x 轴刻度为 vocab 中所有 token 的索引位置\n",
        "ax.set_xticks(x)\n",
        "\n",
        "# 将 x 轴的刻度标签设置为 vocab 的单词（token），并旋转 90 度防止重叠\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "\n",
        "# 显示图例，区分每种温度下的分布\n",
        "ax.legend()\n",
        "\n",
        "# 自动调整子图参数，使内容布局更加紧凑，防止标签被遮挡\n",
        "plt.tight_layout()\n",
        "\n",
        "# 将图片保存为 PDF 文件，便于后续查看或文档引用\n",
        "plt.savefig(\"temperature-plot.pdf\")\n",
        "\n",
        "# 显示最终绘制的图表\n",
        "plt.show()\n",
        "\n",
        "# 一套经典的 matplotlib 条形图绘制流程，此处用来直观比较不同温度下 softmax 概率分布的形态"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
      "metadata": {},
      "source": [
        "- 从结果中可以看出，当温度设置为 0.1 时，概率分布变得更加陡峭，接近于 `torch.argmax` 的行为，因此最可能的 token 几乎总是被选中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "985 x forward\n",
            "0 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "15 x toward\n"
          ]
        }
      ],
      "source": [
        "print_sampled_tokens(scaled_probas[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
      "metadata": {},
      "source": [
        "- 当温度设置为 5 时，概率分布变得更加均匀，从而增加了生成文本的多样性和随机性："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "165 x closer\n",
            "75 x every\n",
            "42 x effort\n",
            "239 x forward\n",
            "71 x inches\n",
            "46 x moves\n",
            "32 x pizza\n",
            "227 x toward\n",
            "103 x you\n"
          ]
        }
      ],
      "source": [
        "print_sampled_tokens(scaled_probas[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
      "metadata": {},
      "source": [
        "- 假设大语言模型（LLM）的输入是“every effort moves you”，上述方法有时可能会生成无意义的文本，例如“every effort moves you pizza”，其出现的概率为 3.2%（即在 1000 次采样中出现了 32 次）。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
      "metadata": {},
      "source": [
        "### 5.3.2 Top-k 取样"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
      "metadata": {},
      "source": [
        "- 为了在使用更高温度增加输出多样性的同时减少生成无意义句子的概率，我们可以将采样限制在前 k 个最可能的 token 中："
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
      "metadata": {},
      "source": [
        "<img src=\"../image/topk.webp\" width=500px>\n",
        "\n",
        "- （请注意，此图中的数值已截取到小数点后两位，以减少视觉干扰。Softmax 行中的值总和应为 1.0。）"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
      "metadata": {},
      "source": [
        "- 我们可以按照下述建议补充代码"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7f110a-8aa7-4c84-8d71-5cfd28468b48",
      "metadata": {},
      "source": [
        "-\t控制输出质量： 减少低概率、无意义的词被选中的机会。\n",
        "-\t保持多样性： 允许模型在概率较高的几个候选词中随机选择，而不是总是选择最高概率的词（这会导致输出缺乏变化）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ],
      "source": [
        "# 设定 top_k 的值，这里我们选择只关注概率最高的前 3 个 token\n",
        "top_k = 3\n",
        "\n",
        "# 使用 torch.topk 函数，从 logits 中选出概率（logits 值）最大的前 top_k 个元素\n",
        "# - top_logits: 代表前 top_k 个 logits（未经过 softmax，因此还不是概率，但大小关系仍然代表相对概率高低）\n",
        "# - top_pos: 代表上述 top_k logits 所对应的 token 索引（即 vocabulary 里的具体 token 位置）\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "\n",
        "# 打印 top_k 的 logits 值（越大表示模型越倾向选择该 token）\n",
        "print(\"Top logits:\", top_logits)\n",
        "# 打印 top_k logits 对应的 token 在 vocab 里的位置（可以用来进一步获取具体 token 字符串）\n",
        "print(\"Top positions:\", top_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ],
      "source": [
        "# 对 logits 分布利用 top-k 掩码，屏蔽掉不在前k名的 token，只保留 top_k 最高分的 token。\n",
        "# 详细说明如下：\n",
        "# - torch.where: 按条件对元素选择。如果某个 token 的 logits 分数 < top_logits[-1]（即 top_k 中分数最低的那一个），\n",
        "#   就把它赋值为 -inf（负无穷大，经过 softmax 后概率几乎为0），否则保留原 logits。\n",
        "# - 这样做的目的是：只允许可能性最大的 top_k 个 token 参与后续采样，其他 token 彻底屏蔽，不会被采样到。\n",
        "# - 使用 float(\"-inf\") 是 PyTorch 推荐的方式，确保数据类型正确（否则报错）。\n",
        "# - 新的 logits 张量与原 logits 形状相同，只是非 top_k 的位置被赋为 -inf。\n",
        "# 用 torch.where 对 logits 分布进行 top-k 掩码处理，实现只保留最可能的 top_k 个 token，其余全置为 -inf\n",
        "# torch.where(\n",
        "#     condition,   # 条件表达式：这里判断各 token 的概率分数是否 < top_k 中最低分（即top_logits[-1]）\n",
        "#     input,       # 满足 condition 时赋值内容，这里为 -inf（负无穷），经过softmax概率为0\n",
        "#     other        # 不满足 condition, 保留原值\n",
        "# )\n",
        "# 语法含义：对 next_token_logits 中每个元素，若其小于 top_logits[-1]（即不是 top k 分数），输出 -inf；否则输出原分数\n",
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1],      # 判断当前token是否在top_k之外\n",
        "    input=torch.tensor(float(\"-inf\")),                 # 不在top_k内的token被赋值为-inf，禁止采样\n",
        "    other=next_token_logits                            # 属于top_k的token保留原logits分数\n",
        ")\n",
        "\n",
        "# 输出 new_logits， 只有 top_k 个 logits 有真实分数，其余均为 -inf\n",
        "print(new_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
      "metadata": {},
      "source": [
        "> NOTE:  \n",
        ">\n",
        ">  一种稍微更高效的实现方式可以通过以下代码实现：\n",
        ">\n",
        "> ```python\n",
        "> new_logits = torch.full_like( # create tensor containing -inf values\n",
        ">    next_token_logits, -torch.inf\n",
        ">)   \n",
        "> new_logits[top_pos] = next_token_logits[top_pos] # copy top k values into the -inf tensor\n",
        "> ```\n",
        ">\n",
        "> For more details, see https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ],
      "source": [
        "# 对经过 top-k 掩码处理后的 new_logits 张量进行 softmax 操作，得到每个 token 的采样概率分布\n",
        "# 详细说明：\n",
        "# - new_logits 里，只有 top_k 个 token 的 logits 分数为真实值，其余的 token 都被设置为 -inf（负无穷）。\n",
        "# - 对 new_logits 执行 softmax 时，带有 -inf 的位置其 softmax 输出必为 0，这样保证每次采样时只会从 top_k 内选择 token。\n",
        "# - softmax 的 dim=0 说明这是对 1 维向量（当前只预测一个位置的所有 token）的 logits 进行归一化，输出概率仍是一维张量，与 logits 形状一致。\n",
        "# - 最终结果 topk_probas 只在 top_k 对应的位置有大于 0 的概率，其余为 0，总和为 1。\n",
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "# 打印经过 top-k softmax 后的概率分布，其中只有 top_k 个 token 有概率，其它全为 0\n",
        "print(topk_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
      "metadata": {},
      "source": [
        "### 5.3.3 优化文本更新功能"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34770423-473d-46f6-a5fa-6b2979564d26",
      "metadata": {},
      "source": [
        "- 在前两小节中，我们介绍了**温度采样**和**top-k 采样**的概念。\n",
        "- 现在，我们将结合这两种方法，对之前用于生成大语言模型（LLM）文本的 `generate_simple` 函数进行改进，创建一个新的 `generate` 函数："
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2a9c09a-41fb-465e-9f60-eb4fd2a7230d",
      "metadata": {},
      "source": [
        "    - (译者):用自己的话总结下\n",
        "    - 温度校正是更加平滑,防止数据差之毫厘以谬以千里 \n",
        "    - topK是防止臭鱼烂虾进入筛选范围提高质量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "    \"\"\"\n",
        "    根据给定输入 idx 自动生成后续 token 序列，支持 temperature softmax 采样和 top-k 策略。\n",
        "\n",
        "    参数说明：\n",
        "        model:          训练好的因果语言模型（如 GPTModel）\n",
        "        idx:            当前上下文输入 token 的索引，形状为 (batch_size, 序列长度)\n",
        "        max_new_tokens: 生成新 token 的最大步数\n",
        "        context_size:   每次送入模型的上下文长度（等同于模型支持的最大长度）\n",
        "        temperature:    温度系数（>0 启用采样, =0 变为贪婪采样 argmax）\n",
        "        top_k:          限制每步只从 logits 最靠前的 top_k 个 token 采样（int 或 None）\n",
        "        eos_id:         可选，终止符 token id（遇到则提前停止生成）\n",
        "\n",
        "    返回值：\n",
        "        idx:   拼接后的完整 token 序列（原序列 + 生成部分），形状为 (batch_size, 序列长度 + 新增 token 数)\n",
        "    \"\"\"\n",
        "    # 每一步生成一个单词（token），循环最多 max_new_tokens 次\n",
        "    for _ in range(max_new_tokens):\n",
        "        # 只取最近 context_size 长度的上下文作为模型输入（让生成长度不会超过模型最大限制）\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)  # 前向推理，得到所有位置的下一个 token logits\n",
        "        # 只取当前序列最后一个位置的 logits（即准备预测下一个 token）\n",
        "        logits = logits[:, -1, :]   # 形状 (batch_size, vocab_size)\n",
        "\n",
        "        # ----------- Top-k 策略：只允许概率最高的 top_k 个 token 被采样 -----------\n",
        "        if top_k is not None:\n",
        "            # 得到每个样本概率最高的前 top_k 个值及其阈值\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]  # 第 top_k 大的值，低于此的都设为 -inf\n",
        "            # 对所有 logits：小于 min_val 的位置替换为 -inf（保证 softmax 后它们的概率为 0）\n",
        "            logits = torch.where(\n",
        "                logits < min_val.unsqueeze(1),  # 保证 batch 维度上的广播\n",
        "                torch.tensor(float(\"-inf\"), device=logits.device),\n",
        "                logits\n",
        "            )\n",
        "            # 此时 logits 中只有 top_k 位置为实际值，其余都为 -inf\n",
        "\n",
        "        # ----------- 温度采样：控制分布平滑或尖锐 -----------\n",
        "        if temperature > 0.0:\n",
        "            # 对 logits 除以 temperature，temperature 越高分布越平滑，低温趋近于 argmax\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # softmax 得到每个 token 的概率分布\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, vocab_size)\n",
        "\n",
        "            # 根据概率分布从所有 token 采样下一个 token，采样结果 shape=(batch_size, 1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            # 多项式采样充分利用概率分布进行多样化生成\n",
        "\n",
        "        else:\n",
        "            # 如果 temperature 不启用，就直接用贪婪法（概率最大的位置），效率更高\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "            # 不带 sampling，完全“最可能”地生成，缺少多样性\n",
        "\n",
        "        # ----------- EOS（终止符号）控制：遇到就提前停止 -----------\n",
        "        # 支持提前中止生成，如果采样结果正好是终止符（如 <eos>），跳出循环\n",
        "        if eos_id is not None and (idx_next == eos_id).any():\n",
        "            # （注：batch 生成时，如果任一序列到 <eos>，整体就提前 break）\n",
        "            break\n",
        "\n",
        "        # 将本步采样到的新 token 拼接到原序列后，作为下一步模型输入\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, 当前长度+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves youlit did Gisburn rather a--I felt nervous portrait by his knees\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
        "#经典的操作"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
      "metadata": {},
      "source": [
        "## 5.4 在Pytorch中加载并保留权重"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fc52676-f026-4566-a226-2a90269f9d53",
      "metadata": {},
      "source": [
        "- 大模型的训练是很贵的, 所以导入已训练好的参数是很有必要的\n",
        "<img src=\"../image/mental-model-3.webp\" width=400px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
      "metadata": {},
      "source": [
        "- 在Pytorch中我们所推荐的保存方式是所谓的 `state_dict` ,这玩意通过调用 `torch.save` 的子模块 `.state_dict()` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "#训练完的数据保存一下"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
      "metadata": {},
      "source": [
        "- 之后我们可以对新的 `GPTModel` 导入已经训练好的参数:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 首先，实例化一个新的GPTModel模型，采用GPT-2 124M参数配置。\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 自动检测是否有可用的GPU，如果有就使用GPU，否则回退到CPU。\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 从本地保存的文件 'model.pth' 加载模型权重（state_dict）。\n",
        "# 使用 map_location 保证无论是在GPU还是CPU加载，权重都能正确映射到当前设备。\n",
        "# weights_only=True 只加载权重，不包括额外的信息（PyTorch 2.0及以上支持）。\n",
        "model.load_state_dict(\n",
        "    torch.load(\"model.pth\", map_location=device, weights_only=True)\n",
        ")\n",
        "\n",
        "# 将模型切换到评估模式（eval），以便推理时不会启用dropout等训练专用机制。\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
      "metadata": {},
      "source": [
        "- 自适应的Adam跟AdamW相较于SGD更好!\n",
        "- 但是这些算法需要另外的参数, 所以保存训练好的参数就更有必要了:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用 torch.save 保存一个包含模型参数和优化器参数的字典到磁盘，文件名为 \"model_and_optimizer.pth\"\n",
        "torch.save({\n",
        "    # 'model_state_dict' 保存当前模型的全部参数（如权重、偏置）\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    # 'optimizer_state_dict' 保存优化器的全部状态（如自适应梯度等，保证断点续训时优化器状态不会丢失）\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    # 保存文件的名称，可以自由指定，一般会用 .pth 或 .pt 作为后缀\n",
        "    \"model_and_optimizer.pth\"\n",
        ")\n",
        "# 此方式可一次性打包保存模型与优化器等关键信息，方便中断和恢复训练流程"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "8a0c7295-c822-43bf-9286-c45abc542868",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 从磁盘加载包含模型和优化器状态的检查点文件（.pth）。weights_only=True 表示只加载权重与状态，不包含额外元数据（需PyTorch 2.0及以上）。\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
        "\n",
        "# 创建一个新的 GPTModel 实例，参数配置采用 GPT-2 124M（与之前训练保持一致，否则参数无法正确加载）\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 将加载回来的模型参数 (state_dict) 应用到新建的模型对象中，实现模型参数的恢复\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "# 实例化优化器AdamW（让优化器关联到新模型的参数，注意超参数如lr、weight_decay应与训练保存时一致）\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
        "\n",
        "# 加载优化器的状态（如自适应学习率缓存、动量等），这样可以在断点后精确恢复训练进度\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "# 切换模型到训练模式（train），启用如 Dropout/BatchNorm 等训练特有功能，准备继续训练\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4194350e-0409-4a63-8ffd-d3a896509032",
      "metadata": {},
      "source": [
        "## 5.5 从OpenAI导入超参数"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
      "metadata": {},
      "source": [
        "- 在之前的实验中，我们仅使用了一本非常短的小故事书来训练一个小型 GPT-2 模型，这主要是为了教学目的。\n",
        "- 对此感兴趣的读者可以在[../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)中找到基于完整古登堡计划图书语料库的更长时间预训练记录。\n",
        "- 幸运的是，我们无需花费数万到数十万美元在大型预训练语料库上预训练模型，而是可以直接加载 OpenAI 提供的预训练权重。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
      "metadata": {},
      "source": [
        "- 有关从Hugging Face中加载权重的另一种方法请参阅 [../02_alternative_weight_loading](../02_alternative_weight_loading)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75cab892-a165-4f43-9601-f517bc212ab6",
      "metadata": {},
      "source": [
        "- 首先，我们需要一些基础代码来从 OpenAI 下载文件并将权重加载到 Python 中。\n",
        "- 由于 OpenAI 使用了 [TensorFlow](https://www.tensorflow.org/)，我们需要安装并使用 TensorFlow 来加载权重；同时，[tqdm](https://github.com/tqdm/tqdm) 是一个用于显示进度条的库。\n",
        "- 取消注释并运行下一个代码单元以安装所需的库。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Requirement already satisfied: tensorflow in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (2.20.0)\n",
            "Requirement already satisfied: tqdm in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (4.67.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (6.33.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (80.10.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (1.78.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: pillow in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (12.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: rich in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (14.3.2)\n",
            "Requirement already satisfied: namex in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /ssd/zy/anaconda/envs/llms/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.20.0\n",
            "tqdm version: 4.67.3\n"
          ]
        }
      ],
      "source": [
        "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
        "print(\"tqdm version:\", version(\"tqdm\"))\n",
        "#tensorflow他到底还是来了"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-27 16:42:51.919541: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-02-27 16:42:52.524426: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2026-02-27 16:42:54.133997: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
          ]
        }
      ],
      "source": [
        "# 从当前目录下导入自定义工具函数\n",
        "# gpt_download.py 是本章同一目录下的辅助脚本，封装了 GPT-2 模型权重的自动下载与加载逻辑\n",
        "# 通过调用 download_and_load_gpt2，可以方便地从 OpenAI 官方源拉取 GPT-2 模型文件，并解析为适合后续 PyTorch 加载的格式\n",
        "from gpt_download import download_and_load_gpt2  # 加载和下载GPT-2权重的核心API\n",
        "# 这其实是“召唤神仙”——一行代码帮助我们一次性搞定数据下载与权重读取流程"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
      "metadata": {},
      "source": [
        "- 通过如下代码下载124M的模型:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 25.1kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 643kiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 54.0kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [18:12<00:00, 455kiB/s]    \n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 1.15MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 584kiB/s] \n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 562kiB/s] \n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
          ]
        }
      ],
      "source": [
        "# ==== 更详细注释版 ====\n",
        "# download_and_load_gpt2 函数的第一个返回值 settings 是一个“模型结构与超参数的元信息”字典（dict）。\n",
        "# 典型包含（但不限于）如下关键字段：\n",
        "#   - 'n_vocab'：词表大小，即模型能处理的单词/子词 token 总数（例如 50257，GPT-2 默认词表长度）\n",
        "#   - 'n_ctx'：上下文长度（context length），指模型单次最大可输入/生成的 token 数，GPT-2 为 1024\n",
        "#   - 'n_embd'：词嵌入（embedding）和隐藏层的维度数，比如 768\n",
        "#   - 'n_head'：多头注意力机制的头数，例如 12\n",
        "#   - 'n_layer'：transformer 堆叠层（Block）数量，例如 12\n",
        "#   - 还可能包含 dropout 概率、激活函数类型等\n",
        "# 参数示例如下：\n",
        "# Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, ...}\n",
        "#\n",
        "# 理解 settings 非常重要，因为：\n",
        "# - 能帮助我们检查所下载权重具体属于哪种 GPT-2 变体（小/中/大/超大）。\n",
        "# - 确认词表、层数、嵌入维度等参数，保证自定义的 GPTModel 初始化时，结构完全兼容后续权重加载，否则会报错或性能异常。\n",
        "# - 若需迁移到其它框架/硬件或做结构微调，必须知晓这些核心元参数。\n",
        "#\n",
        "# 建议每次载入权重后都 print 出来（如下），以便核对/调试和写脚本自动化。\n",
        "print(\"Settings:\", settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ],
      "source": [
        "# params 是 gpt_download.py 下载并解析后的权重字典，\n",
        "# 其键（key）为各层权重的名称，值为对应的 numpy 数组或 PyTorch 张量。\n",
        "# 常见 key 包括 'wte'（token embedding）、'wpe'（position embedding）、\n",
        "# 各 transformer 块的权重（如 'h.0.attn.c_attn.weight'）等。\n",
        "# 列出所有 key，可以帮助我们了解原版权重的组织方式，为后续权重映射和检查提供便利。\n",
        "print(\"Parameter dictionary keys:\", params.keys())  # 输出所有权重参数名称列表"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ],
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
      "metadata": {},
      "source": [
        "- 此外，`model_size` 参数还支持 \"355M\"、\"774M\" 和 \"1558M\" 等选项。\n",
        "- 下图总结了这些不同规模模型之间的主要差异："
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
      "metadata": {},
      "source": [
        "<img src=\"../image/gpt-sizes.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
      "metadata": {},
      "source": [
        "- 在上述操作中，我们已经成功将 124M 的 GPT-2 模型权重加载到 Python 中，但仍需将这些权重传输到我们的 `GPTModel` 实例中。\n",
        "- 首先，我们需要初始化一个新的 `GPTModel` 实例。\n",
        "- 需要注意的是，原始的 GPT 模型在多头注意力模块中为查询、键和值矩阵的线性层初始化了带有偏置向量的权重，这种做法既不必要也不推荐。然而，为了正确加载权重，我们在实现中必须将 `qkv_bias` 参数设置为 `True`。\n",
        "- 此外，我们使用了原始 GPT-2 模型所支持的 `1024`  token 的上下文长度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义不同 GPT-2 尺寸的配置参数字典，方便选择与扩展\n",
        "# 每个条目描述一个模型变体的核心参数：\n",
        "#   - emb_dim: 嵌入与隐藏层维度（即 d_model）\n",
        "#   - n_layers: Transformer 块数\n",
        "#   - n_heads: 注意力头数量\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "# 上述名称对应 OpenAI 官方 GPT-2 预训练模型的 4 个不同规模\n",
        "\n",
        "# 指定想要构建的模型名称，这里以 gpt2-small (124M) 为例\n",
        "model_name = \"gpt2-small (124M)\"  # 可更换为上面其他任一模型名\n",
        "\n",
        "# 从基本的 GPT-2 配置（通常是 124M 设置）创建一份副本，作为初始化模板\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "\n",
        "# 用对应模型尺寸的实际参数（embedding/层数/注意力头）覆盖基本配置\n",
        "NEW_CONFIG.update(model_configs[model_name])\n",
        "\n",
        "# 还需补充其它与原始权重强相关的参数：\n",
        "# - context_length: 最大上下文长度（GPT-2 默认 1024）；\n",
        "# - qkv_bias: 在注意力 Q/K/V 线性层中启用偏置（与原版权重结构兼容）。\n",
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "\n",
        "# 使用组装好的配置新建 GPTModel 实例\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "\n",
        "# 将模型置为评估（eval）模式，关闭 dropout 等，仅推理状态\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
      "metadata": {},
      "source": [
        "- 接下来的任务是将 OpenAI 的权重分配到我们 `GPTModel` 实例中对应的权重张量中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
      "metadata": {},
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    \"\"\"\n",
        "    将右侧的权重（right）分配/赋值给左侧的模型参数（left）。\n",
        "\n",
        "    参数说明:\n",
        "    left  : torch.nn.Parameter\n",
        "        - 目标参数（模型原本的 nn.Parameter），用于被新权重覆盖。\n",
        "    right : np.ndarray 或 torch.Tensor\n",
        "        - 要分配的新权重数组，通常来自于加载的 numpy 权重或权重转储。\n",
        "\n",
        "    函数逻辑:\n",
        "    1. 检查左右两边的形状是否一致（此处有 shape 紧急校验，防止维度错配）。\n",
        "    2. 用 torch.tensor(right) 把 right 转换为 torch 张量，再包裹成可训练的 nn.Parameter\n",
        "       - 这样可以保证参数类型和 requires_grad 标记符合 PyTorch 的训练/推理流程。\n",
        "    3. 返回新的 nn.Parameter 对象（实际用于模型参数替换）。\n",
        "\n",
        "    使用场景:\n",
        "    - 在权重对齐/迁移时，将 numpy 权重加载进 PyTorch 定义的自定义模型结构。\n",
        "    - 统一权重类型与属性，并即时进行 shape 检查，防止隐式错误传递。\n",
        "\n",
        "    注意事项:\n",
        "    - 此函数返回的是新的 Parameter，应确保在调用方做覆盖赋值。\n",
        "    - 对于严格权重匹配的模型迁移任务十分关键。\n",
        "    \"\"\"\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    \"\"\"\n",
        "    将预训练权重 'params' 按照名字和结构, 精确地重新分配到自定义实现的 GPTModel(gpt) 结构中。\n",
        "    \n",
        "    参数:\n",
        "    - gpt: 我们实现的 GPTModel 实例\n",
        "    - params: 来自原始 OpenAI/转换后 numpy 的权重dict, 结构一般是: \n",
        "        {\n",
        "            'wte': ...   # token embedding 权重\n",
        "            'wpe': ...   # position embedding 权重\n",
        "            'blocks': [  # transformer blocks 列表, 每层一个\n",
        "                {\n",
        "                    'attn': {\n",
        "                        'c_attn': {'w': ..., 'b': ...}, # QKV 合并权重, shape=[embed, 3*embed]\n",
        "                        'c_proj': {'w': ..., 'b': ...}, # 注意力输出投影\n",
        "                    },\n",
        "                    'mlp': {\n",
        "                        'c_fc':   {'w': ..., 'b': ...}, # 前向MLP第一层\n",
        "                        'c_proj': {'w': ..., 'b': ...}, # MLP投影层\n",
        "                    },\n",
        "                    'ln_1': {'g': ..., 'b': ...},      # 块内 LayerNorm1\n",
        "                    'ln_2': {'g': ..., 'b': ...},      # 块内 LayerNorm2\n",
        "                },\n",
        "                ...\n",
        "            ],\n",
        "            'g': ... # 最后 LayerNorm 的 scale\n",
        "            'b': ... # 最后 LayerNorm 的 shift\n",
        "        }\n",
        "    \"\"\"\n",
        "    # 1. 分配位置嵌入（Position Embedding）权重\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])  # shape: [max_positions, embed_dim]\n",
        "\n",
        "    # 2. 分配词表嵌入（Token/Word Embedding）权重\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])  # shape: [vocab_size, embed_dim]\n",
        "\n",
        "    # 3. 遍历每一个 Transformer 块，将权重逐一分配到对应子模块\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        # --- Attention 子模块 ---\n",
        "        # (1) 拆分 Q/K/V 的合并全连接的权重\n",
        "        # 原始 GPT权重里，c_attn 的 w 是 shape=[embed_dim, 3*embed_dim]，按最后一维拆分出 Q, K, V\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
        "        # PyTorch 线性层是 [out, in]，需要转置\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        # (2) 同理，拆分 bias\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        # (3) 注意力输出的投影层权重 (out_proj)，同样需要转置\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight, \n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias, \n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # --- FeedForward 子模块（MLP 部分） ---\n",
        "        # (1) MLP 的第一个全连接：c_fc (GELU前), 转置\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        # (2) MLP 的投影回 embedding 维度：c_proj, 转置\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # --- 块内 LayerNorm 参数 ---\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale, \n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])  # scale/gamma\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift, \n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])  # shift/beta\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale, \n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift, \n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    # 4. 分配最终 LayerNorm（transformer 输出后的归一化）参数\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "\n",
        "    # 5. 输出（投影）层权重 (通常共享token embedding)\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "    \n",
        "# ------------------------\n",
        "# 实际调用：把预训练好的模型权重加载进 gpt\n",
        "# 作用：此时 gpt 变成了“带有真实预训练权重、即开箱可用”的版本\n",
        "# params 通常由权重转换逻辑/脚本提前处理好，比如 *.npz 或权重pkl里加载出来\n",
        "load_weights_into_gpt(gpt, params)\n",
        "# 放到指定 device 上（如 cuda 或 cpu），便于推理/后续使用\n",
        "gpt.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
      "metadata": {},
      "source": [
        "- 如果模型正确加载了,我们可以用先前的`generate` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
          ]
        }
      ],
      "source": [
        "# 设置随机种子，使生成的结果可复现（保证多次运行时采样出的文本一致）\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 使用已经加载好权重的 gpt 模型进行文本生成\n",
        "# 步骤说明如下：\n",
        "# 1. 将输入字符串 \"Every effort moves you\" 用 tokenizer 编码为 token id 列表，并放到指定 device（如 CUDA）。\n",
        "# 2. 调用 generate 函数生成后续 token id：\n",
        "#    - model=gpt：使用我们加载了预训练权重的 GPT 模型\n",
        "#    - idx=...：输入的文本 token id，作为生成的初始提示\n",
        "#    - max_new_tokens=25：最多生成 25 个新 token\n",
        "#    - context_size=NEW_CONFIG[\"context_length\"]：上下文窗口长度（决定模型可用多少历史 token 信息）\n",
        "#    - top_k=50：采样时仅在 logits 排名前 50 的 token 中选取（top-k 限制，提升结果多样性且避免生僵硬重复内容）\n",
        "#    - temperature=1.5：采样温度，数值越大越随机，数值越小更保守/稳定\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "# 将生成的 token id 序列转回为可读文本，并输出\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
      "metadata": {},
      "source": [
        "- 我们可以确认模型权重已正确加载，因为模型能够生成连贯的文本；如果我们在加载过程中出现任何错误，模型将无法实现这一点。\n",
        "\n",
        "- 如果您想了解另一种从 Hugging Face Hub 加载权重的方法，请参阅 [../02_alternative_weight_loading](../02_alternative_weight_loading)。\n",
        "\n",
        "- 如果您对 GPT 架构与 Llama 架构（Meta AI 开发的一种流行大语言模型）之间的比较感兴趣，请查看附加内容：[../07_gpt_to_llama](../07_gpt_to_llama)。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
      "metadata": {},
      "source": [
        "## 总结与收获"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
      "metadata": {},
      "source": [
        "- 请参考 [./gpt_train.py](./gpt_train.py) 脚本，这是一个独立的训练脚本。\n",
        "- [./gpt_generate.py](./gpt_generate.py) 脚本会加载 OpenAI 提供的预训练权重，并根据提示生成文本。\n",
        "- 您可以在 [./exercise-solutions.ipynb](./exercise-solutions.ipynb) 中找到练习的解答。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
