{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "<br>汉化的库: <a href=\"https://github.com/GoatCsu/CN-LLMs-from-scratch.git\">https://github.com/GoatCsu/CN-LLMs-from-scratch.git</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"../image/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# 第 6 章：进行文本分类的微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.8\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.10.0\n",
      "tensorflow version: 2.20.0\n",
      "pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# 从 importlib.metadata 模块导入 version 函数\n",
    "# 该函数用于获取已安装 Python 包的版本信息\n",
    "from importlib.metadata import version\n",
    "\n",
    "# 定义一个包含本章所需依赖包名称的列表\n",
    "pkgs = [\"matplotlib\",  # 用于数据可视化和绘图的库\n",
    "        \"numpy\",       # 用于数值计算和数组操作的基础库\n",
    "        \"tiktoken\",    # OpenAI 的分词器库,用于将文本转换为 token\n",
    "        \"torch\",       # PyTorch 深度学习框架,用于构建和训练神经网络\n",
    "        \"tensorflow\",  # 用于加载OpenAI的预训练权重的TensorFlow库\n",
    "        \"pandas\"       # 用于加载数据集的库,提供数据处理和分析功能\n",
    "       ]\n",
    "\n",
    "# 遍历包列表,逐个打印每个包的版本号\n",
    "for p in pkgs:\n",
    "    # 使用 f-string 格式化输出:包名 + 版本号\n",
    "    # version(p) 会查询已安装包的元数据并返回版本字符串\n",
    "    print(f\"{p} version: {version(p)}\")\n",
    "\n",
    "# 注:此代码块用于环境检查,确保所有必需的依赖包都已正确安装\n",
    "# 如果某个包未安装,version() 函数会抛出 PackageNotFoundError 异常"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"../image/1.png\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946c3e56-b04b-4b0f-b35f-b485ce5b28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 防止某些单元格执行两次的工具函数\n",
    "# ============================================================\n",
    "# 在 Jupyter Notebook 中,有时会不小心多次执行同一个单元格\n",
    "# 这可能导致重复操作(如重复加载数据、重复训练模型等)\n",
    "# 本代码提供了一个自定义魔法命令 %%run_once,用于确保单元格只执行一次\n",
    "\n",
    "# 从 IPython 核心模块导入 register_line_cell_magic 装饰器\n",
    "# 该装饰器用于注册自定义的 Jupyter 魔法命令\n",
    "# 魔法命令是 Jupyter 中以 % 或 %% 开头的特殊命令\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "# 使用 set 数据结构来存储已经执行过的单元格标识符\n",
    "# set 的特点:\n",
    "# 1. 无序集合,不允许重复元素\n",
    "# 2. 查找效率高(O(1)时间复杂度)\n",
    "# 3. 适合用于记录\"是否已执行\"这种布尔状态\n",
    "executed_cells = set()\n",
    "\n",
    "# 使用装饰器注册一个新的魔法命令\n",
    "# @register_line_cell_magic 会将下面的函数注册为可在 Jupyter 中使用的魔法命令\n",
    "# 注册后可以通过 %%run_once 来调用这个函数\n",
    "@register_line_cell_magic\n",
    "def run_once(line, cell):\n",
    "    \"\"\"\n",
    "    自定义魔法命令:确保单元格只执行一次\n",
    "    \n",
    "    使用方法:\n",
    "        %%run_once unique_cell_id\n",
    "        # 你的代码\n",
    "        print(\"这段代码只会执行一次\")\n",
    "    \n",
    "    参数说明:\n",
    "        line (str): 魔法命令后的第一行内容,用作单元格的唯一标识符\n",
    "                   例如 %%run_once my_cell 中的 \"my_cell\"\n",
    "        cell (str): 单元格中的实际代码内容(多行字符串)\n",
    "    \n",
    "    工作原理:\n",
    "        1. 检查 line(单元格标识符)是否在 executed_cells 集合中\n",
    "        2. 如果不在,执行单元格代码并将标识符加入集合\n",
    "        3. 如果已在,跳过执行并打印提示信息\n",
    "    \"\"\"\n",
    "    # 检查当前单元格标识符是否已经执行过\n",
    "    if line not in executed_cells:\n",
    "        # 如果未执行过:\n",
    "        # 1. 使用 get_ipython() 获取当前 IPython 实例\n",
    "        # 2. 调用 run_cell() 方法执行单元格中的代码\n",
    "        get_ipython().run_cell(cell)\n",
    "        \n",
    "        # 将当前单元格标识符添加到已执行集合中\n",
    "        # 这样下次再执行时就会被跳过\n",
    "        executed_cells.add(line)\n",
    "    else:\n",
    "        # 如果已经执行过,打印提示信息而不执行代码\n",
    "        # 这可以防止重复操作(如重复下载数据、重复初始化模型等)\n",
    "        print(f\"Cell '{line}' has already been executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 不同类型的微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- 本章节没有代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- 常见微调大语言模型的方法包括：指令微调( instructionfinetuning)和分类微调(classification finetuning)\n",
    "- 如下是:指令微调，也是下一章节所要讲的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"../image/2.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- 如果您具有机器学习的背景，对于分类微调您可能已经熟悉. 举个例子，分类微调类似于训练卷积网络来对手写数字进行分类的过程\n",
    "- 在分类微调中，模型可以输出特定的分类标签（例如，“spam”和“not spam”）\n",
    "- 分类微调模型只能预测它在训练期间所熟知的类别标签（例如，“垃圾邮件”或“非垃圾邮件”），而指令微调模型通常可以执行更广泛的任务\n",
    "- 我们可以将分类微调模型视为高度专业化的模型;在实践中，开发专业化的模型通常比开发在许多不同任务上表现良好的通用模型要容易得多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"../image/3.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"../image/4.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- 本节准备我们用于分类微调的数据集\n",
    "- 我们使用由垃圾邮件和非垃圾邮件组成的数据集来对 LLM 进行分类微调\n",
    "- 首先，我们下载并解压缩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "# 导入所需的标准库\n",
    "import urllib.request  # 用于从网络下载文件\n",
    "import zipfile         # 用于解压 ZIP 压缩文件\n",
    "import os              # 用于文件系统操作（如重命名文件）\n",
    "from pathlib import Path  # 用于跨平台的路径操作\n",
    "\n",
    "# 定义数据集的下载地址和本地存储路径\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"  # UCI 机器学习仓库中的 SMS 垃圾短信数据集\n",
    "zip_path = \"sms_spam_collection.zip\"  # 下载后的 ZIP 文件保存路径\n",
    "extracted_path = \"sms_spam_collection\"  # 解压后的文件夹路径\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"  # 最终数据文件的完整路径（使用 Path 对象拼接路径）\n",
    "\n",
    "# 定义下载并解压数据集的函数\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    \"\"\"\n",
    "    下载并解压 SMS 垃圾短信数据集\n",
    "    \n",
    "    参数:\n",
    "        url: 数据集的下载链接\n",
    "        zip_path: 下载的 ZIP 文件保存路径\n",
    "        extracted_path: 解压后的文件夹路径\n",
    "        data_file_path: 最终数据文件的路径（Path 对象）\n",
    "    \"\"\"\n",
    "    # 检查数据文件是否已经存在，避免重复下载\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return  # 如果文件已存在，直接返回，不执行后续操作\n",
    "\n",
    "    # 步骤 1: 下载文件\n",
    "    # 使用 urllib.request.urlopen 打开 URL 连接\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        # 以二进制写入模式打开本地文件\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            # 读取网络响应的全部内容并写入本地文件\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # 步骤 2: 解压文件\n",
    "    # 使用 zipfile.ZipFile 打开下载的 ZIP 文件（只读模式 \"r\"）\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        # 将 ZIP 文件中的所有内容解压到指定文件夹\n",
    "        zip_ref.extractall(extracted_path)\n",
    "    \n",
    "    # 步骤 3: 重命名文件并添加 .tsv 扩展名\n",
    "    # 原始文件名为 \"SMSSpamCollection\"（无扩展名），需要重命名为 \"SMSSpamCollection.tsv\"\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"  # 解压后的原始文件路径\n",
    "    os.rename(original_file_path, data_file_path)  # 重命名文件，添加 .tsv 扩展名\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "# 调用函数，执行下载、解压和重命名操作\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- 数据集保存为一个以制表符分隔的文本文件SMSSpamCollection.tsv，位于 SMSSpamCollection 文件夹中。我们可以使用以下代码将其加载到 pandas DataFrame 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入 pandas 库，用于数据处理和分析\n",
    "import pandas as pd\n",
    "\n",
    "# 使用 pandas 的 read_csv 函数读取 TSV 文件（制表符分隔的文本文件）\n",
    "# 参数说明：\n",
    "#   - data_file_path: 数据文件的完整路径（Path 对象）\n",
    "#   - sep=\"\\t\": 指定分隔符为制表符（Tab），因为这是 TSV 格式\n",
    "#   - header=None: 告诉 pandas 文件没有列名行（第一行就是数据）\n",
    "#   - names=[\"Label\", \"Text\"]: 手动为两列指定列名\n",
    "#     * \"Label\" 列：存储短信的类别标签（\"ham\" 表示正常短信，\"spam\" 表示垃圾短信）\n",
    "#     * \"Text\" 列：存储短信的实际文本内容\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "\n",
    "# 在 Jupyter Notebook 中，单独一行写变量名会自动显示该变量的内容\n",
    "# 这里会显示 DataFrame 的前几行和后几行，以及总行数和列数信息\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- 执行如下代码来查看数据集中的数据类别分布，会发现数据中“非垃圾消息（ham）”的出现频率远高于“垃圾消息（spam）”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- 为了简化处理，并且出于教学目的考虑，我们选择使用小规模数据集，这有助于更快地对大语言模型进行微调。因此，我们对数据集进行了下采样，使每个类别包含 747 个实例。\n",
    "- （除了下采样之外，还有其他几种方法可以处理类别不平衡，但这些超出了本书的范围; 你可以在 imbalanced-learn 中找到示例和更多信息）[`imbalanced-learn` 用户指南](https://imbalanced-learn.org/stable/user_guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%%run_once balance_df\n",
    "# Jupyter 魔法命令：确保这个单元格只运行一次，避免重复执行导致数据重复处理\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    \"\"\"\n",
    "    创建平衡数据集的函数\n",
    "    \n",
    "    目的：解决类别不平衡问题（本数据集中 \"ham\" 样本远多于 \"spam\" 样本）\n",
    "    方法：下采样（downsampling）—— 将多数类（ham）的样本数量减少到与少数类（spam）相同\n",
    "    \n",
    "    参数：\n",
    "        df: pandas DataFrame，包含 \"Label\" 和 \"Text\" 两列\n",
    "    \n",
    "    返回：\n",
    "        balanced_df: 平衡后的 DataFrame，两个类别的样本数量相等\n",
    "    \"\"\"\n",
    "    \n",
    "    # 步骤 1：统计 \"spam\" 类别的样本数量\n",
    "    # df[df[\"Label\"] == \"spam\"]: 布尔索引，筛选出所有标签为 \"spam\" 的行\n",
    "    # .shape[0]: 获取行数（即 \"spam\" 样本的总数）\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    # 根据前面的输出，num_spam = 747\n",
    "    \n",
    "    # 步骤 2：从 \"ham\" 类别中随机抽取与 \"spam\" 数量相同的样本\n",
    "    # df[df[\"Label\"] == \"ham\"]: 筛选出所有标签为 \"ham\" 的行（原本有 4825 个）\n",
    "    # .sample(num_spam, random_state=123): 随机抽取 num_spam 个样本\n",
    "    #   - num_spam: 抽取的样本数量（这里是 747）\n",
    "    #   - random_state=123: 设置随机种子，确保每次运行结果一致（可复现性）\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    # 结果：ham_subset 包含 747 个随机选择的 \"ham\" 样本\n",
    "    \n",
    "    # 步骤 3：合并下采样后的 \"ham\" 数据和所有 \"spam\" 数据\n",
    "    # pd.concat([...]):  pandas 的拼接函数，将多个 DataFrame 按行方向（垂直）合并\n",
    "    #   - ham_subset: 747 个 \"ham\" 样本\n",
    "    #   - df[df[\"Label\"] == \"spam\"]: 747 个 \"spam\" 样本\n",
    "    # 结果：balanced_df 包含 1494 行（747 + 747），两个类别数量相等\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "# 调用函数，创建平衡数据集\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "\n",
    "# 打印类别分布，验证平衡效果\n",
    "# value_counts() 会统计每个类别的出现次数\n",
    "# 预期输出：ham    747\n",
    "#          spam   747\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- 随后我们把标签 \"ham\" 和 \"spam\" 转换为整数类标签“0”和“1”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "%%run_once label_mapping\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- 现在自定义一个函数,用于把数据集随机划分为训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    \"\"\"\n",
    "    将数据集随机划分为训练集、验证集和测试集\n",
    "    \n",
    "    参数说明：\n",
    "        df: pandas DataFrame，待划分的数据集\n",
    "        train_frac: float，训练集占总数据集的比例（例如 0.7 表示 70%）\n",
    "        validation_frac: float，验证集占总数据集的比例（例如 0.1 表示 10%）\n",
    "        \n",
    "    返回值：\n",
    "        train_df: 训练集 DataFrame\n",
    "        validation_df: 验证集 DataFrame\n",
    "        test_df: 测试集 DataFrame（剩余部分，比例 = 1 - train_frac - validation_frac）\n",
    "    \"\"\"\n",
    "    \n",
    "    # 步骤 1：打乱数据集顺序（随机化）\n",
    "    # df.sample(frac=1, ...): 对 DataFrame 进行随机采样\n",
    "    #   - frac=1: 采样比例为 100%，即返回所有行，但顺序被打乱\n",
    "    #   - random_state=123: 设置随机种子，确保每次运行结果一致（可复现性）\n",
    "    # .reset_index(drop=True): 重置索引\n",
    "    #   - 打乱后原索引会变得无序（例如 [523, 12, 891, ...]）\n",
    "    #   - drop=True: 丢弃旧索引，生成新的连续索引 [0, 1, 2, ...]\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # 步骤 2：计算各数据集的分割点（索引位置）\n",
    "    # train_end: 训练集的结束位置（也是验证集的起始位置）\n",
    "    #   - len(df): 数据集总行数（例如 1494）\n",
    "    #   - len(df) * train_frac: 训练集应包含的行数（例如 1494 * 0.7 = 1045.8）\n",
    "    #   - int(...): 向下取整，得到整数索引（例如 1045）\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    \n",
    "    # validation_end: 验证集的结束位置（也是测试集的起始位置）\n",
    "    #   - int(len(df) * validation_frac): 验证集应包含的行数（例如 1494 * 0.1 = 149.4 → 149）\n",
    "    #   - train_end + ...: 从训练集结束位置开始累加（例如 1045 + 149 = 1194）\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # 步骤 3：根据计算出的分割点切片 DataFrame\n",
    "    # train_df: 从索引 0 到 train_end（不包含 train_end）\n",
    "    #   - 例如 df[0:1045]，包含前 1045 行\n",
    "    train_df = df[:train_end]\n",
    "    \n",
    "    # validation_df: 从 train_end 到 validation_end（不包含 validation_end）\n",
    "    #   - 例如 df[1045:1194]，包含 149 行\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    \n",
    "    # test_df: 从 validation_end 到末尾\n",
    "    #   - 例如 df[1194:]，包含剩余的 300 行（1494 - 1194 = 300）\n",
    "    #   - 测试集比例 = 1 - train_frac - validation_frac = 1 - 0.7 - 0.1 = 0.2（20%）\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "\n",
    "# 调用函数，将 balanced_df 划分为三个数据集\n",
    "# 参数说明：\n",
    "#   - balanced_df: 之前创建的平衡数据集（1494 行，spam 和 ham 各 747 个）\n",
    "#   - 0.7: 训练集占 70%（约 1045 个样本）\n",
    "#   - 0.1: 验证集占 10%（约 149 个样本）\n",
    "#   - 剩余 20% 自动分配给测试集（约 300 个样本）\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "# 将三个数据集保存为 CSV 文件\n",
    "# to_csv(...) 参数说明：\n",
    "#   - 第一个参数: 文件名（保存在当前工作目录）\n",
    "#   - index=None: 不保存 DataFrame 的索引列（只保存 Label 和 Text 两列）\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)\n",
    "\n",
    "# 结果：\n",
    "# - train.csv: 约 1045 行（70%）\n",
    "# - validation.csv: 约 149 行（10%）\n",
    "# - test.csv: 约 300 行（20%）\n",
    "# 三个文件都包含 Label 和 Text 两列，可用于后续的模型训练、验证和测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 创建数据加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- 由于文本消息长度随机,因此在批量化组合训练数据之前要做数据归一化,我们有两种操作可供选择\n",
    "  1. 将所有消息截断到数据集中最短消息的长度或批次长度\n",
    "  2. 将所有消息填充到数据集中最长消息的长度或批次长度\n",
    "\n",
    "- 这里我们选择操作2,填充数据\n",
    "- 并且,我们使用`<|endoftext|>` 作为填充标识符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"../image/5.png\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "# 打印<|endoftext|>对应的词元id\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- 下面我们首先将 `SpamDataset` 训练数据集中最长的序列，然后将填充token（<|endoftext|>）添加到其他序列末端以匹配该序列长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    \"\"\"\n",
    "    垃圾邮件分类数据集类\n",
    "    \n",
    "    功能：\n",
    "    1. 从 CSV 文件加载文本数据和标签\n",
    "    2. 使用 tokenizer 将文本编码为词元 ID 序列\n",
    "    3. 对序列进行截断或填充，使所有样本长度一致\n",
    "    4. 提供 PyTorch DataLoader 所需的标准接口\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        \n",
    "        参数：\n",
    "            csv_file (str): CSV 文件路径，包含 'Label' 和 'Text' 两列\n",
    "            tokenizer: 分词器对象（如 tiktoken），用于将文本编码为词元 ID\n",
    "            max_length (int, optional): 序列的最大长度\n",
    "                - 如果为 None，则自动计算数据集中最长序列的长度\n",
    "                - 如果指定值，则截断超过该长度的序列\n",
    "            pad_token_id (int): 填充词元的 ID，默认 50256 是 GPT-2 的 <|endoftext|> 标记\n",
    "        \"\"\"\n",
    "        # 步骤 1: 从 CSV 文件读取数据到 pandas DataFrame\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # 步骤 2: 将所有文本编码为词元 ID 列表\n",
    "        # 例如：\"Hello world\" -> [15496, 995] (具体 ID 取决于 tokenizer)\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "        \n",
    "        # 步骤 3: 确定序列的最大长度\n",
    "        if max_length is None:\n",
    "            # 如果未指定 max_length，则计算数据集中最长序列的长度\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            # 如果指定了 max_length，则使用该值\n",
    "            self.max_length = max_length\n",
    "            \n",
    "            # 截断所有超过 max_length 的序列\n",
    "            # 例如：如果 max_length=100，则 [1,2,3,...,150] -> [1,2,3,...,100]\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # 步骤 4: 填充所有序列到相同长度（self.max_length）\n",
    "        # 对于长度不足的序列，在末尾添加 pad_token_id\n",
    "        # 例如：如果 max_length=100，序列 [1,2,3] -> [1,2,3,50256,50256,...,50256] (共100个元素)\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取指定索引的单个样本\n",
    "        \n",
    "        这是 PyTorch Dataset 的必需方法，DataLoader 会调用它来获取数据\n",
    "        \n",
    "        参数：\n",
    "            index (int): 样本索引\n",
    "            \n",
    "        返回：\n",
    "            tuple: (编码后的文本张量, 标签张量)\n",
    "                - 编码后的文本: shape [max_length]，dtype=torch.long\n",
    "                - 标签: 标量张量，0 表示正常邮件(ham)，1 表示垃圾邮件(spam)\n",
    "        \"\"\"\n",
    "        # 获取编码后的文本（已经过填充，长度为 self.max_length）\n",
    "        encoded = self.encoded_texts[index]\n",
    "        \n",
    "        # 获取对应的标签（0 或 1）\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        \n",
    "        # 将列表转换为 PyTorch 张量并返回\n",
    "        # dtype=torch.long 是因为词元 ID 和标签都是整数\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集的样本总数\n",
    "        \n",
    "        这是 PyTorch Dataset 的必需方法，DataLoader 需要知道数据集大小\n",
    "        \n",
    "        返回：\n",
    "            int: 数据集中的样本数量\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        \"\"\"\n",
    "        计算数据集中最长编码序列的长度（私有辅助方法）\n",
    "        \n",
    "        遍历所有已编码的文本，找出最长的序列长度\n",
    "        这个方法仅在 max_length=None 时被调用\n",
    "        \n",
    "        返回：\n",
    "            int: 最长序列的长度\n",
    "        \"\"\"\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# 创建训练数据集实例\n",
    "# 这里使用我们之前定义的 SpamDataset 类来加载和处理训练数据\n",
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",           # 指定训练数据的 CSV 文件路径\n",
    "    max_length=None,                # max_length=None 表示自动计算数据集中最长序列的长度\n",
    "                                    # SpamDataset 会调用 _longest_encoded_length() 方法\n",
    "                                    # 遍历所有样本找出最长的编码序列，并将其设为 max_length\n",
    "    tokenizer=tokenizer             # 传入之前初始化的 GPT-2 分词器\n",
    "                                    # 用于将文本转换为词元 ID\n",
    ")\n",
    "\n",
    "# 打印训练集中最长序列的长度\n",
    "# 这个值是通过 _longest_encoded_length() 方法自动计算得出的\n",
    "# 后续会用这个长度来统一填充验证集和测试集，确保所有批次的张量形状一致\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- 我们还将验证和测试集填充到最长的训练序列\n",
    "- 在本节代码中,任何超过最长训练示例长度的验证集和测试集样本都将使用之前定义的 `SpamDataset` 中的代码 `encoded_text[:self.max_length]`进行截断\n",
    "- 此行为完全是可选的，如果我们在验证和测试集情况下都设置 `max_length=Non`，代码也能正常运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "#将验证集和测试集数据填充到最长序列的长度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- 接下来，我们使用数据集来实例化数据加载器，这与前几章中创建数据加载器类似"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"../image/6.png\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "# 从 PyTorch 导入 DataLoader 类,用于批量加载数据\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# num_workers: 数据加载时使用的子进程数量\n",
    "# 设为 0 表示在主进程中加载数据(适合小数据集或调试)\n",
    "# 在大数据集上可以设为 2-4 来加速数据加载\n",
    "num_workers = 0\n",
    "\n",
    "# batch_size: 每个批次包含的样本数量\n",
    "# 这里设为 8,意味着每次迭代会同时处理 8 个文本样本\n",
    "# 较大的 batch_size 可以提高训练稳定性,但会占用更多显存\n",
    "batch_size = 8\n",
    "\n",
    "# 设置随机种子确保可复现性\n",
    "# 这会影响 shuffle=True 时的数据打乱顺序\n",
    "# 使用相同的种子可以在不同运行中得到相同的训练批次顺序\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# ========== 训练集数据加载器 ==========\n",
    "# 用于在训练过程中批量加载训练数据\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,      # 传入之前创建的训练数据集\n",
    "    batch_size=batch_size,      # 每批 8 个样本\n",
    "    shuffle=True,               # shuffle=True: 每个 epoch 开始时打乱数据顺序\n",
    "                                # 这有助于防止模型记住样本顺序,提高泛化能力\n",
    "    num_workers=num_workers,    # 使用 0 个子进程(主进程加载)\n",
    "    drop_last=True,             # drop_last=True: 丢弃最后一个不完整的批次\n",
    "                                # 例如:如果有 1494 个样本,batch_size=8\n",
    "                                # 最后会剩余 6 个样本(1494 % 8 = 6),这 6 个样本会被丢弃\n",
    "                                # 这样可以确保每个批次的大小都是 8,避免最后一个小批次影响训练\n",
    ")\n",
    "\n",
    "# ========== 验证集数据加载器 ==========\n",
    "# 用于在训练过程中定期评估模型性能\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,        # 传入验证数据集\n",
    "    batch_size=batch_size,      # 保持相同的批次大小\n",
    "    num_workers=num_workers,    # 使用相同的加载进程数\n",
    "    drop_last=False,            # drop_last=False: 保留最后一个不完整的批次\n",
    "                                # 验证时我们希望评估所有样本,不丢弃任何数据\n",
    "                                # 注意:验证集不需要 shuffle,因为评估顺序不影响结果\n",
    ")\n",
    "\n",
    "# ========== 测试集数据加载器 ==========\n",
    "# 用于最终评估模型在未见过数据上的性能\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,       # 传入测试数据集\n",
    "    batch_size=batch_size,      # 保持相同的批次大小\n",
    "    num_workers=num_workers,    # 使用相同的加载进程数\n",
    "    drop_last=False,            # drop_last=False: 保留所有测试样本\n",
    "                                # 测试时必须评估完整的测试集\n",
    "                                # 同样不需要 shuffle,保持数据原始顺序即可\n",
    ")\n",
    "\n",
    "# 总结:\n",
    "# - 训练集: shuffle=True(打乱), drop_last=True(丢弃不完整批次)\n",
    "# - 验证集: 无 shuffle(不打乱), drop_last=False(保留所有数据)\n",
    "# - 测试集: 无 shuffle(不打乱), drop_last=False(保留所有数据)\n",
    "# 这是深度学习中标准的数据加载器配置模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- 作为验证步骤，我们遍历数据加载器，并确保每个批次包含 8 个训练样本，其中每个训练样本由 120 个 token 组成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# ========== 验证数据加载器的输出 ==========\n",
    "# 这段代码用于检查 DataLoader 是否正确工作,以及数据的形状是否符合预期\n",
    "\n",
    "print(\"Train loader:\")\n",
    "\n",
    "# 遍历训练数据加载器\n",
    "# - input_batch: 输入文本的 token ID 张量,形状为 (batch_size, max_length)\n",
    "# - target_batch: 对应的标签张量,形状为 (batch_size,)\n",
    "#   其中 0 表示 ham(正常消息), 1 表示 spam(垃圾消息)\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "    # 注意:这里使用 pass 是因为我们只需要遍历一次就能获取最后一个批次\n",
    "    # 循环会一直执行直到遍历完所有批次,最后 input_batch 和 target_batch\n",
    "    # 会保留最后一个批次的数据\n",
    "    \n",
    "    # 原注释\"如果这个数据在训练集出现过,则跳过\"是不准确的\n",
    "    # 实际上这里没有做任何跳过操作,只是简单地遍历所有批次\n",
    "\n",
    "# 打印最后一个批次的维度信息\n",
    "# input_batch.shape 应该是 (8, 120):\n",
    "# - 8: batch_size,每批 8 个样本\n",
    "# - 120: max_length,每个样本被填充/截断到 120 个 token\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "\n",
    "# target_batch.shape 应该是 (8,):\n",
    "# - 8: batch_size,每批 8 个标签\n",
    "# - 每个标签是一个标量(0 或 1)\n",
    "print(\"Label batch dimensions\", target_batch.shape)\n",
    "\n",
    "# 预期输出示例:\n",
    "# Train loader:\n",
    "# Input batch dimensions: torch.Size([8, 120])\n",
    "# Label batch dimensions torch.Size([8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- 最后，让我们通过打印来查看每个数据集的批次数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 用预训练权重初始化模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- 在本节中，我们将初始化在上一章中使用的预训练模型\n",
    "\n",
    "<img src=\"../image/7.png\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 模型选择与配置\n",
    "# ============================================================================\n",
    "\n",
    "# 选择要使用的 GPT-2 模型变体\n",
    "# 可选项: \"gpt2-small (124M)\", \"gpt2-medium (355M)\", \"gpt2-large (774M)\", \"gpt2-xl (1558M)\"\n",
    "# 数字表示模型的参数量（例如 124M = 1.24亿参数）\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "# 用于测试模型生成能力的输入提示（在后续代码中会用到）\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "# ============================================================================\n",
    "# 基础配置字典\n",
    "# ============================================================================\n",
    "# 定义所有 GPT-2 模型变体共享的基础配置参数\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # 词表大小：GPT-2 使用的 BPE 词表包含 50257 个 token\n",
    "    \"context_length\": 1024,  # 上下文长度：模型一次能处理的最大 token 数量（位置编码的最大长度）\n",
    "    \"drop_rate\": 0.0,        # Dropout 率：设为 0.0 表示不使用 dropout（推理时通常关闭）\n",
    "    \"qkv_bias\": True         # 查询-键-值偏置：在注意力机制的 Q、K、V 线性变换中是否使用偏置项\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# 不同模型变体的特定配置\n",
    "# ============================================================================\n",
    "# 定义各个 GPT-2 模型变体的架构参数\n",
    "# - emb_dim: 嵌入维度（隐藏层大小），决定了模型的\"宽度\"\n",
    "# - n_layers: Transformer 层数，决定了模型的\"深度\"\n",
    "# - n_heads: 多头注意力的头数，必须能整除 emb_dim\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# 合并配置\n",
    "# ============================================================================\n",
    "# 将选定模型的特定参数（emb_dim, n_layers, n_heads）合并到基础配置中\n",
    "# 这样 BASE_CONFIG 就包含了初始化模型所需的所有参数\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "# ============================================================================\n",
    "# 数据集长度验证\n",
    "# ============================================================================\n",
    "# 断言检查：确保数据集的最大序列长度不超过模型的上下文窗口\n",
    "# \n",
    "# 为什么需要这个检查？\n",
    "# - 模型的位置编码只支持到 context_length（1024）的长度\n",
    "# - 如果输入序列超过这个长度，模型无法正确处理\n",
    "# - train_dataset.max_length 是在前面创建数据集时设置的（通常是 120）\n",
    "# \n",
    "# 如果检查失败会怎样？\n",
    "# - 程序会抛出 AssertionError 并显示错误消息\n",
    "# - 错误消息会提示用户需要用正确的 max_length 重新初始化数据集\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "022a649a-44f5-466c-8a8e-326c063384f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022a649a-44f5-466c-8a8e-326c063384f5",
    "outputId": "7091e401-8442-4f47-a1d9-ecb42a1ef930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-27 22:17:04.149934: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-27 22:17:04.235486: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-27 22:17:06.059070: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 步骤 1: 导入必要的模块\n",
    "# ============================================================================\n",
    "# - gpt_download.download_and_load_gpt2: 从 OpenAI 下载预训练的 GPT-2 权重文件\n",
    "# - previous_chapters.GPTModel: 我们在前面章节实现的 GPT 模型架构类\n",
    "# - previous_chapters.load_weights_into_gpt: 将下载的权重加载到我们的模型中的工具函数\n",
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "# ============================================================================\n",
    "# 步骤 2: 解析模型大小字符串\n",
    "# ============================================================================\n",
    "# CHOOSE_MODEL 的格式示例: \"gpt2-small (124M)\"\n",
    "# 我们需要提取括号中的模型大小标识 \"124M\"\n",
    "# \n",
    "# 字符串处理步骤:\n",
    "# 1. split(\" \")[-1]  → 按空格分割,取最后一个元素 → \"(124M)\"\n",
    "# 2. lstrip(\"(\")     → 去掉左边的 \"(\" → \"124M)\"\n",
    "# 3. rstrip(\")\")     → 去掉右边的 \")\" → \"124M\"\n",
    "# \n",
    "# 最终 model_size = \"124M\" (或 \"355M\", \"774M\", \"1558M\" 等)\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "# ============================================================================\n",
    "# 步骤 3: 下载并加载预训练权重\n",
    "# ============================================================================\n",
    "# download_and_load_gpt2 函数会:\n",
    "# 1. 检查本地 \"gpt2\" 目录是否已有对应模型的权重文件\n",
    "# 2. 如果没有,从 OpenAI 的服务器下载 (checkpoint, encoder, hparams 等文件)\n",
    "# 3. 加载权重并返回两个对象:\n",
    "#    - settings: 模型的超参数配置 (dict),包含层数、隐藏层大小等\n",
    "#    - params: 实际的权重参数 (dict),包含所有层的权重和偏置\n",
    "# \n",
    "# 参数说明:\n",
    "# - model_size: 模型规模标识 (\"124M\", \"355M\" 等)\n",
    "# - models_dir: 权重文件的存储目录 (会在当前目录下创建 \"gpt2\" 文件夹)\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "# ============================================================================\n",
    "# 步骤 4: 初始化模型架构\n",
    "# ============================================================================\n",
    "# 使用 BASE_CONFIG 创建一个\"空\"的 GPT 模型\n",
    "# 此时模型的权重是随机初始化的,还不能生成有意义的文本\n",
    "# \n",
    "# BASE_CONFIG 包含的关键参数:\n",
    "# - vocab_size: 50257 (词表大小)\n",
    "# - context_length: 1024 (最大序列长度)\n",
    "# - emb_dim: 768/1024/1280/1600 (嵌入维度,取决于模型大小)\n",
    "# - n_layers: 12/24/36/48 (Transformer 层数)\n",
    "# - n_heads: 12/16/20/25 (注意力头数)\n",
    "# - drop_rate: 0.0 (Dropout 率,推理时为 0)\n",
    "# - qkv_bias: True (注意力机制是否使用偏置)\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "\n",
    "# ============================================================================\n",
    "# 步骤 5: 加载预训练权重\n",
    "# ============================================================================\n",
    "# load_weights_into_gpt 函数会:\n",
    "# 1. 遍历 params 字典中的所有权重\n",
    "# 2. 将每个权重张量复制到模型对应的参数中\n",
    "# 3. 处理权重形状的转换 (如果需要)\n",
    "# \n",
    "# 加载后,模型就具备了 OpenAI 预训练的知识,可以:\n",
    "# - 生成连贯的文本\n",
    "# - 理解语言的语法和语义\n",
    "# - 作为下游任务 (如分类) 的起点进行微调\n",
    "load_weights_into_gpt(model, params)\n",
    "\n",
    "# ============================================================================\n",
    "# 步骤 6: 切换到评估模式\n",
    "# ============================================================================\n",
    "# model.eval() 的作用:\n",
    "# 1. 禁用 Dropout: 推理时不需要随机丢弃神经元\n",
    "# 2. 固定 BatchNorm (如果有): 使用训练时统计的均值和方差\n",
    "# 3. 确保模型行为的确定性: 相同输入总是产生相同输出\n",
    "# \n",
    "# 注意:\n",
    "# - 这不会冻结模型参数 (仍然可以进行微调)\n",
    "# - 如果要微调,需要在训练循环中调用 model.train()\n",
    "# - 如果只是推理,保持 eval() 模式即可\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- 为了确保模型已正确加载，让我们仔细检查它是否生成了连贯的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 导入文本生成相关的工具函数\n",
    "# ============================================================================\n",
    "# 这些函数来自前面章节的实现,用于:\n",
    "# - generate_text_simple: 使用模型生成文本的简单实现\n",
    "# - text_to_token_ids: 将文本字符串转换为 token ID 序列\n",
    "# - token_ids_to_text: 将 token ID 序列转换回文本字符串\n",
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 测试预训练模型的文本生成能力\n",
    "# ============================================================================\n",
    "# 输入一个简单的提示文本,看模型能否生成连贯的续写\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "# ============================================================================\n",
    "# 步骤 1: 将输入文本转换为 token IDs\n",
    "# ============================================================================\n",
    "# text_to_token_ids(text_1, tokenizer) 会:\n",
    "# 1. 使用 tokenizer 将文本分词\n",
    "# 2. 将每个 token 映射为对应的整数 ID\n",
    "# 3. 返回一个形状为 [1, seq_len] 的张量 (batch_size=1)\n",
    "# \n",
    "# 步骤 2: 使用模型生成新的 token\n",
    "# ============================================================================\n",
    "# generate_text_simple 函数会:\n",
    "# 1. 接收初始 token IDs (idx 参数)\n",
    "# 2. 循环生成 max_new_tokens 个新 token (这里是 15 个)\n",
    "# 3. 每次生成时:\n",
    "#    - 将当前序列输入模型\n",
    "#    - 获取最后一个位置的 logits\n",
    "#    - 选择概率最高的 token (贪婪解码)\n",
    "#    - 将新 token 追加到序列中\n",
    "# 4. 返回完整的 token ID 序列 (原始输入 + 新生成的)\n",
    "# \n",
    "# context_size 参数:\n",
    "# - 限制输入序列的最大长度为 BASE_CONFIG[\"context_length\"] (1024)\n",
    "# - 如果序列超过此长度,会截断最早的 token\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 步骤 3: 将生成的 token IDs 转换回文本并打印\n",
    "# ============================================================================\n",
    "# token_ids_to_text 会:\n",
    "# 1. 将 token ID 序列解码为文本字符串\n",
    "# 2. 处理特殊 token (如 <|endoftext|>)\n",
    "# 3. 返回人类可读的文本\n",
    "# \n",
    "# 预期输出:\n",
    "# - 应该是 \"Every effort moves you\" 后面跟着 15 个新生成的 token\n",
    "# - 如果模型加载正确,生成的文本应该是连贯且符合语法的\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- 在我们将模型微调为分类器之前，让我们看看该模型是否已经可以通过提示对垃圾邮件进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 测试预训练模型的零样本分类能力\n",
    "# ============================================================================\n",
    "# 这里我们尝试让预训练的 GPT 模型直接进行垃圾邮件分类,而不进行任何微调\n",
    "# 这被称为\"零样本学习\"(zero-shot learning)\n",
    "\n",
    "# 构造一个提示文本,要求模型判断给定文本是否为垃圾邮件\n",
    "# 提示格式:\n",
    "# - 明确的指令: \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "# - 待分类的文本: 一条典型的垃圾邮件(包含中奖、现金奖励等关键词)\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 使用模型生成回答\n",
    "# ============================================================================\n",
    "# 步骤 1: text_to_token_ids(text_2, tokenizer)\n",
    "#   - 将提示文本转换为 token IDs\n",
    "#   - 返回形状为 [1, seq_len] 的张量\n",
    "#\n",
    "# 步骤 2: generate_text_simple 生成 23 个新 token\n",
    "#   - max_new_tokens=23: 生成足够长的回答(期望模型回答 \"yes\" 或 \"no\")\n",
    "#   - 使用贪婪解码策略(每次选择概率最高的 token)\n",
    "#   - context_size 限制输入序列长度不超过 1024\n",
    "#\n",
    "# 注意: 由于模型只经过了预训练(next-token prediction),\n",
    "#       并未经过指令微调(instruction fine-tuning),\n",
    "#       因此可能无法很好地遵循\"回答 yes 或 no\"的指令\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 将生成的 token IDs 转换回文本并打印\n",
    "# ============================================================================\n",
    "# 预期结果:\n",
    "# - 理想情况: 模型应该回答 \"yes\"(因为这是一条明显的垃圾邮件)\n",
    "# - 实际情况: 由于模型未经过指令微调,可能会生成不相关的文本,\n",
    "#            或者继续补全提示而不是直接回答问题\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- 正如我们所看到的，该模型不太擅长遵循指示\n",
    "- 这是意料之中的，因为它只是经过了预训练，还没有经过指令微调（指令微调将在下一章中介绍）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 添加分类头"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"../image/8.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- 在本节中，我们将修改预训练的 LLM，为分类微调做准备\n",
    "- 首先，让我们先看一下模型的架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- 我们可以看到,在第 4 章中实现的架构\n",
    "- 我们的目标是替换和微调输出层\n",
    "- 为了实现这一点，我们首先冻结模型，这意味着我们使所有层都是不可训练的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# 返回 model 中所有的参数,但是不参与反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- 然后，我们替换输出层`(model.out_head)`，它最初将层输入映射到 50,257 个维度（词汇表的大小）\n",
    "- 由于我们对二元分类模型进行了微调（预测 2 个类别，“spam”和“not spam”），因此我们可以替换如下所示的输出层，默认情况下它是可训练的\n",
    "- 我们使用 `BASE_CONFIG[\"emb_dim\"]`（在 “gpt2-small （124M）” 模型中为 768）来保持下面的代码更通用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子以确保结果可复现\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 定义分类任务的类别数量\n",
    "# 对于垃圾邮件分类任务,我们只需要 2 个类别:spam(垃圾邮件) 和 ham(正常邮件)\n",
    "num_classes = 2\n",
    "\n",
    "# 替换模型的输出层(分类头)\n",
    "# 原始的 out_head 将嵌入维度(768)映射到词汇表大小(50257),用于生成文本\n",
    "# 现在我们将其替换为一个新的线性层,将嵌入维度映射到类别数量(2)\n",
    "# in_features: 输入特征维度,即模型的嵌入维度(对于 gpt2-small 是 768)\n",
    "# out_features: 输出特征维度,即分类任务的类别数量(这里是 2)\n",
    "# 这个新创建的层默认是可训练的(requires_grad=True)\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- 从技术上讲，只需训练输出层就足够了\n",
    "- 但是，正如在 [Finetuning Large Language Models](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)中表明，微调其他层可以显著提高性能\n",
    "- 因此，我们还使最后一个 transformer 模块和最后一个 `LayerNorm` 模块连接起来，将最后一个 transformer 模块连接到输出层，使其可训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"../image/9.png\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "# 解冻最后一个 Transformer 块,使其参数可训练\n",
    "# model.trf_blocks[-1] 表示获取 Transformer 块列表中的最后一个块\n",
    "# .parameters() 返回该块中所有的参数(权重和偏置)\n",
    "# 通过设置 requires_grad = True,这些参数将在反向传播时计算梯度并更新\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 解冻最后的 LayerNorm 层,使其参数可训练\n",
    "# model.final_norm 是连接最后一个 Transformer 块和输出层之间的归一化层\n",
    "# 这一层对于稳定训练和提高模型性能很重要\n",
    "# 同样设置 requires_grad = True 使其参数可以在训练中更新\n",
    "for param in model.final_norm.parameters(): \n",
    "    param.requires_grad = True\n",
    "\n",
    "# 总结:\n",
    "# 1. 之前我们冻结了整个模型(所有参数 requires_grad = False)\n",
    "# 2. 然后替换了输出层(新层默认 requires_grad = True)\n",
    "# 3. 现在我们额外解冻最后一个 Transformer 块和 final_norm\n",
    "# 4. 这样做的好处是:既保留了预训练知识(前面的层冻结),又允许模型适应新任务(后面的层可训练)\n",
    "# 5. 这种策略在实践中通常比只训练输出层效果更好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- 即使我们添加了新的输出层并标记了某些层为可训练或不可训练，我们仍然可以像之前一样使用这个模型\n",
    "- 例如,我们输入点文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 使用 tokenizer 将文本 \"Do you have time\" 编码为 token IDs\n",
    "# tokenizer.encode() 会将文本分词并转换为对应的整数 ID 列表\n",
    "# 例如: \"Do you have time\" 可能被编码为 [5211, 345, 423, 640] (具体数字取决于 tokenizer)\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "\n",
    "# 将 Python 列表转换为 PyTorch 张量,并添加批次维度\n",
    "# torch.tensor(inputs): 将列表转换为 1 维张量,例如 shape 为 [4]\n",
    "# .unsqueeze(0): 在第 0 维添加一个维度,将 shape 从 [4] 变为 [1, 4]\n",
    "# 这是因为模型期望输入的 shape 为 [batch_size, sequence_length]\n",
    "# 即使只有一个样本,也需要批次维度\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "\n",
    "# 打印编码后的 token IDs\n",
    "# 输出示例: Inputs: tensor([[5211, 345, 423, 640]])\n",
    "print(\"Inputs:\", inputs)\n",
    "\n",
    "# 打印输入张量的形状\n",
    "# 输出示例: Inputs dimensions: torch.Size([1, 4])\n",
    "# 其中 1 是批次大小(batch size), 4 是序列长度(sequence length,即 token 数量)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- 与前几章相比，它现在有两个输出维度，而不再是 50,257 个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # 形状：（批次大小，词元数量）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- 如前几章所述，对于每个 input token，模型都会返回一个 output vector\n",
    "- 由于我们向模型提供了具有 4 个输入 token 的文本样本，因此输出由上面的 4 个 2 维输出向量组成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"../image/10.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- 在第 3 章中，我们讨论了attention机制，它将每个输入 token 连接到另一个输入 token\n",
    "- 在第 3 章中，我们还介绍了类 GPT 模型中使用的因果注意力掩码(causal attention mask);这种掩码让当前token只关注当前和先前出现过的位置\n",
    "- 基于这种因果注意力机制，第 4 个（最后一个）token在所有token中包含最多的信息，因为唯一包含所有其他全部信息只有它\n",
    "- 因此，我们在微调过程中格外关注这个最后的词元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# 提取并打印最后一个 token 的输出向量\n",
    "# outputs 的形状是 [batch_size, sequence_length, num_features]\n",
    "# 在这个例子中是 [1, 4, 2] (1个样本, 4个token, 2个输出特征)\n",
    "# \n",
    "# 索引解释:\n",
    "# - outputs[:, -1, :] 的含义:\n",
    "#   - 第一个 ':' 表示选择所有批次(这里只有1个批次)\n",
    "#   - '-1' 表示选择序列中的最后一个 token(第4个token)\n",
    "#   - 最后的 ':' 表示选择该 token 的所有输出特征(2个特征)\n",
    "# \n",
    "# 为什么关注最后一个 token?\n",
    "# - 由于因果注意力机制(causal attention mask),最后一个 token 能够\"看到\"\n",
    "#   序列中所有之前的 token(包括它自己)\n",
    "# - 因此,最后一个 token 的输出包含了整个输入序列的聚合信息\n",
    "# - 这使得它最适合用于分类任务,因为它综合了全部上下文\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"../image/11.png\" width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 计算分类损失和准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"../image/12.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- 在解释损失计算之前，让我们简单了解一下模型输出是如何转换为类标签的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"../image/13.png\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- 与第 5 章类似，我们通过 `softmax` 函数将输出 （logits） 转换为概率分数，然后通过`argmax`函数获得最大概率值的索引位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "# 步骤1: 将 logits 转换为概率分布\n",
    "# - outputs[:, -1, :] 是最后一个 token 的输出 logits (原始分数)\n",
    "# - dim=-1 表示在最后一个维度(特征维度)上应用 softmax\n",
    "# - softmax 将任意实数转换为 [0, 1] 范围内的概率,且所有概率之和为 1\n",
    "# 例如: logits [-2.1, 0.3] -> probas [0.09, 0.91]\n",
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "\n",
    "# 步骤2: 找到概率最大的类别\n",
    "# - torch.argmax 返回最大值所在的索引位置\n",
    "# - 这个索引就是模型预测的类别标签\n",
    "# 例如: probas [0.09, 0.91] -> label = 1 (第1个位置概率最大)\n",
    "label = torch.argmax(probas)\n",
    "\n",
    "# 步骤3: 输出预测的类别标签\n",
    "# - .item() 将 PyTorch 张量转换为 Python 标量值\n",
    "# - 对于二分类任务: 0 通常表示 \"ham\"(正常消息), 1 表示 \"spam\"(垃圾消息)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- 如第 5 章所述，softmax 函数在这里是可选的，因为最大的输出对应于最大的概率分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- 我们可以应用这个概念来计算所谓的\"分类准确性\"，计算给定数据集中正确预测的百分比\n",
    "- 为了计算分类准确率，我们可以将前面基于 `argmax` 的预测代码应用于数据集中的所有示例，并按如下方式计算正确预测的分数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"\n",
    "    计算模型在数据加载器上的分类准确率\n",
    "    \n",
    "    参数:\n",
    "        data_loader: PyTorch DataLoader 对象,包含输入数据和标签\n",
    "        model: 要评估的模型(GPT模型)\n",
    "        device: 运行设备('cuda', 'mps' 或 'cpu')\n",
    "        num_batches: 要评估的批次数量,None表示评估所有批次\n",
    "    \n",
    "    返回:\n",
    "        float: 分类准确率(0到1之间的值)\n",
    "    \"\"\"\n",
    "    # 将模型设置为评估模式\n",
    "    # - 这会禁用 dropout 和 batch normalization 的训练行为\n",
    "    # - 确保模型在推理时的行为一致性\n",
    "    model.eval()\n",
    "    \n",
    "    # 初始化计数器\n",
    "    # - correct_predictions: 记录预测正确的样本总数\n",
    "    # - num_examples: 记录已处理的样本总数\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    \n",
    "    # 确定要处理的批次数量\n",
    "    if num_batches is None:\n",
    "        # 如果 num_batches 为 None,则处理数据加载器中的所有批次\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 如果指定了 num_batches,取它与数据加载器总批次数中的较小值\n",
    "        # 这样可以避免索引越界,同时支持只评估部分数据(用于快速验证)\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    # 遍历数据加载器中的每个批次\n",
    "    # - enumerate 返回索引 i 和数据 (input_batch, target_batch)\n",
    "    # - input_batch: 输入文本的 token IDs,形状为 [batch_size, seq_length]\n",
    "    # - target_batch: 真实标签,形状为 [batch_size],值为 0(ham) 或 1(spam)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # 只处理前 num_batches 个批次\n",
    "        if i < num_batches:\n",
    "            # 将输入数据和标签移动到指定设备(GPU/MPS/CPU)\n",
    "            # - 这是 PyTorch 中进行 GPU 加速计算的必要步骤\n",
    "            # - 模型和数据必须在同一设备上才能进行计算\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            \n",
    "            # 使用 torch.no_grad() 上下文管理器\n",
    "            # - 禁用梯度计算,节省内存并加速推理\n",
    "            # - 在评估/推理阶段不需要计算梯度(只在训练时需要)\n",
    "            with torch.no_grad():\n",
    "                # 前向传播:将输入传递给模型\n",
    "                # - model(input_batch) 返回形状为 [batch_size, seq_length, vocab_size] 的 logits\n",
    "                # - [:, -1, :] 只取最后一个 token 位置的输出,形状变为 [batch_size, vocab_size]\n",
    "                # - 对于分类任务,我们只关心序列最后一个位置的预测\n",
    "                # - logits 是未归一化的原始分数(还未经过 softmax)\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            \n",
    "            # 从 logits 中获取预测标签\n",
    "            # - torch.argmax 在最后一个维度(dim=-1,即 vocab_size 维度)上找到最大值的索引\n",
    "            # - 返回形状为 [batch_size] 的张量,每个元素是预测的类别(0 或 1)\n",
    "            # - 注意:这里不需要先应用 softmax,因为 argmax 的结果不受单调变换影响\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            # 累加当前批次的样本数量\n",
    "            # - predicted_labels.shape[0] 返回批次大小(batch_size)\n",
    "            # - 用于后续计算准确率时的分母\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            \n",
    "            # 累加当前批次中预测正确的样本数量\n",
    "            # - (predicted_labels == target_batch) 进行逐元素比较,返回布尔张量\n",
    "            # - .sum() 计算 True 的数量(即预测正确的样本数)\n",
    "            # - .item() 将单元素张量转换为 Python 标量值\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "            \n",
    "        else:\n",
    "            # 如果已经处理了 num_batches 个批次,提前退出循环\n",
    "            break\n",
    "    \n",
    "    # 返回分类准确率\n",
    "    # - 准确率 = 预测正确的样本数 / 总样本数\n",
    "    # - 返回值在 0 到 1 之间,例如 0.85 表示 85% 的准确率\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- 用该函数计算不同数据集的分类精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda device.\n",
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Note:\n",
    "\n",
    "#取消注释以下行将允许代码在 Apple Silicon 芯片上运行（如果适用），\n",
    "#这比在 Apple CPU 上运行快大约 2 倍（根据 M3 MacBook Air 的测量结果）。\n",
    "#截至目前，在 PyTorch 2.4 版本中，通过 CPU 和 MPS 得到的结果是相同的。\n",
    "#然而，在 PyTorch 的早期版本中，使用 MPS 时，可能会观察到不同的结果。\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # 对于 nn.Module 类，无需 model = model.to(device)赋值操作\n",
    "\n",
    "torch.manual_seed(123) # 由于训练数据加载器中的随机打乱，因此设置随机种子以确保可重复性\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "#各种计算\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- 可以看到，预测的准确性不是很好，这是因为因为我们还没有对模型进行微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- 在开始微调 （/training） 之前，我们首先必须定义要在训练期间优化的损失函数\n",
    "- 目标是最大限度地提高模型的垃圾邮件分类准确性;\n",
    "- 由于分类准确率不是可微分的，我们使用交叉熵损失作为最大化准确率的替代（您可以在我免费提供的[深度学习入门课程](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression)的第 8 讲中了解有关此主题的更多信息）\n",
    "\n",
    "- `calc_loss_batch` 函数与第 5 章相同，只是我们只对优化最后一个 `tokens model（input_batch）``[：， -1， ：]` 感兴趣，而不是所有 `tokens model（input_batch）`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"\n",
    "    计算单个批次的损失值\n",
    "    \n",
    "    参数:\n",
    "        input_batch: 输入的 token 序列批次，形状为 [batch_size, seq_len]\n",
    "        target_batch: 目标标签批次（0 表示 ham，1 表示 spam），形状为 [batch_size]\n",
    "        model: GPT 模型实例\n",
    "        device: 计算设备（CPU、CUDA 或 MPS）\n",
    "    \n",
    "    返回:\n",
    "        loss: 该批次的交叉熵损失值（标量张量）\n",
    "    \"\"\"\n",
    "    # 将输入数据和目标标签移动到指定设备（GPU/CPU）上进行计算\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    \n",
    "    # 前向传播：将输入序列送入模型\n",
    "    # model(input_batch) 输出形状为 [batch_size, seq_len, vocab_size]\n",
    "    # [:, -1, :] 表示只取每个序列的最后一个 token 的输出 logits\n",
    "    # 因为对于分类任务，我们只关心序列末尾的预测结果\n",
    "    # 最终 logits 形状为 [batch_size, vocab_size]\n",
    "    logits = model(input_batch)[:, -1, :]  # 提取最后一个 token 的 logits 用于分类\n",
    "    \n",
    "    # 计算交叉熵损失\n",
    "    # logits: 模型的原始输出（未经 softmax），形状 [batch_size, vocab_size]\n",
    "    # target_batch: 真实标签（0 或 1），形状 [batch_size]\n",
    "    # cross_entropy 会自动对 logits 应用 softmax，然后计算负对数似然损失\n",
    "    # 这是分类任务的标准损失函数，用于衡量预测分布与真实标签的差异\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "使用 `calc_closs_loader`，我们在开始训练之前计算初始训练集、验证集和测试集损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"\n",
    "    计算整个数据加载器（或指定批次数）的平均损失值\n",
    "    \n",
    "    参数:\n",
    "        data_loader: PyTorch DataLoader 对象，包含输入批次和目标标签\n",
    "        model: GPT 模型实例\n",
    "        device: 计算设备（CPU、CUDA 或 MPS）\n",
    "        num_batches: 可选参数，指定要计算损失的批次数量\n",
    "                     - 如果为 None，则计算所有批次的损失\n",
    "                     - 如果指定了数值，则只计算前 num_batches 个批次的损失\n",
    "                     - 这在快速评估时很有用（例如只用 5 个批次来估算整体损失）\n",
    "    \n",
    "    返回:\n",
    "        平均损失值（浮点数）\n",
    "    \"\"\"\n",
    "    # 初始化累计损失值为 0.0\n",
    "    total_loss = 0.\n",
    "    \n",
    "    # 边界情况 1：如果数据加载器为空（没有数据），返回 NaN（Not a Number）\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    # 情况 2：如果 num_batches 为 None，则计算所有批次的损失\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    \n",
    "    # 情况 3：如果指定了 num_batches，则只计算前 num_batches 个批次\n",
    "    # 注意：这里的 else 分支实际上处理了 num_batches 不为 None 的情况\n",
    "    else:\n",
    "        # 注释掉的代码：原本可以用 min() 来确保 num_batches 不超过数据加载器的总批次数\n",
    "        # 但当前实现通过循环中的 break 来达到同样的效果\n",
    "        # num_batches = min(num_batches, len(data_loader))\n",
    "        pass  # 这里的 else 分支实际上什么都不做，逻辑在下面的循环中处理\n",
    "    \n",
    "    # 遍历数据加载器中的所有批次\n",
    "    # enumerate() 返回索引 i 和数据 (input_batch, target_batch)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        # 只处理前 num_batches 个批次\n",
    "        if i < num_batches:\n",
    "            # 调用 calc_loss_batch 计算当前批次的损失\n",
    "            # 返回的 loss 是一个 PyTorch 张量（标量）\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            \n",
    "            # 将当前批次的损失值累加到总损失中\n",
    "            # .item() 方法将 PyTorch 张量转换为 Python 标量（浮点数）\n",
    "            # 这样可以避免在 GPU 上累积大量的计算图，节省内存\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        else:\n",
    "            # 如果已经处理了 num_batches 个批次，提前退出循环\n",
    "            # 这样可以在不需要遍历整个数据集时节省计算时间\n",
    "            break\n",
    "    \n",
    "    # 返回平均损失：总损失除以批次数\n",
    "    # 这样可以得到每个批次的平均损失，便于比较不同大小数据集的损失\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "# 使用 torch.no_grad() 上下文管理器来禁用梯度计算\n",
    "# 原因：\n",
    "#   1. 我们这里只是评估模型性能，不需要反向传播更新参数\n",
    "#   2. 禁用梯度跟踪可以节省内存（不需要存储中间计算图）\n",
    "#   3. 可以加快计算速度（跳过梯度相关的操作）\n",
    "with torch.no_grad():\n",
    "    # 计算训练集上的平均损失\n",
    "    # num_batches=5 表示只使用前 5 个批次来快速估算损失（而不是遍历整个训练集）\n",
    "    # 这样可以在保持合理准确度的同时大幅减少计算时间\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    \n",
    "    # 计算验证集上的平均损失\n",
    "    # 验证集用于在训练过程中监控模型的泛化能力\n",
    "    # 同样只使用 5 个批次进行快速评估\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    \n",
    "    # 计算测试集上的平均损失\n",
    "    # 测试集用于最终评估模型在未见过数据上的表现\n",
    "    # 注意：测试集应该只在模型完全训练完成后使用一次\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "# 打印三个数据集上的损失值\n",
    "# .3f 表示保留 3 位小数，使输出更易读\n",
    "print(f\"Training loss: {train_loss:.3f}\")      # 训练集损失（通常最低）\n",
    "print(f\"Validation loss: {val_loss:.3f}\")      # 验证集损失（用于调参和早停）\n",
    "print(f\"Test loss: {test_loss:.3f}\")           # 测试集损失（最终性能指标）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- 在下一节中，我们将训练模型以最小化损失值，从而提高分类准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 在有监督数据上微调模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- 在本节中，我们将定义并使用训练函数来提高模型的分类准确率\n",
    "- 下面的 `train_classifier_simple` 函数实际上与我们在第 5 章中用于预训练模型的 `train_model_simple `函数相同\n",
    "- 唯二区别\n",
    "  1. 我们现在跟踪的是已经看到的训练样本数量（examples_seen），而不是token数量\n",
    "  2. 我们在每个周期后计算准确率，而不是打印一个样例文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"../image/14.png\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# 简单的分类器训练函数\n",
    "# 这个函数与第五章的 train_model_simple 函数结构相同，但针对分类任务做了调整\n",
    "# 主要区别：\n",
    "#   1. 跟踪的是已看到的样本数（examples_seen）而不是 token 数\n",
    "#   2. 每个 epoch 结束后计算并记录准确率，而不是生成样本文本\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    \"\"\"\n",
    "    参数说明：\n",
    "        model: 要训练的模型（已添加分类头的 GPT 模型）\n",
    "        train_loader: 训练数据加载器\n",
    "        val_loader: 验证数据加载器\n",
    "        optimizer: 优化器（如 AdamW）\n",
    "        device: 运行设备（'cuda' 或 'cpu'）\n",
    "        num_epochs: 训练的总轮数\n",
    "        eval_freq: 每隔多少步（step）评估一次损失\n",
    "        eval_iter: 评估时使用多少个批次来计算平均损失/准确率\n",
    "    \"\"\"\n",
    "    \n",
    "    # 初始化四个列表，用于记录训练过程中的指标变化\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    \n",
    "    # examples_seen: 记录已经训练过的样本总数（用于监控训练进度）\n",
    "    # global_step: 全局步数计数器，从 -1 开始（第一次循环会变成 0）\n",
    "    examples_seen, global_step = 0, -1\n",
    "    \n",
    "    # 开始训练循环：遍历每个 epoch（训练轮次）\n",
    "    for epoch in range(num_epochs):\n",
    "        # 将模型设置为训练模式\n",
    "        # 训练模式会启用 Dropout、BatchNorm 等层的训练行为\n",
    "        model.train()  \n",
    "        \n",
    "        # 遍历训练数据加载器中的每个批次\n",
    "        # input_batch: 输入数据（token IDs），shape: [batch_size, seq_len]\n",
    "        # target_batch: 目标标签（0 或 1），shape: [batch_size]\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # 步骤 1: 清零梯度\n",
    "            # PyTorch 默认会累积梯度，所以每次反向传播前需要手动清零\n",
    "            optimizer.zero_grad() \n",
    "            \n",
    "            # 步骤 2: 前向传播 - 计算当前批次的损失\n",
    "            # calc_loss_batch 会将数据移到正确的设备上，并计算交叉熵损失\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            \n",
    "            # 步骤 3: 反向传播 - 计算损失相对于模型参数的梯度\n",
    "            # 这一步会自动计算所有需要梯度的参数的偏导数\n",
    "            loss.backward() \n",
    "            \n",
    "            # 步骤 4: 参数更新 - 使用计算出的梯度更新模型权重\n",
    "            # optimizer 会根据其算法（如 AdamW）和学习率来调整参数\n",
    "            optimizer.step() \n",
    "            \n",
    "            # 更新已处理的样本数量\n",
    "            # input_batch.shape[0] 是当前批次的样本数（通常等于 batch_size）\n",
    "            examples_seen += input_batch.shape[0] \n",
    "            \n",
    "            # 全局步数加 1（每处理一个批次就是一步）\n",
    "            global_step += 1\n",
    "\n",
    "            # 定期评估：每隔 eval_freq 步评估一次模型在训练集和验证集上的表现\n",
    "            if global_step % eval_freq == 0:\n",
    "                # 调用 evaluate_model 计算当前模型的训练损失和验证损失\n",
    "                # eval_iter 控制评估时使用多少个批次（避免遍历整个数据集以节省时间）\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                \n",
    "                # 将损失值记录到列表中，用于后续绘图分析\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                # 打印当前的训练进度和损失值\n",
    "                # :06d 表示用 6 位数字显示步数（不足的用 0 填充）\n",
    "                # :.3f 表示保留 3 位小数\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 每个 epoch 结束后，计算并打印准确率\n",
    "        # 这是与第五章的主要区别之一：我们关注分类准确率而不是生成文本质量\n",
    "        \n",
    "        # 计算训练集准确率\n",
    "        # num_batches=eval_iter 表示只用部分批次快速估算（与损失评估一致）\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        \n",
    "        # 计算验证集准确率\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        \n",
    "        # 打印准确率（转换为百分比，保留 2 位小数）\n",
    "        # end=\"\" 表示不换行，让两个 print 输出在同一行\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        \n",
    "        # 将准确率记录到列表中，用于后续分析和绘图\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    # 训练完成，返回所有记录的指标\n",
    "    # 这些数据可用于：\n",
    "    #   - 绘制损失曲线（观察收敛情况）\n",
    "    #   - 绘制准确率曲线（观察模型性能提升）\n",
    "    #   - 检测过拟合（训练集和验证集指标的差距）\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- `evaluate_model` 在`train_classifier_simple` 是跟第五章相同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "    # 调用辅助函数 calc_loss_loader 计算模型在 训练集、验证集上的损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- M3 MacBook Air五分钟训练完\n",
    "- V100 or A100 GPU大概用半分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 0.28 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "# 输出每一次的损失值跟在一定频次下进行准确率输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- 跟第五章相似,我们用Matplot作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "   \n",
    "    ax2 = ax1.twiny()  \n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  \n",
    "\n",
    "    fig.tight_layout()  \n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "# 一个经典的画图操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建 x 轴坐标：从 0 到 num_epochs，生成与 train_losses 长度相同的均匀分布点\n",
    "# 用于在图表中显示\"训练轮次(Epochs)\"维度\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "\n",
    "# 创建第二个 x 轴坐标：从 0 到 examples_seen（已处理的样本总数），生成与 train_losses 长度相同的均匀分布点\n",
    "# 用于在图表中显示\"已处理样本数\"维度（通过 twiny 创建的第二个 x 轴）\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "# 调用绘图函数，绘制训练损失和验证损失随训练进度的变化曲线\n",
    "# - epochs_tensor: 主 x 轴（训练轮次）\n",
    "# - examples_seen_tensor: 辅助 x 轴（已处理样本数）\n",
    "# - train_losses: 训练集损失值列表\n",
    "# - val_losses: 验证集损失值列表\n",
    "# - 默认 label=\"loss\"，图表标题和 y 轴标签会显示 \"loss\"\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- 图中, 根据训练的斜率, 我们可以发现模型训练的很好\n",
    "- 此外, 训练和验证损失非常接近可以表明，该模型不会倾向于过拟合训练数据\n",
    "- 同样的, 我们可以对精度进行绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- 根据上面的准确率图，我们可以看到该模型在第 4 个和第 5 循环之后,训练和验证准确率变得相对较高\n",
    "- 但是，别忘了我们之前在 training 函数中指定了 `eval_iter=5`，这意味着我们只估计了训练和验证集的性能\n",
    "- 我们可以计算完整数据集的训练、验证和测试集性能，如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
    "# 输出总的训练集、验证集和测试集的准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- 我们可以看到，训练集和验证集的表现实际上是相同的。\n",
    "- 然而，由于测试集表现略微较差，我们可以看出，模型在一定程度上对训练数据进行了过拟合，同时也对用于调整超参数（如学习率）的验证数据进行了过拟合。\n",
    "- 不过，这种情况是正常的，并且通过增加模型的 dropout rate（drop_rate）或优化器设置中的 weight_decay，可能进一步减小这种差距。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 使用LLM作为垃圾消息分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"../image/15.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- 最后，让我们将微调后的 GPT 模型投入实际应用。\n",
    "- 以下的 `classify_review` 函数实现了类似于我们之前实现的 `SpamDataset` 的数据预处理步骤。\n",
    "- 然后，函数返回模型预测的整数类别标签，并返回对应的类别名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    \"\"\"\n",
    "    使用微调后的 GPT 模型对文本进行垃圾消息分类\n",
    "    \n",
    "    参数:\n",
    "        text: 待分类的输入文本字符串\n",
    "        model: 微调后的 GPT 模型实例\n",
    "        tokenizer: 用于文本编码的 tokenizer\n",
    "        device: 运行设备（'cpu' 或 'cuda'）\n",
    "        max_length: 输入序列的最大长度（默认为 None）\n",
    "        pad_token_id: 填充 token 的 ID（默认为 50256，GPT-2 的 <|endoftext|> token）\n",
    "    \n",
    "    返回:\n",
    "        字符串 \"spam\" 或 \"not spam\"，表示分类结果\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========== 步骤 1: 设置模型为评估模式 ==========\n",
    "    model.eval()\n",
    "    # 将模型设置为评估模式，这会：\n",
    "    # - 禁用 dropout（训练时用于防止过拟合的随机失活层）\n",
    "    # - 禁用 batch normalization 的更新（如果有的话）\n",
    "    # - 确保模型行为与训练时不同，适合推理场景\n",
    "    \n",
    "    # ========== 步骤 2: 文本编码（tokenization） ==========\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    # 使用 tokenizer 将输入文本转换为 token ID 列表\n",
    "    # 例如: \"Hello world\" -> [15496, 995] (具体数字取决于 tokenizer 的词汇表)\n",
    "    \n",
    "    # ========== 步骤 3: 获取模型支持的最大上下文长度 ==========\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # 从模型的位置嵌入层（pos_emb）获取支持的最大序列长度\n",
    "    # pos_emb.weight 的形状是 [max_context_length, embedding_dim]\n",
    "    # 因此 shape[0] 就是模型能处理的最大 token 数量\n",
    "    # 对于 GPT-2 small，这个值通常是 1024\n",
    "    \n",
    "    # ========== 步骤 4: 截断过长的序列 ==========\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "    # 如果 token 序列长度超过以下两者中的较小值，则进行截断：\n",
    "    # - max_length: 用户指定的最大长度（通常是训练时使用的 max_length）\n",
    "    # - supported_context_length: 模型架构支持的最大长度\n",
    "    # 这样可以防止输入超出模型的处理能力\n",
    "    \n",
    "    # ========== 步骤 5: 填充序列到固定长度 ==========\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    # 如果序列长度小于 max_length，则在末尾添加填充 token\n",
    "    # 例如: 如果 input_ids = [15496, 995]，max_length = 5，pad_token_id = 50256\n",
    "    # 则填充后: [15496, 995, 50256, 50256, 50256]\n",
    "    # 填充是为了保证批处理时所有样本长度一致（虽然这里是单个样本）\n",
    "    \n",
    "    # ========== 步骤 6: 转换为张量并添加 batch 维度 ==========\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) \n",
    "    # 1. torch.tensor(input_ids, device=device): 将 Python 列表转换为 PyTorch 张量\n",
    "    #    并直接放到指定设备上（CPU 或 GPU），避免后续数据传输开销\n",
    "    # 2. unsqueeze(0): 在第 0 维增加一个维度，将形状从 [seq_len] 变为 [1, seq_len]\n",
    "    #    这是因为模型期望输入的形状是 [batch_size, seq_len]\n",
    "    #    即使只有一个样本，也需要 batch 维度\n",
    "    \n",
    "    # ========== 步骤 7: 模型推理（前向传播） ==========\n",
    "    with torch.no_grad():\n",
    "        # 使用 torch.no_grad() 上下文管理器：\n",
    "        # - 禁用梯度计算，节省内存和计算资源\n",
    "        # - 推理时不需要梯度，因为我们不会进行反向传播\n",
    "        \n",
    "        logits = model(input_tensor)[:, -1, :] \n",
    "        # 1. model(input_tensor): 将输入张量传入模型进行前向传播\n",
    "        #    输出形状为 [batch_size, seq_len, num_classes]\n",
    "        #    对于我们的分类任务，num_classes = 2（spam 或 not spam）\n",
    "        # \n",
    "        # 2. [:, -1, :]: 提取最后一个 token 位置的 logits\n",
    "        #    - 第一个 `:` 表示所有 batch（这里只有 1 个）\n",
    "        #    - `-1` 表示序列的最后一个位置（因为我们在最后一个 token 后添加了分类头）\n",
    "        #    - 最后一个 `:` 表示所有类别的 logits\n",
    "        #    结果形状: [batch_size, num_classes] = [1, 2]\n",
    "        # \n",
    "        # 3. 为什么只取最后一个 token？\n",
    "        #    在微调时，我们在序列末尾添加了分类头，模型学会了在最后一个位置\n",
    "        #    输出分类结果。这是 GPT 类模型做分类任务的标准做法。\n",
    "    \n",
    "    # ========== 步骤 8: 获取预测类别 ==========\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    # 1. torch.argmax(logits, dim=-1): 在最后一个维度（类别维度）上找到最大值的索引\n",
    "    #    - logits 形状是 [1, 2]，包含两个类别的原始分数\n",
    "    #    - dim=-1 表示在类别维度上操作\n",
    "    #    - 返回概率最高的类别索引（0 或 1）\n",
    "    #    结果形状: [1]（一个标量张量）\n",
    "    # \n",
    "    # 2. .item(): 将单元素张量转换为 Python 标量（int 类型）\n",
    "    #    这样可以在后续的 if 语句中直接使用\n",
    "    # \n",
    "    # 注意: 这里直接用 argmax 而不是先 softmax 再 argmax，因为：\n",
    "    # - softmax 不会改变最大值的位置\n",
    "    # - 我们只关心哪个类别概率最高，不需要具体的概率值\n",
    "    \n",
    "    # ========== 步骤 9: 返回人类可读的分类结果 ==========\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n",
    "    # 将数字标签转换为字符串标签：\n",
    "    # - 如果预测标签是 1，返回 \"spam\"（垃圾消息）\n",
    "    # - 如果预测标签是 0，返回 \"not spam\"（正常消息）\n",
    "    # 这个映射关系与训练数据的标签编码一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- 试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- 最后，让我们保存模型，以便以后如果需要重用模型时，无需重新训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")\n",
    "# 储存!大功告成!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- 下次我们可以这么唤醒这个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- 请参阅 [./gpt_class_finetune.py](./gpt_class_finetune.py) 脚本，这是一个自包含的分类微调脚本。\n",
    "- 你可以在 [./exercise-solutions.ipynb](./exercise-solutions.ipynb) 中找到练习解决方案。\n",
    "- 此外，感兴趣的读者可以在 [附录E](../../appendix-E) 中找到关于低秩适应（LoRA）的参数高效微调的介绍。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
