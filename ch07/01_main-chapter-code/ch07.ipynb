{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e91914-5f51-43fa-b65b-625e73b4d17b",
   "metadata": {
    "id": "12e91914-5f51-43fa-b65b-625e73b4d17b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "<br>汉化的库: <a href=\"https://github.com/GoatCsu/CN-LLMs-from-scratch.git\">https://github.com/GoatCsu/CN-LLMs-from-scratch.git</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"../image/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf",
   "metadata": {
    "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf"
   },
   "source": [
    "# 第七章：指令微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
    "outputId": "9d937b84-d8f8-4ce9-cc3c-211188f49a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.7.1\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.4.0\n",
      "tqdm version: 4.66.4\n",
      "tensorflow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",  # 绘图库\n",
    "    \"tiktoken\",    # 分词器\n",
    "    \"torch\",       # 深度学习库\n",
    "    \"tqdm\",        # 进度条\n",
    "    \"tensorflow\",  # 用于加载OpenAI的预训练权重\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")\n",
    "# 读取并输出版本号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264fca98-2f9a-4193-b435-2abfa3b4142f",
   "metadata": {
    "id": "264fca98-2f9a-4193-b435-2abfa3b4142f"
   },
   "source": [
    "<img src=\"../image/1.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813",
   "metadata": {
    "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813"
   },
   "source": [
    "## 7.1 指令微调的介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab",
   "metadata": {
    "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab"
   },
   "source": [
    "- 在第5章中，我们看到大语言模型的预训练是通过让模型学习逐个生成单词来实现的。\n",
    "- 由此可见,预训练的大语言模型擅长文本补全的任务，但不擅长执行指令。\n",
    "- 在本章中，我们将微调大语言模型使其更好地遵循指令。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc0535-0904-44ed-beaf-9b678292ef35",
   "metadata": {
    "id": "18dc0535-0904-44ed-beaf-9b678292ef35"
   },
   "source": [
    "<img src=\"../image/2.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8",
   "metadata": {
    "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8"
   },
   "source": [
    "- 在下图中,你可以看到本章节所涉及的话题\n",
    "\n",
    "<img src=\"../image/3.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86",
   "metadata": {
    "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86"
   },
   "source": [
    "## 7.2 为有监督指令微调准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b34ff8-619f-4e89-bd03-ce513269760d",
   "metadata": {
    "id": "f8b34ff8-619f-4e89-bd03-ce513269760d"
   },
   "source": [
    "- 使用我为本章准备的一个指令数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0G3axLw6kY1N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0G3axLw6kY1N",
    "outputId": "a5f70eb8-6248-4834-e7ae-6105e94e5afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "# 在网上下载并打开数据库\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n",
    "# 看一下数据一共有多少条"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af8176-4255-4e92-8c7d-998771733eb8",
   "metadata": {
    "id": "d7af8176-4255-4e92-8c7d-998771733eb8"
   },
   "source": [
    "- 每个我们从上述 JSON 文件加载的 `data` 列表中的项都是一个字典，格式如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-LiuBMsHkzQV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LiuBMsHkzQV",
    "outputId": "cc742019-b8d7-40f9-b21a-6a5ddf821377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])\n",
    "# 打印第51个json的形式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46",
   "metadata": {
    "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46"
   },
   "source": [
    "- 有时输入也可能是空的，如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "uFInFxDDk2Je",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFInFxDDk2Je",
    "outputId": "70241295-a9ec-4b7d-caf5-ab6f267e3271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034799a-6575-45fd-98c9-9d1012d0fd58",
   "metadata": {
    "id": "f034799a-6575-45fd-98c9-9d1012d0fd58"
   },
   "source": [
    "- 指令微调通常被称为“监督指令微调”，因为它涉及在一个数据集上训练模型，而该数据集中明确提供了输入-输出对。\n",
    "- 有多种不同的方法可以将样本制作为适应于大语言模型的格式；下图分别展示了两种用于训练Alpaca（[https://crfm.stanford.edu/2023/03/13/alpaca.html](https://crfm.stanford.edu/2023/03/13/alpaca.html)）和Phi-3（[https://arxiv.org/abs/2404.14219](https://arxiv.org/abs/2404.14219)）LLM的示例格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10",
   "metadata": {
    "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10"
   },
   "source": [
    "<img src=\"../image/4.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6",
   "metadata": {
    "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6"
   },
   "source": [
    "- 在本章中，我们默认使用Alpaca风格的提示格式，这是一种较早公开并被广泛使用的指令微调提示模板。\n",
    "- 下面，我们将格式化输入内容，并将其作为输入传递给大语言模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Jhk37nnJnkBh",
   "metadata": {
    "id": "Jhk37nnJnkBh"
   },
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    \"\"\"\n",
    "    将单个数据条目格式化为 Alpaca 风格的提示格式（prompt）。\n",
    "    适用于指令微调任务，使文本内容能直接用于大语言模型输入。\n",
    "\n",
    "    参数\n",
    "    ----\n",
    "    entry : dict\n",
    "        包含键 'instruction'（指令/需求描述）、'input'（附加输入，可能为空），\n",
    "        还有 'output'（期望模型输出，未在本函数处理）。\n",
    "\n",
    "    返回\n",
    "    ----\n",
    "    prompt : str\n",
    "        格式化后的多行字符串，包含固定模板、Instruction 和可选的 Input 字段。\n",
    "\n",
    "    示例\n",
    "    ----\n",
    "    entry = {\n",
    "        \"instruction\": \"将下列英文翻译成中文。\",\n",
    "        \"input\": \"I love learning artificial intelligence.\",\n",
    "        ...\n",
    "    }\n",
    "    format_input(entry)\n",
    "    # 返回:\n",
    "    # Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "    #\n",
    "    # ### Instruction:\n",
    "    # 将下列英文翻译成中文。\n",
    "    #\n",
    "    # ### Input:\n",
    "    # I love learning artificial intelligence.\n",
    "    \"\"\"\n",
    "\n",
    "    # 拼接任务描述和Instruction部分（固定说明 + 来自 entry['instruction']）\n",
    "    instruction_text = (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\"\n",
    "        \"\\n\\n### Instruction:\\n\"\n",
    "        f\"{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # 如果 'input' 字段非空，则添加 Input 部分，否则不添加（例如有些任务无需附加输入）\n",
    "    if entry[\"input\"]:\n",
    "        input_text = f\"\\n\\n### Input:\\n{entry['input']}\"\n",
    "    else:\n",
    "        input_text = \"\"  # 没有输入时，该部分为空字符串\n",
    "\n",
    "    # 合并成最终 prompt；注意模型微调通常还需拼接 output 部分\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6",
   "metadata": {
    "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6"
   },
   "source": [
    "- 格式化的回复如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "F9UQRfjzo4Js",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9UQRfjzo4Js",
    "outputId": "13ec7abf-ad94-4e26-860d-6a39a344f31f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "# 先使用五十条数据进行测试\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc93ddf-431c-49c0-96f2-fb3a79c4d94c",
   "metadata": {
    "id": "4dc93ddf-431c-49c0-96f2-fb3a79c4d94c"
   },
   "source": [
    "- 以下是一个没有输入内容对应的格式化响应："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3891fa9-f738-41cd-946c-80ef9a99c346",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3891fa9-f738-41cd-946c-80ef9a99c346",
    "outputId": "d6be5713-1293-4a70-c8c8-a86ea8e95817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8afd5-2a21-49a5-90c3-6a03865a4771",
   "metadata": {
    "id": "4aa8afd5-2a21-49a5-90c3-6a03865a4771"
   },
   "source": [
    "- 最后，在下一节中准备 PyTorch 数据加载器之前，我们将数据集划分为训练集、验证集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aFZVopbIlNfx",
   "metadata": {
    "id": "aFZVopbIlNfx"
   },
   "outputs": [],
   "source": [
    "# 自定义训练集、测试集和验证集的大小\n",
    "train_portion = int(len(data) * 0.85)  # 85% 作为训练集\n",
    "test_portion = int(len(data) * 0.1)    # 10% 作为测试集\n",
    "val_portion = len(data) - train_portion - test_portion  # 剩下的 5% 作为验证集\n",
    "\n",
    "# 划分数据集\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "-zf6oht6bIUQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zf6oht6bIUQ",
    "outputId": "bb5fe8e5-1ce5-4fca-a430-76ecf42e99ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaaf606-f913-4445-8301-632ae10d387d",
   "metadata": {
    "id": "fcaaf606-f913-4445-8301-632ae10d387d"
   },
   "source": [
    "## 7.3 将数据组织成训练批次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f63bd-9755-4d07-8884-5e2e5345cf27",
   "metadata": {
    "id": "233f63bd-9755-4d07-8884-5e2e5345cf27"
   },
   "source": [
    "<img src=\"../image/5.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c",
   "metadata": {
    "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c"
   },
   "source": [
    "- 下图总结了我们处理数据的几种方式\n",
    "\n",
    "<img src=\"../image/6.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af423f-aad9-4b3c-bea5-153021c04862",
   "metadata": {
    "id": "b9af423f-aad9-4b3c-bea5-153021c04862"
   },
   "source": [
    "- 首先，我们实现一个 `InstructionDataset` 类，它对数据集中的所有输入进行预分词，类似于第6章中的 `SpamDataset`。\n",
    "\n",
    "<img src=\"../image/7.png\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb",
   "metadata": {
    "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    自定义数据集类，用于将原始指令数据（如 Alpaca 格式）转成模型可用的 token 编码序列。\n",
    "    \"\"\"\n",
    "    def __init__(self, data, tokenizer):\n",
    "        \"\"\"\n",
    "        :param data: 一个包含多条指令-输入-输出字典的列表，每条如 {'instruction': ..., 'input': ..., 'output': ...}\n",
    "        :param tokenizer: 分词器对象，比如 tiktoken 编码器，需支持 .encode(str) 方法\n",
    "        \"\"\"\n",
    "        self.data = data  # 原始数据列表\n",
    "\n",
    "        # 存储所有处理好的 token id 序列\n",
    "        self.encoded_texts = []\n",
    "\n",
    "        for entry in data:\n",
    "            # 1. 格式化用户 prompt，比如加上 \"### Instruction\" 等头\n",
    "            instruction_plus_input = format_input(entry)\n",
    "\n",
    "            # 2. 格式化期望的答案标签，与原数据 output 拼接（前加换行及 Response 前缀）\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "\n",
    "            # 3. 合并为模型训练的目标文本（你训练的就是输入输出对）\n",
    "            full_text = instruction_plus_input + response_text\n",
    "\n",
    "            # 4. 用 tokenizer 预编码成 token id 列表\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        支持下标访问：dataset[idx] 返回第 idx 个训练样本的 token id 列表（已编码）\n",
    "        \"\"\"\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集长度，等于原始数据的条数\n",
    "        \"\"\"\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f0e69-4b22-41c0-a25d-f077527eddd1",
   "metadata": {
    "id": "384f0e69-4b22-41c0-a25d-f077527eddd1"
   },
   "source": [
    "- 与第6章类似, 为了加速训练, 我们希望将多个批次收集到同个训练轮次中, 这要求将所有输入填充到相同的长度。\n",
    "- 同样与上一章类似，我们使用 `<|endoftext|>` 作为填充 token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff24fe1a-5746-461c-ad3d-b6d84a1a7c96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff24fe1a-5746-461c-ad3d-b6d84a1a7c96",
    "outputId": "4d63f8b8-b4ad-45d9-9e93-c9dd8c2b7706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken  # 导入 tiktoken 库，用于加载和使用高效的分词器（tokenizer）\n",
    "\n",
    "# 加载 GPT-2 的编码器（分词器），常用于 OpenAI 系列的 LLM 训练和推理\n",
    "# 这个编码器会将字符串转换为 token ID 序列，与 GPT-2 及许多社区 LLM 数据集格式兼容\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")  # \"gpt2\" 是内置的编码模型名称\n",
    "\n",
    "# 测试编码一个特殊 token：<|endoftext|>\n",
    "# allowed_special={\"<|endoftext|>\"} 参数表示明确允许对特殊的 <|endoftext|> token 编码\n",
    "# 通常 <|endoftext|> 被用作“文本结束”或者“填充”标记，不在普通词表中，需专项允许\n",
    "# 输出其对应的 token id 列表，确认分词器配置无误\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427",
   "metadata": {
    "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427"
   },
   "source": [
    "- 在第6章中，我们将数据集中的所有例子填充为相同的长度。\n",
    "  - 而在这里，我们采取了一种更为复杂的方法: 开发了一个自定义的 \"collate\" 函数，并将其传递给数据加载器。\n",
    "  - 这个自定义的collate函数会将每个批次中的训练示例填充到相同的长度（不同批次的长度可以不同）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3",
   "metadata": {
    "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3"
   },
   "source": [
    "<img src=\"../image/8.png\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca",
   "metadata": {
    "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca"
   },
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    自定义的collate函数，用于将一个批次的序列填充到相同长度，并生成输入张量。\n",
    "    \n",
    "    参数说明:\n",
    "        batch: 一个批次的样本, 例如 [[1,2,3], [4,5], [6,7,8,9]]\n",
    "        pad_token_id: 用于填充的token的id，默认为GPT-2中的<|endoftext|>的id: 50256\n",
    "        device: 输出张量要放置的设备，\"cpu\" 或 \"cuda\"\n",
    "    返回:\n",
    "        形状为 (batch_size, max_length) 的张量，每一行是填充后的输入序列\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: 计算本批次中长度最长的序列，加1是为了在末尾额外添加一个pad_token\n",
    "    # 这样可以确保后续的target序列和input序列能错位一位（适用于下游因果语言建模）\n",
    "    batch_max_length = max(len(item)+1 for item in batch)  # +1表示每句话后面加个pad\n",
    "\n",
    "    inputs_lst = []  # 用于存储每个样本的张量化输入\n",
    "    # Step 2: 对每个序列独立处理\n",
    "    for item in batch:\n",
    "        # 由于item是list，这里需要copy，否则会就地修改原始数据（小心副作用）\n",
    "        new_item = item.copy()  \n",
    "        # 在每个样本末尾先加一个pad_token_id，实现+1长度的需求\n",
    "        new_item += [pad_token_id]\n",
    "        # Step 3: 如果当前序列长度还不足最大长度，则继续填充pad到满足batch_max_length\n",
    "        # - (batch_max_length - len(new_item)) 保证补全到等长\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Step 4: 由于最后一位加的pad只是为了target错位输入，不需要作为input token，需裁剪掉\n",
    "        # 保证最后返回的inputs张量形状统一且不多余\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        # 将当前样本的tensor结果加入列表\n",
    "        inputs_lst.append(inputs)\n",
    "    # Step 5: 将所有输入张量用stack拼接为(batch_size, seq_len)，并搬到指定device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
    "outputId": "8705ca9a-e999-4f70-9db8-1ad084eba7bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b",
   "metadata": {
    "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b"
   },
   "source": [
    "<img src=\"../image/9.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17769a19-b961-4213-92ef-34f441b2d1d6",
   "metadata": {
    "id": "17769a19-b961-4213-92ef-34f441b2d1d6"
   },
   "source": [
    "- 上述内容中，我们仅返回了给大语言模型的输入。\n",
    "- 然而，对于大语言模型的训练，我们还需要目标值。\n",
    "- 与我们在预训练大语言模型时的做法相似，目标token序号与输入token序号相对应，但相比起来向右移动了一个位置（见下图），这样的设计使得大语言模型能够学习如何预测序列中的下一个词元。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef",
   "metadata": {
    "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef"
   },
   "source": [
    "<img src=\"../image/10.png\" width=400px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc",
   "metadata": {
    "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc"
   },
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,  # 默认填充ID使用GPT-2的<|endoftext|> token\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # 步骤1：计算本批次中需要对齐（补齐填充）的目标最大长度\n",
    "    # 这里为每个样本增加1个token长度，是因为后续会拼接上一个pad_token_id，便于构造target序列\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "\n",
    "    # 步骤2：初始化两个空列表，分别用于存放每个样本的input和target序列\n",
    "    # - inputs_lst：存放每个样本处理后的输入序列\n",
    "    # - targets_lst：存放每个样本对应的目标序列\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        # 步骤3：创建当前样本的拷贝，避免修改原始数据\n",
    "        new_item = item.copy()\n",
    "        # 步骤4：追加一个pad_token_id，作为当前序列的“结束”标志（和target错位时对齐）\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        # 步骤5：按规定长度补全padding到batch_max_length\n",
    "        #   - 计算还需要补多少pad_token_id，使总长度一致\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "\n",
    "        # 步骤6：构造模型的输入序列(inputs)\n",
    "        #   - inputs是padded的从第一个元素到倒数第二个元素\n",
    "        #   - 这样处理后，inputs的长度为 batch_max_length-1\n",
    "        inputs = torch.tensor(padded[:-1]) \n",
    "\n",
    "        # 步骤7：构造目标序列(targets)\n",
    "        #   - targets是padded的从第二个元素到最后一个元素\n",
    "        #   - 目的：输入序列与目标序列错位一位，使得模型每一步都以timestep t的token预测下一个t+1的token\n",
    "        #   - 长度也为batch_max_length-1，与inputs完全对齐\n",
    "        targets = torch.tensor(padded[1:]) \n",
    "        \n",
    "        # 步骤8：将当前样本的inputs和targets加入对应列表\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # 步骤9：将所有样本的inputs和targets分别拼接为形状为(batch_size, seq_len)的大张量\n",
    "    #       并转移到指定的device（如'cuda'或'cpu'）\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    # 步骤10：返回拼接好的inputs和targets张量\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
    "outputId": "b9ceae14-13c2-49f7-f4a4-b503f3db3009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15",
   "metadata": {
    "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15"
   },
   "source": [
    "- 接下来，我们引入了一个 `ignore_index` 值，用于将所有填充 token 的ID替换为一个新值；引入 `ignore_index` 的目的是使我们能够在损失函数中忽略填充值（稍后会详细讨论）。\n",
    "\n",
    "<img src=\"../image/11.png\" width=500px>\n",
    "\n",
    "- 具体来说，这意味着我们将 `50256` 对应的 token ID替换为 `-100`，如图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4bed33-956e-4b3f-a09c-586d8203109a",
   "metadata": {
    "id": "bd4bed33-956e-4b3f-a09c-586d8203109a"
   },
   "source": [
    "<img src=\"../image/12.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346513e-c3f4-44fe-af22-4ebd36497728",
   "metadata": {
    "id": "5346513e-c3f4-44fe-af22-4ebd36497728"
   },
   "source": [
    "- （此外，我们还引入了 `allowed_max_length`，以支持“限制样本的长度”。如果您打算使用比GPT-2模型支持的1024个 token 上下文长度更长的数据集，这个设置将非常有用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2",
   "metadata": {
    "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2"
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    自定义collate函数，用于将一个batch内的变量长度样本整理成统一格式的张量，\n",
    "    并处理填充、目标（targets）及可选的最大序列长度。\n",
    "    \n",
    "    参数说明:\n",
    "        batch: List[List[int]]\n",
    "            小批量样本，每个元素是一个token id序列（长度各异）。\n",
    "        pad_token_id: int\n",
    "            用于填充的token id，默认为GPT-2的<|endoftext|>的id: 50256。\n",
    "        ignore_index: int\n",
    "            在计算损失时要忽略的填充值，例如CrossEntropyLoss默认-100。\n",
    "        allowed_max_length: int or None\n",
    "            （可选）如果设置，限制最终输入/目标序列的最大长度。\n",
    "        device: str\n",
    "            张量最终转移到的设备（'cpu' 或 'cuda'）。\n",
    "    返回:\n",
    "        inputs_tensor: torch.LongTensor, shape [batch_size, seq_len]\n",
    "            拼接好的inputs张量。\n",
    "        targets_tensor: torch.LongTensor, shape [batch_size, seq_len]\n",
    "            拼接好的targets张量，填充部分已替换为ignore_index。\n",
    "    \"\"\"\n",
    "\n",
    "    # 步骤1：确定当前batch内的最大序列长度\n",
    "    #   - +1 是因为后面每个序列都要额外加一个 <|endoftext|> token\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "\n",
    "    # 用于收集处理后的每个样本的输入（inputs）和目标（targets）张量\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    # 步骤2：逐个处理batch里的每个样本\n",
    "    for item in batch:\n",
    "        # 2.1 拷贝原始序列，避免原数据污染\n",
    "        new_item = item.copy()\n",
    "\n",
    "        # 2.2 在序列末尾拼接一个 <|endoftext|> (pad_token_id)，使模型学到文本结束\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        # 2.3 进行padding补齐到batch内最大长度\n",
    "        #    - padding的token也是pad_token_id\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "\n",
    "        # 2.4 划分inputs和targets\n",
    "        #     - inputs: padded的前n-1个token（不包含最后一个）\n",
    "        #     - targets: padded的后n-1个token（首位剔除，右移1位）\n",
    "        inputs = torch.tensor(padded[:-1])   # 作为模型输入\n",
    "        targets = torch.tensor(padded[1:])   # 作为下一个token预测目标\n",
    "\n",
    "        # 2.5 【填充值处理】为了后续损失计算时忽略填充token，在targets中，\n",
    "        #     - 除第一个pad_token_id出现外，其余pad都替换为ignore_index\n",
    "        #     - 这里的mask等于True的位置就是pad_token_id\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        # 只有在出现2次及以上pad_token_id时才处理(首个保留, 后面换为ignore_index)\n",
    "        if indices.numel() > 1:\n",
    "            # indices是 pad_token 的下标，将下标1及以后全部设为ignore_index（保留第一个pad_token_id）\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # 2.6 （可选）如果设置了最大长度，截断inputs和targets\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        # 2.7 收集本样本处理好的inputs和targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # 步骤3：将所有样本堆叠、转为大张量，并放到目标设备\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    # 步骤4：返回inputs和targets张量\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
    "outputId": "a5501547-239d-431d-fb04-da7fa2ffad79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7",
   "metadata": {
    "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7"
   },
   "source": [
    "- 看看填充 token 替换为 -100 产生了什么效果。\n",
    "- 为了说明，假设我们有一个小型分类任务，包含两个类标签，0和1，类似于第6章的内容。\n",
    "- 如果有以下的logits值（模型最后一层的输出），我们可以计算出以下的损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "W2jvh-OP9MFV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2jvh-OP9MFV",
    "outputId": "b5cd858e-7c58-4a21-c5a7-e72768bd301c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "# 这段代码用于演示如何用 PyTorch 的 cross_entropy 函数计算分类问题的损失\n",
    "import torch\n",
    "\n",
    "# logits_1 是一个二维 Tensor，每一行表示一个样本在两个类别上的模型输出分数\n",
    "# 第一个样本的输出：[-1.0, 1.0]；第二个样本输出：[-0.5, 1.5]\n",
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 第1个训练样本\n",
    "     [-0.5, 1.5]]  # 第2个训练样本\n",
    ")\n",
    "\n",
    "# targets_1 表示每个样本的真实类别标签，分别是类别0和类别1\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "# 计算交叉熵损失（cross entropy loss），即对每个样本，\n",
    "# 根据其 logits 和真实标签求平均损失。这也是分类任务常用的损失函数\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "\n",
    "# 输出交叉熵损失的结果（是一个标量 Tensor）\n",
    "print(loss_1)\n",
    "\n",
    "# 运行结果大致为 0.313 (不同设备或数值环境可能有轻微差异)\n",
    "# 解释：此结果表示模型当前预测与真实标签的平均不一致程度，数值越小通常说明模型性能越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd3244-8886-4505-92e9-367d28529e1e",
   "metadata": {
    "id": "5edd3244-8886-4505-92e9-367d28529e1e"
   },
   "source": [
    "- 显然,多了一个token会影响loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nvVMuil89v9N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvVMuil89v9N",
    "outputId": "e4a07b99-a23c-4404-ccdb-5f93c39f3b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # 新增第3个训练实例\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dca331-40e0-468b-b690-189fe156ba8f",
   "metadata": {
    "id": "54dca331-40e0-468b-b690-189fe156ba8f"
   },
   "source": [
    "- 但是我们看看如果这个token变成了-100会怎样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "RTyB1vah9p56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTyB1vah9p56",
    "outputId": "28c16387-1d9c-48a7-eda7-aa270864683d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)\n",
    "# 综上所述、交叉熵会忽略-100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef09d21-b652-4760-abea-4f76920e6a25",
   "metadata": {
    "id": "cef09d21-b652-4760-abea-4f76920e6a25"
   },
   "source": [
    "- 如上述所见，这3个训练样本计算得到的损失与我们从2个样本计算得到的损失相同，可以看出交叉熵损失函数忽略了带有 -100 标签的训练样本。\n",
    "- 默认情况下，PyTorch 的 `cross_entropy(..., ignore_index=-100)` 设置会忽略对应于标签 -100 的样本。\n",
    "- 使用这个 -100 的 `ignore_index`，我们可以忽略在批次中填充训练样本到相同长度时使用的额外结束 token（填充 token）。\n",
    "- 然而，我们忽略第一个结束 token（50256）也不是个好选择，因为这个 token 有助于向LLM发出**响应已完成**的信号。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524",
   "metadata": {
    "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524"
   },
   "source": [
    "- 除了屏蔽填充词元，实践中我们通常还会屏蔽与指令相关的目标token ID（这是本章节的练习）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39",
   "metadata": {
    "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39"
   },
   "source": [
    "<img src=\"../image/13.png\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96",
   "metadata": {
    "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96"
   },
   "source": [
    "## 7.4 创建指令数据集的数据加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50",
   "metadata": {
    "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50"
   },
   "source": [
    "- 在本节中，我们使用 `InstructionDataset` 类和 `custom_collate_fn` 函数来实例化训练集、验证集和测试集数据加载器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffe390-b226-4d5c-983f-9f4da773cb82",
   "metadata": {
    "id": "9fffe390-b226-4d5c-983f-9f4da773cb82"
   },
   "source": [
    "<img src=\"../image/14.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932677e9-9317-42e8-b461-7b0269518f97",
   "metadata": {
    "id": "932677e9-9317-42e8-b461-7b0269518f97"
   },
   "source": [
    "- 之前的 `custom_collate_fn` 函数的另一个改进之处在于，我们现在直接将数据移动到目标设备（例如GPU），而不是在主训练循环中执行。这提高了效率，因为当我们将 `custom_collate_fn` 作为数据加载器的一部分使用时，数据的移动可以在后台进行。\n",
    "- 我们使用 Python 标准库中的 `functools` 模块的 `partial` 函数，创建了一个新函数，其中原始函数的 `device` 参数已预先填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "etpqqWh8phKc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etpqqWh8phKc",
    "outputId": "925faf3a-6df4-4ad0-f276-f328493619c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 注意：\n",
    "# 如果适用，取消注释以下行将使代码能够在Apple Silicon芯片上运行，\n",
    "# 这比在Apple CPU上运行要快得多（在M3 MacBook Air上测得）。\n",
    "# 然而，计算得到的loss可能会略有不同。\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c",
   "metadata": {
    "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# 使用 functools.partial 创建一个“定制化”的 collate 函数，用于 DataLoader 数据批处理\n",
    "# 解释：collate_fn 通常需要传入一些参数（如 device、最大长度等），但是 DataLoader 只支持接收一个函数的引用作为参数。\n",
    "# 因此，我们可以用 partial 先把 custom_collate_fn 里的参数“冻结/填充”好，返回一个新函数，这样 DataLoader 只需调用该新函数即可。\n",
    "\n",
    "# 参数说明：\n",
    "# - custom_collate_fn: 我们自定义的批量聚合函数，会负责把一批数据拼接、填充对齐、转成张量、移动到设备等\n",
    "# - device: 当前目标设备（如 CPU、GPU 或 Apple MPS），数据会被直接拷贝到该设备，提高训练效率\n",
    "# - allowed_max_length: 限制序列最大长度，超长时截断（避免显存溢出等）\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,            # 目标批量聚合函数\n",
    "    device=device,                # 固定参数：数据放到指定的设备上\n",
    "    allowed_max_length=1024       # 固定参数：最大允许长度为 1024\n",
    ")\n",
    "\n",
    "# customized_collate_fn 现在就是一个\"带默认参数\"的新函数，只需要 (batch) 一个输入\n",
    "# 之后可以直接传给 DataLoader 的 collate_fn 参数，无需再每次手动传 device/allowed_max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a",
   "metadata": {
    "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a"
   },
   "source": [
    "- 接下来，我们像之前的章节一样实例化数据加载器，唯一不同的是，我们现在为批处理过程提供了自定义的collate函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "BtWkgir6Hlpe",
   "metadata": {
    "id": "BtWkgir6Hlpe"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设置DataLoader的一些参数\n",
    "num_workers = 0         # 启用多少个子进程来加载数据。0表示只用主进程加载，适合Jupyter等交互环境和小数据集\n",
    "batch_size = 8          # 每个训练批次的样本数。通常可以根据GPU/CPU内存适当调整，如8、16、32等\n",
    "\n",
    "torch.manual_seed(123)  # 设置随机种子，以确保实验的可复现性（如shuffle、采样结果固定）\n",
    "\n",
    "# 构建训练集的自定义Dataset对象，\n",
    "# InstructionDataset 负责把原始指令数据train_data处理成模型可用的格式（分词、转token id等）\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "\n",
    "# 实例化训练数据加载器DataLoader，负责后续批量取数据供模型训练\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,                     # 传入自定义Dataset对象\n",
    "    batch_size=batch_size,             # 每批的样本数\n",
    "    collate_fn=customized_collate_fn,  # 自定义批量聚合与padding函数（如自动填充、转tensor、送device等）\n",
    "    shuffle=True,                      # 每轮训练前随机打乱数据，有助于提升泛化能力\n",
    "    drop_last=True,                    # 若最后剩余数据不足一个batch，就丢弃（避免batch size不一致导致的问题）\n",
    "    num_workers=num_workers            # 数据加载用的进程数，0表示不开子进程，只用主线程\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d097dc8-ad34-4f05-b435-e4147965f532",
   "metadata": {
    "id": "1d097dc8-ad34-4f05-b435-e4147965f532"
   },
   "outputs": [],
   "source": [
    "# 初始化验证与测试\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0",
   "metadata": {
    "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0"
   },
   "source": [
    "- 看看输入和输出批次的维度是怎样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "GGs1AI3vHpnX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGs1AI3vHpnX",
    "outputId": "53a9695d-87cb-4d7c-8b43-1561dfa68ba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657",
   "metadata": {
    "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657"
   },
   "source": [
    "- 如上面的输出所示，所有批次的批次大小为8，但长度各不相同，正如预期的那样。\n",
    "- 我们还可以通过输出 `inputs` 批次中第一个训练样本的内容，再次确认输入中包含了与 token ID 50256 对应的 `<|endoftext|>` 填充 token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
    "outputId": "ce919ecd-5ded-453c-a312-10cf55c13da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360",
   "metadata": {
    "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360"
   },
   "source": [
    "- 类似地，我们通过输出，直观地检查目标中是否包含 -100 占位符 token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
    "outputId": "fdf486f3-e99d-4891-9814-afc9e4991020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aad445-8f19-4238-b9bf-db80767fb91a",
   "metadata": {
    "id": "d6aad445-8f19-4238-b9bf-db80767fb91a"
   },
   "source": [
    "## 7.5 加载预训练的大语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b",
   "metadata": {
    "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b"
   },
   "source": [
    "- GPT跟本书ch05和ch06章节演示是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4",
   "metadata": {
    "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4"
   },
   "source": [
    "<img src=\"../image/15.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2",
   "metadata": {
    "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2"
   },
   "source": [
    "- 然而，我们没有加载1.24亿参数的最小模型，而是选择了3.55亿参数的中型版本，因为1.24亿参数的模型对于通过指令微调获得合理的结果来说过于简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d249d67-5eba-414e-9bd2-972ebf01329d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d249d67-5eba-414e-9bd2-972ebf01329d",
    "outputId": "3f08f5e1-ca7c-406d-e2ae-1b5fcafad3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [04:20<00:00, 5.45MiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 3.08MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 820kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 555kiB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入工具函数\n",
    "from gpt_download import download_and_load_gpt2  # 用于下载及加载预训练GPT-2模型权重\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt  # GPT模型定义与权重加载函数\n",
    "\n",
    "# 定义基础配置字典，包括词表大小、最大上下文长度、dropout概率等\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # GPT-2词表的token总数，标准GPT-2为50257\n",
    "    \"context_length\": 1024,  # 输入序列的最大长度（即模型能处理的上下文长度）\n",
    "    \"drop_rate\": 0.0,        # dropout比率(关闭dropout，方便推理与一致性)\n",
    "    \"qkv_bias\": True         # 是否为Self Attention中的query/key/value加上可学习偏置\n",
    "}\n",
    "\n",
    "# 列出可选的几种GPT-2模型参数配置，参数量由小到大\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},     # 1.24亿参数，默认GPT-2配置\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},   # 3.55亿参数，本文所用配置\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},    # 7.74亿参数\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},      # 15.58亿参数\n",
    "}\n",
    "\n",
    "# 选择要加载的GPT-2模型类型（这里只需更改此变量即可切换）\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"   # 用3.55亿参数的GPT-2模型参与后续实验\n",
    "\n",
    "# 将选定模型的参数（如emb维度、transformer层数、头数）合并进基本配置\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "# 提取模型代号，例如 \"(355M)\"\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "# 下载并加载GPT-2模型权重\n",
    "# - model_size：模型大小字符串（如 '355M'），自动匹配官方权重文件\n",
    "# - models_dir：保存/查找模型权重的目录\n",
    "# - 返回settings和params，两者分别为元数据与权重参数\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "# 创建一个GPT模型实例，使用合并后的配置参数\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "\n",
    "# 将下载到的预训练权重加载到模型（in-place方式）\n",
    "load_weights_into_gpt(model, params)\n",
    "\n",
    "# 将模型切换到评估模式，关闭如dropout、batchnorm等正则化与扰动操作\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5",
   "metadata": {
    "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5"
   },
   "source": [
    "- 在下一节开始微调模型之前，我们先来看一下它在一个验证集数据上的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
    "outputId": "30d4fbd9-7d22-4545-cfc5-c5749cc0bd93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa",
   "metadata": {
    "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea49d62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2fda5-f796-4954-8f72-1dd1123e3344",
   "metadata": {
    "id": "36e2fda5-f796-4954-8f72-1dd1123e3344"
   },
   "source": [
    "- 请注意，之前章节中使用的 `generate` 函数返回的是输入和输出文本的合并结果，这在上一节中便于生成可读的文本。\n",
    "- 为了提取响应，我们可以从 `generated_text` 的开头减去指令部分获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
    "outputId": "b46de9b3-98f0-45e4-a9ae-86870c3244a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    # 从生成的文本开始计数\n",
    "    generated_text[len(input_text):]\n",
    "    #如果生成的文本包含 `### Response:`，则删除它\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    #去掉空格\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44080b2-a4c5-4520-a797-549519f66a3e",
   "metadata": {
    "id": "d44080b2-a4c5-4520-a797-549519f66a3e"
   },
   "source": [
    "- 如我们所见，模型还无法正确地执行指令，但它创建了一个“response”部分，虽然只是简单地重复了原始输入句子和指令。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d27b9d-a942-4cf5-b797-848c5f01e723",
   "metadata": {
    "id": "70d27b9d-a942-4cf5-b797-848c5f01e723"
   },
   "source": [
    "## 7.6 在指令数据上微调大语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a",
   "metadata": {
    "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a"
   },
   "source": [
    "- 在这一部分,我们将要微调模型\n",
    "\n",
    "<img src=\"../image/16.png\" width=500px>\n",
    "\n",
    "- 之前所使用的loss函数和训练函数我们都可以复用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65444865-df87-4d98-9faf-875e1c4be860",
   "metadata": {
    "id": "65444865-df87-4d98-9faf-875e1c4be860"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00",
   "metadata": {
    "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00"
   },
   "source": [
    "- 在开始训练之前，让我们计算初始的训练集和验证集损失（与之前章节一样，目标是最小化损失）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
    "outputId": "36fdf03b-6fa6-46c3-c77d-ecc99e886265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.825909233093262\n",
      "Validation loss: 3.7619338512420653\n"
     ]
    }
   ],
   "source": [
    "# 将模型加载到指定的设备（如 GPU 或 CPU），以便后续计算在该设备上进行\n",
    "model.to(device)\n",
    "\n",
    "# 设置随机种子，保证实验的可重复性\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 下面不进行梯度计算（节省内存，加快推理，仅做评估），只做推理计算训练集与验证集的平均loss\n",
    "with torch.no_grad():\n",
    "    # 计算训练集上的平均损失（仅取前5个batch，为了节省计算时间），用于评估模型在当前参数下的表现\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader,   # 训练数据的Dataloader\n",
    "        model,          # 当前的GPT模型\n",
    "        device,         # 计算所用设备（CUDA/GPU或CPU）\n",
    "        num_batches=5   # 只评估前5个batch\n",
    "    )\n",
    "    # 计算验证集上的平均损失（同上，也仅取前5个batch），用于衡量模型泛化能力\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, \n",
    "        model, \n",
    "        device, \n",
    "        num_batches=5\n",
    "    )\n",
    "\n",
    "# 在微调之前，先打印一次初始的训练集和验证集损失\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9",
   "metadata": {
    "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9"
   },
   "source": [
    "- 因为模型更大了,我们的计算成本就比之前高了不少\n",
    "- 下表列出了不同设备运行该模型的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b57fb-e689-4550-931c-6d34a932487c",
   "metadata": {
    "id": "db4b57fb-e689-4550-931c-6d34a932487c"
   },
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    \n",
    "| Model              | Device                | Runtime for 2 Epochs |\n",
    "|--------------------|-----------------------|----------------------|\n",
    "| gpt2-medium (355M) | CPU (M3 MacBook Air)  | 15.78 minutes        |\n",
    "| gpt2-medium (355M) | GPU (M3 MacBook Air)  | 10.77 minutes        |\n",
    "| gpt2-medium (355M) | GPU (L4)              | 1.83 minutes         |\n",
    "| gpt2-medium (355M) | GPU (A100)            | 0.86 minutes         |\n",
    "| gpt2-small (124M)  | CPU (M3 MacBook Air)  | 5.74 minutes         |\n",
    "| gpt2-small (124M)  | GPU (M3 MacBook Air)  | 3.73 minutes         |\n",
    "| gpt2-small (124M)  | GPU (L4)              | 0.69 minutes         |\n",
    "| gpt2-small (124M)  | GPU (A100)            | 0.39 minutes         |\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
    "outputId": "cea0618c-56ca-418a-c972-bcc060362727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.800, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.809\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.782\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.536, Val loss 0.732\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.739\n",
      "Ep 1 (Step 000080): Train loss 0.603, Val loss 0.734\n",
      "Ep 1 (Step 000085): Train loss 0.518, Val loss 0.717\n",
      "Ep 1 (Step 000090): Train loss 0.575, Val loss 0.699\n",
      "Ep 1 (Step 000095): Train loss 0.505, Val loss 0.689\n",
      "Ep 1 (Step 000100): Train loss 0.509, Val loss 0.684\n",
      "Ep 1 (Step 000105): Train loss 0.571, Val loss 0.679\n",
      "Ep 1 (Step 000110): Train loss 0.564, Val loss 0.676\n",
      "Ep 1 (Step 000115): Train loss 0.517, Val loss 0.670\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.437, Val loss 0.674\n",
      "Ep 2 (Step 000125): Train loss 0.452, Val loss 0.687\n",
      "Ep 2 (Step 000130): Train loss 0.450, Val loss 0.683\n",
      "Ep 2 (Step 000135): Train loss 0.408, Val loss 0.678\n",
      "Ep 2 (Step 000140): Train loss 0.411, Val loss 0.677\n",
      "Ep 2 (Step 000145): Train loss 0.374, Val loss 0.679\n",
      "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.676\n",
      "Ep 2 (Step 000155): Train loss 0.420, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.416, Val loss 0.683\n",
      "Ep 2 (Step 000165): Train loss 0.382, Val loss 0.687\n",
      "Ep 2 (Step 000170): Train loss 0.328, Val loss 0.680\n",
      "Ep 2 (Step 000175): Train loss 0.336, Val loss 0.668\n",
      "Ep 2 (Step 000180): Train loss 0.394, Val loss 0.657\n",
      "Ep 2 (Step 000185): Train loss 0.423, Val loss 0.658\n",
      "Ep 2 (Step 000190): Train loss 0.343, Val loss 0.649\n",
      "Ep 2 (Step 000195): Train loss 0.330, Val loss 0.636\n",
      "Ep 2 (Step 000200): Train loss 0.312, Val loss 0.636\n",
      "Ep 2 (Step 000205): Train loss 0.355, Val loss 0.632\n",
      "Ep 2 (Step 000210): Train loss 0.361, Val loss 0.631\n",
      "Ep 2 (Step 000215): Train loss 0.392, Val loss 0.636\n",
      "Ep 2 (Step 000220): Train loss 0.294, Val loss 0.645\n",
      "Ep 2 (Step 000225): Train loss 0.340, Val loss 0.658\n",
      "Ep 2 (Step 000230): Train loss 0.296, Val loss 0.655\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 0.83 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time  # 导入time模块，用于计时训练过程\n",
    "\n",
    "start_time = time.time()  # 记录训练开始的时间（以秒为单位的时间戳）\n",
    "\n",
    "torch.manual_seed(123)  # 设置PyTorch的全局随机种子，保证结果可复现\n",
    "\n",
    "# 创建AdamW优化器（带有权重衰减的Adam优化器，一般用于Transformer/GPT类模型）\n",
    "# - model.parameters() ：模型中所有需要更新的参数\n",
    "# - lr=0.00005        ：学习率（步长），即每次参数更新幅度。这里设置为5e-5\n",
    "# - weight_decay=0.1  ：权重衰减系数，用于L2正则，帮助缓解过拟合\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2  # 规定训练轮数为2，即完整遍历两次训练集\n",
    "\n",
    "# 调用自定义的训练函数train_model_simple，进行模型finetune微调\n",
    "# - model            ：要训练的GPT模型\n",
    "# - train_loader     ：训练集的DataLoader，负责按batch迭代训练数据\n",
    "# - val_loader       ：验证集的DataLoader\n",
    "# - optimizer        ：训练时使用的优化器\n",
    "# - device           ：计算设备（如'cuda'或'cpu'）\n",
    "# - num_epochs       ：训练总轮数\n",
    "# - eval_freq=5      ：每训练5个batch就做一次验证集评估\n",
    "# - eval_iter=5      ：每次只用5个batch来评估损失，加快验证步骤\n",
    "# - start_context    ：验证时第一个输入的prompt，为val_data[0]格式化后文本\n",
    "# - tokenizer        ：分词器，用于文本/Token之间转换\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()  # 记录训练结束的时间\n",
    "\n",
    "execution_time_minutes = (end_time - start_time) / 60  # 计算训练总耗时（分钟）\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")  # 输出训练总用时"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ise3wGjlB-iq",
   "metadata": {
    "id": "Ise3wGjlB-iq"
   },
   "source": [
    "- 从上面的输出可以看出，模型训练得很好，训练损失和验证损失值不断下降。\n",
    "- 此外，从每个epoch结束后输出的响应文本来看，我们可以看到模型正确地执行了指令，将输入句子 `'The chef cooks the meal every day.'` 转换为被动语态 `'The meal is cooked every day by the chef.'`（我们将在后续章节中对响应进行适当的格式化和评估）。\n",
    "- 最后，让我们看看训练损失和验证损失曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4acd368b-1403-4807-a218-9102e35bfdbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "4acd368b-1403-4807-a218-9102e35bfdbb",
    "outputId": "680da58a-9bd7-402d-ac95-470a4a29a6c4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0",
   "metadata": {
    "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0"
   },
   "source": [
    "- 如我们所见，在第一个训练轮次的开始，损失急剧下降，这意味着模型开始迅速学习。\n",
    "- 大约在训练1个训练轮次时，模型出现了轻微的过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3",
   "metadata": {
    "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3"
   },
   "source": [
    "## 7.7 抽取并保存模型回复"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49",
   "metadata": {
    "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49"
   },
   "source": [
    "<img src=\"../image/17.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427",
   "metadata": {
    "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427"
   },
   "source": [
    "- 在本节中，我们保存测试集的响应，以便在下一节进行评估。\n",
    "- 我们还保存了模型的副本，以备将来使用。\n",
    "- 但首先，让我们粗略的查看一下微调后的模型生成的响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "VQ2NZMbfucAc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQ2NZMbfucAc",
    "outputId": "8416b4ac-1993-4628-dea6-7789cdc8926c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulus.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 设置随机种子，以保证生成结果的可复现性\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 从测试集 test_data 中取前三个样本，逐个生成模型响应并打印结果\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    # 将当前条目的输入格式化为完整的指令输入字符串\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    # 使用模型生成响应对应的 token 序列\n",
    "    # - model: 当前微调后的语言模型\n",
    "    # - idx: 经过分词器编码后的输入 token id，并放到计算设备上\n",
    "    # - max_new_tokens: 限制每次最多生成 256 个新 token\n",
    "    # - context_size: 上下文最大长度，采用基础配置中的 context_length\n",
    "    # - eos_id: 指定特殊 token（50256）作为生成终止标记\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    \n",
    "    # 将生成得到的 token id 序列解码为文本\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    \n",
    "    # 提取模型真正生成的回复内容（去除输入内容与特殊标记，并去除首尾空格）\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]               # 截掉输入 prompt 部分\n",
    "        .replace(\"### Response:\", \"\")                  # 去掉提示标记\n",
    "        .strip()                                       # 去除首尾空白符\n",
    "    )\n",
    "\n",
    "    # 打印格式化好的输入内容\n",
    "    print(input_text)\n",
    "    # 打印该条指令的标准参考输出（ground-truth）\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    # 打印模型生成的输出内容\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    # 分隔线便于阅读多个样本的输出效果\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab64c1-586f-4939-8def-23feeb1b3599",
   "metadata": {
    "id": "49ab64c1-586f-4939-8def-23feeb1b3599"
   },
   "source": [
    "- 从测试集中的指令、给定的响应以及模型的响应来看，模型的表现相对较好。\n",
    "- 第一个和最后一个指令的回答显然是正确的。\n",
    "- 第二个回答接近正确；模型回答为“积云”（cumulus cloud），而不是“雷雨云”（cumulonimbus）（不过需要注意的是，积云可能发展成雷雨云，而雷雨云具有产生雷暴的能力）。\n",
    "- 最重要的是，我们可以看到，模型评估结果不像第六章那样直接，因为在第六章中我们只需要计算正确的垃圾邮件/非垃圾邮件类别标签的百分比来获得分类准确率。\n",
    "- 实际上，指令微调后的LLM（如聊天机器人）通常通过多种方法进行评估：\n",
    "  - 短答案和多选基准，如MMLU（“大规模多任务语言理解测量”，[https://arxiv.org/abs/2009.03300](https://arxiv.org/abs/2009.03300)），测试模型的知识。\n",
    "  - 与其他LLM的人工偏好比较，如LMSYS聊天机器人竞技场（[https://arena.lmsys.org](https://arena.lmsys.org)）。\n",
    "  - 自动化对话基准，其中使用另一个LLM，如GPT-4，来评估响应，例如AlpacaEval（[https://tatsu-lab.github.io/alpaca_eval/](https://tatsu-lab.github.io/alpaca_eval/)）。\n",
    "- 在下一节中，我们将使用类似AlpacaEval的方法，使用另一个LLM来评估我们模型的响应；不过，我们将使用自己的测试集，而不是公开可用的基准数据集。\n",
    "- 为此，我们将模型的响应添加到 `test_data` 字典中，并将其保存为 `\"instruction-data-with-response.json\"` 文件，以便记录，这样我们可以在需要时在单独的Python会话中加载并分析它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "-PNGKzY4snKP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PNGKzY4snKP",
    "outputId": "0453dfb3-51cd-49e2-9e63-f65b606c3478"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:36<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # 导入进度条库，用于显示循环进度\n",
    "\n",
    "# 遍历每一条测试数据，tqdm用于显示处理进度条\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    # 针对当前测试样本，格式化输入（如添加前缀/后缀，准备为prompt）\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    # 调用generate函数生成响应\n",
    "    # - model: 当前的语言模型\n",
    "    # - idx: 用当前输入文本经过分词器转换得到的token id，并移动到device（CPU/GPU）\n",
    "    # - max_new_tokens: 限定一次最多生成256个新token，用于控制输出长度\n",
    "    # - context_size: 设置上下文允许的最大token数\n",
    "    # - eos_id: 指定特殊token（50256，通常代表<end-of-sequence>）作为终止信号\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "\n",
    "    # 将token id列表解码回人类可读文本\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    # 去掉输入prompt部分，只保留模型生成的回复内容\n",
    "    # 同时去除“### Response:”这种标记字符串和首尾空白符\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    # 把模型生成的回复写入到对应测试数据字典中\n",
    "    # 这样test_data每一项都多了个\"model_response\"字段，便于之后保存和评估\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "# 把包含模型回复的完整测试数据保存为json文件\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # 使用indent参数让json输出更具可读性（美观）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d6fa7-d162-44c3-bef1-4013c027b155",
   "metadata": {
    "id": "228d6fa7-d162-44c3-bef1-4013c027b155"
   },
   "source": [
    "- 让我们再检查一下其中一个条目，确认回复是否已正确添加到 `test_data` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "u-AvCCMTnPSE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-AvCCMTnPSE",
    "outputId": "ce3b2545-8990-4446-e44c-a945e0049c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a",
   "metadata": {
    "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a"
   },
   "source": [
    "- 最后保存这个模型以便日后复用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cBU0iHmVfOI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cBU0iHmVfOI",
    "outputId": "d6e7f226-9310-43f5-f31f-adc3a893a8e9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obgoGI89dgPm",
   "metadata": {
    "id": "obgoGI89dgPm"
   },
   "source": [
    "## 7.8 评价微调后的大语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b9d30-7336-499f-abb5-4a21be3129f5",
   "metadata": {
    "id": "805b9d30-7336-499f-abb5-4a21be3129f5"
   },
   "source": [
    "<img src=\"../image/18.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1",
   "metadata": {
    "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1"
   },
   "source": [
    "- 在本节中，我们通过使用另一个更强大的LLM来自动化微调后的LLM的响应评估。\n",
    "- 具体来说，我们使用了Meta AI发布的8B参数指令微调Llama 3模型，该模型可以通过ollama本地运行（[https://ollama.com](https://ollama.com)）。\n",
    "- （另外，如果您更喜欢通过OpenAI API使用像GPT-4这样的更强大的LLM，请参阅 [llm-instruction-eval-openai.ipynb](../03_model-evaluation/llm-instruction-eval-openai.ipynb) ）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9",
   "metadata": {
    "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9"
   },
   "source": [
    "- Ollama 是一个高效运行LLM的程序。\n",
    "- 它是 llama.cpp 的一个封装器（[https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)），该项目使用纯C/C++实现LLM，以最大化效率。\n",
    "- 请注意，Ollama 是用于生成文本（进行模型推理）的工具，而不是用于训练或微调LLM的工具。\n",
    "- 在运行以下代码之前，请访问 [https://ollama.com](https://ollama.com) 安装Ollama，并按照指示操作（例如，点击“下载”按钮并下载适用于您操作系统的Ollama应用程序）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822",
   "metadata": {
    "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822"
   },
   "source": [
    "- 对于macOS和Windows用户，点击已下载的ollama应用程序；如果提示安装命令行工具，选择“是”。\n",
    "- Linux用户可以使用ollama网站上提供的安装命令。\n",
    "\n",
    "- 通常，在我们通过命令行使用ollama之前，需要先启动ollama应用程序或在单独的终端中运行 `ollama serve`。\n",
    "\n",
    "<img src=\"../image/ollama-run.webp\" width=700px>\n",
    "\n",
    "- 在另一个终端运行ollama应用程序或 `ollama serve` 后，在命令行中执行以下命令，尝试使用8B参数的Llama 3模型（该模型占用4.7GB的存储空间，第一次执行此命令时会自动下载）。\n",
    "```bash\n",
    "# 8B 模型\n",
    "ollama run llama3\n",
    "```\n",
    "\n",
    "\n",
    "输出可能如下所示\n",
    "\n",
    "```\n",
    "$ ollama run llama3\n",
    "pulling manifest\n",
    "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
    "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB\n",
    "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B\n",
    "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B\n",
    "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "removing any unused layers\n",
    "success\n",
    "```\n",
    "\n",
    "- 请注意，`llama3` 指的是经过指令微调的8B参数Llama 3模型。\n",
    "\n",
    "- 使用ollama与 `\"llama3\"` 模型（8B参数模型）时需要16GB的RAM；如果您的机器不支持，可以尝试使用更小的模型，例如3.8B参数的phi-3模型，通过设置 `model = \"phi-3\"`，该模型只需8GB的RAM。\n",
    "\n",
    "- 如果您的机器支持，您还可以使用更大的70B参数Llama 3模型，只需将 `llama3` 替换为 `llama3:70b`。\n",
    "\n",
    "- 下载完成后，您将看到一个命令行提示符，可以与模型进行对话。\n",
    "\n",
    "- 尝试输入类似 \"What do llamas eat?\" 的提示，模型应返回类似以下的输出：\n",
    "\n",
    "```\n",
    ">>> What do llamas eat?\n",
    "Llamas are ruminant animals, which means they have a four-chambered\n",
    "stomach and eat plants that are high in fiber. In the wild, llamas\n",
    "typically feed on:\n",
    "1. Grasses: They love to graze on various types of grasses, including tall\n",
    "grasses, wheat, oats, and barley.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4",
   "metadata": {
    "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4"
   },
   "source": [
    "- 结束运行仅需要输入 `/bye`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3",
   "metadata": {
    "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3"
   },
   "source": [
    "- 以下代码检查ollama会话是否正常运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "026e8570-071e-48a2-aa38-64d7be35f288",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "026e8570-071e-48a2-aa38-64d7be35f288",
    "outputId": "e30d3533-e1f5-4aa9-b24f-33273fc7b30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "# 检查运行情况\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0",
   "metadata": {
    "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0"
   },
   "outputs": [],
   "source": [
    "# 该单元格是可选的；它允许您重新启动notebook\n",
    "# 并只运行第7.7节，而无需重新运行之前的代码。\n",
    "import json            # 导入json模块，用于读取和处理JSON数据\n",
    "from tqdm import tqdm  # 导入tqdm模块，用于显示进度条\n",
    "\n",
    "# 我们的数据文件路径\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "# 读取JSON文件并将其内容加载为Python对象\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)  # test_data现在是一个包含指令样本的列表，每个样本是一个字典\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    \"\"\"\n",
    "    将一个数据条目格式化为模型输入的字符串。\n",
    "\n",
    "    参数:\n",
    "        entry (dict): 包含'instruction', 'input'等字段的字典\n",
    "\n",
    "    返回:\n",
    "        str: 格式化后的输入文本，符合对话/指令-响应格式\n",
    "    \"\"\"\n",
    "    # 先拼接统一的系统说明和指令部分\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"  # 给模型的背景说明\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"     # 实际的指令内容\n",
    "    )\n",
    "\n",
    "    # 检查输入数据中是否有“input”字段内容，存在则添加输入部分，否则为空\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    # 返回完整的输入字符串：包含系统提示 + 指令 + （可选）输入字段\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3464705-d026-4594-977f-fb357e51c3a9",
   "metadata": {
    "id": "b3464705-d026-4594-977f-fb357e51c3a9"
   },
   "source": [
    "- 现在，与我们之前使用的 `ollama run` 命令互动模型的另一种方式是通过其REST API，在Python中通过以下函数进行操作。\n",
    "- 在运行notebook中的下一个单元格之前，请确保ollama仍在运行（前面的代码单元格应显示 `\"Ollama running: True\"`）。\n",
    "- 接下来，运行以下代码单元格来查询模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f",
   "metadata": {
    "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy munching on hay cubes or loose hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their diet. However, these should be given in moderation to avoid digestive issues.\n",
      "4. Fruits and vegetables: Fresh fruits and veggies can be a tasty treat for llamas. Some favorites include apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas need access to mineral supplements, such as salt licks or loose minerals, to ensure they're getting the necessary nutrients.\n",
      "\n",
      "In general, a llama's diet should consist of:\n",
      "\n",
      "* 70-80% grasses and hay\n",
      "* 10-20% grains and fruits/vegetables\n",
      "* 5-10% minerals and treats\n",
      "\n",
      "It's essential to provide llamas with a balanced diet that meets their nutritional needs. Consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3\",\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # 预处理的类型与符号\n",
    "    # 创建数据负载字典\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # 以下设置是为了获得确定性的响应\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    # 将字典转换为JSON格式的字符串并编码为字节\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    # 对JSON进行编码\n",
    "    # 创建请求对象，设置请求方法为POST并添加必要的头部信息\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    # 设置请求头部为JSON格式\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # 发送请求并捕获响应\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # 读取并解码响应\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc",
   "metadata": {
    "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc"
   },
   "source": [
    "- 现在，使用我们上面定义的 `query_model` 函数，我们可以评估微调后的模型的响应；让我们在前面一节中查看的前三个测试集响应上试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86b839d4-064d-4178-b2d7-01691b452e5e",
   "metadata": {
    "id": "86b839d4-064d-4178-b2d7-01691b452e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      ">> I'd score this response an 80.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The model correctly uses a simile (\"as fast as\") to compare the speed of the car.\n",
      "* It chooses a relevant and familiar animal (cheetah) that is known for its speed, making the comparison relatable and easy to understand.\n",
      "* However, while lightning is an extremely fast phenomenon, it's more universally recognized as the fastest thing in the universe. Cheetahs are also very fast, but they're not quite as iconic or widely associated with extreme speed as lightning.\n",
      "\n",
      "Overall, the response is a good attempt at using a simile to describe the car's speed, and it's close to being excellent. But since lightning is generally considered an even more impressive benchmark for speed, I'd give it 80 out of 100.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulus.\n",
      "\n",
      "Score:\n",
      ">> I'd score this model response as 40 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The model correctly identifies that it's talking about clouds related to thunderstorms.\n",
      "* However, it incorrectly states that cumulus clouds are typically associated with thunderstorms. Cumulonimbus clouds are actually the ones commonly linked with thunderstorms.\n",
      "* The response is not entirely incorrect, but it's not accurate either.\n",
      "\n",
      "A score of 40 reflects a moderate level of error, as the model partially understands the instruction but provides an incorrect answer.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> I'd score my own response as 95 out of 100. Here's why:\n",
      "\n",
      "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
      "* The response is concise and clear, making it easy to understand.\n",
      "* There are no grammatical errors or ambiguities that could lead to confusion.\n",
      "\n",
      "The only reason I wouldn't score it a perfect 100 is that the response is very straightforward and doesn't add any additional value or insights. It simply answers the question in a simple and accurate manner.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 遍历测试数据集中前3个条目，对模型的响应进行打分和展示\n",
    "for entry in test_data[:3]:\n",
    "    # 为每个测试样本构造一个自定义提示词\n",
    "    # - format_input(entry): 格式化输入内容（例如，指令或用户输入）\n",
    "    # - entry['output']: 期望的标准输出\n",
    "    # - entry['model_response']: 当前模型生成的输出\n",
    "    # - 提示要求模型根据输入、标准输出与模型输出之间的差异给出 0~100 的分数（100为最优）\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "\n",
    "    # 打印标准输出（理想答案）供人工比对与参考\n",
    "    print(\"\\nDataset response:\")           # 显示数据集中该条目的正确答案\n",
    "    print(\">>\", entry['output'])\n",
    "\n",
    "    # 打印模型生成的输出（实际推断结果）\n",
    "    print(\"\\nModel response:\")             # 显示模型的回答\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "\n",
    "    # 打印打分结果（模型根据提示打分自身表现）\n",
    "    print(\"\\nScore:\")                      # 显示通过模型打分获得的分数\n",
    "    print(\">>\", query_model(prompt))       # 调用query_model提交上面构造的prompt并输出结果\n",
    "\n",
    "    # 分隔符，便于阅读多个样本的输出\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3",
   "metadata": {
    "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3"
   },
   "source": [
    "- 如我们所见，Llama 3 模型给出了合理的评估\n",
    "- 如果模型的回答不完全正确，它会根据部分正确的内容给予相应的分数，例如“积云”这个回答。\n",
    "- 请注意，之前的提示会返回详细的评估结果；我们可以调整提示，使其生成介于0到100之间的整数分数（其中100为最佳），以便计算模型的平均得分。\n",
    "- 对测试集中的110个条目进行评估大约需要1分钟(在M3 MacBook Air上运行)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb",
   "metadata": {
    "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [00:41<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 50.78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成模型得分的函数，用于评估模型的输出表现\n",
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    针对一组测试样本，批量让模型自评分数（0~100），返回对应分数序列。\n",
    "\n",
    "    参数说明：\n",
    "    - json_data: list\n",
    "        包含每个测试样本的字典list, 数据格式如[{\"input\":.., \"output\":.., json_key:..}, ...]\n",
    "    - json_key: str\n",
    "        指定在每个样本字典中用于打分的key（比如 \"model_response\"）, 代表要评估的答案\n",
    "    - model: str\n",
    "        调用评分时用的模型名（如 \"llama3\"），可根据需求切换不同模型\n",
    "\n",
    "    返回：\n",
    "    - scores: list[int]\n",
    "        每个样本的自评分（int类型），范围 0~100\n",
    "    \"\"\"\n",
    "\n",
    "    scores = []  # 用于存储所有评估得到的分数\n",
    "\n",
    "    # tqdm用于显示进度条，便于知道处理进度\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        # 构造打分prompt，要求模型给出0~100的整数评估分数\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"  # 明确要求只回复数字，方便解析\n",
    "        )\n",
    "        # query_model会用指定模型生成回答\n",
    "        score = query_model(prompt, model)\n",
    "\n",
    "        # 尝试将结果转成整数，若失败记录异常并继续\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")  # 打印无法转换的原始模型输出\n",
    "            continue  # 跳过该条，继续评测下一个样本\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# 对test_data全部样本进行自评分，指定用\"model_response\"字段作为模型要评分的内容\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")  # 打印实际评分条目数\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")       # 打印平均分，保留2位小数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2",
   "metadata": {
    "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2"
   },
   "source": [
    "- 我们的模型平均得分超过50分，可以将其作为参考，与其他模型进行对比;或尝试其他训练设置来改进模型表现。\n",
    "- 截至汉化的时候,ollama 在不同操作系统上的结果可能会有所不同，因此您得到的数值可能与上面显示的略有差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94",
   "metadata": {
    "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94"
   },
   "source": [
    "- 以下看作参考\n",
    "  - Llama 3 8B 基础模型得分为 58.51\n",
    "  - Llama 3 8B 指令微调模型得分为 82.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d7325-284a-446c-92a1-5aa8acc52dee",
   "metadata": {
    "id": "412d7325-284a-446c-92a1-5aa8acc52dee"
   },
   "source": [
    "## 7.9 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tIbNMluCDjVM",
   "metadata": {
    "id": "tIbNMluCDjVM"
   },
   "source": [
    "### 7.9.1 展望\n",
    "\n",
    "- 本章标志着本书的结束。\n",
    "- 我们覆盖了LLM开发的主要步骤：实现LLM架构、预训练LLM以及微调模型。\n",
    "\n",
    "<img src=\"../image/19.png\" width=500px>\n",
    "\n",
    "- 正如本章所述,指令微调后，有时会进行一个可选步骤——偏好微调.\n",
    "- 偏好微调有助于定制模型，更好地符合用户偏好。如果您感兴趣，可以查看 [../04_preference-tuning-with-dpo](../04_preference-tuning-with-dpo) 文件夹。\n",
    "\n",
    "- 本GitHub仓库还包含大量额外的附加资料，您可能会喜欢；有关更多信息，请查看本仓库README页面中的 [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) 部分。\n",
    "\n",
    "### 7.9.2 紧跟时代潮流\n",
    "\n",
    "- 本节没有代码内容。\n",
    "\n",
    "### 7.9.3 寄语\n",
    "\n",
    "- 我希望您喜欢这个从零实现LLM的过程，以及编写预训练和微调代码的过程。\n",
    "- 在我看来，从零构建大模型是理解LLM如何工作的最佳方式；我希望您通过这种方式获得了更深入的理解。\n",
    "- 虽然本书是为了教学目的，但您可能有兴趣将不同的、更强大的LLM应用于实际应用中。\n",
    "  - 为此，您可以考虑使用一些流行工具，如axolotl（[https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)）或LitGPT（[https://github.com/Lightning-AI/litgpt](https://github.com/Lightning-AI/litgpt)），这是我参与开发的工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9853e7f-a81a-4806-9728-be1690807185",
   "metadata": {
    "id": "f9853e7f-a81a-4806-9728-be1690807185"
   },
   "source": [
    "## 总结与收获\n",
    "\n",
    "- 请参阅 [./gpt_instruction_finetuning.py](./gpt_instruction_finetuning.py) 脚本，它是一个自包含的分类微调脚本。\n",
    "- [./ollama_evaluate.py](./ollama_evaluate.py) 是基于第7.8节的独立脚本，通过Ollama和Llama 3评估包含“output”和“response”键的JSON文件。\n",
    "- [./load-finetuned-model.ipynb](./load-finetuned-model.ipynb) 笔记本演示了如何在新会话中加载微调后的模型。\n",
    "- 您可以在 [./exercise-solutions.ipynb](./exercise-solutions.ipynb) 找到习题解答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc51ec-e06c-4470-b626-48401a037851",
   "metadata": {},
   "source": [
    "## 接下来做什么？\n",
    "\n",
    "- 恭喜您完成了本书！如果您在寻找更多资源，我在这个GitHub仓库中添加了几个附加部分，您可能会感兴趣。\n",
    "- 附加资料的完整列表可以在主README的 [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) 部分查看。\n",
    "- 在这里，我想特别强调几个我喜欢的部分：\n",
    "  1. [从零开始的直接偏好优化（DPO）用于LLM对齐](../04_preference-tuning-with-dpo/dpo-from-scratch.ipynb) 实现了一种流行的偏好调优机制，使本章的模型与人类偏好更加契合。\n",
    "  2. [从零开始实现Llama 3.2](../../ch05/07_gpt_to_llama/standalone-llama32.ipynb)，这是Meta AI流行的Llama 3.2的从零实现，包括加载官方的预训练权重；如果您想做一些额外的实验，可以将每章中的 `GPTModel` 模型替换为 `Llama3Model` 类（它可以作为1:1替代）。\n",
    "  3. [将GPT转换为Llama](../../ch05/07_gpt_to_llama) 包含逐步指南的代码，解释了GPT-2和各种Llama模型之间的区别。\n",
    "  4. [理解嵌入层和线性层的区别](../../ch02/03_bonus_embedding-vs-matmul/embeddings-and-linear-layers.ipynb) 是一个概念性解释，说明了我们在LLM输入阶段使用的PyTorch中的 `Embedding` 层在数学上等价于对独热编码数据应用的线性层。\n",
    "- 祝您学习愉快！"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
